# %% [markdown]
# # ğŸ” SAM 3 Lab 5 â€” Object Search by Click
# ## à¸„à¸¥à¸´à¸à¹€à¸¥à¸·à¸­à¸ Object â†’ à¸„à¹‰à¸™à¸«à¸² Object à¸—à¸µà¹ˆà¸„à¸¥à¹‰à¸²à¸¢à¸à¸±à¸™à¸‚à¹‰à¸²à¸¡à¸£à¸¹à¸›à¸ à¸²à¸
#
# ---
#
# ## ğŸ“š à¸ªà¸²à¸£à¸šà¸±à¸ (Table of Contents)
#
# | Step | à¸«à¸±à¸§à¸‚à¹‰à¸­ | à¸ªà¸´à¹ˆà¸‡à¸—à¸µà¹ˆà¸ˆà¸°à¹„à¸”à¹‰à¹€à¸£à¸µà¸¢à¸™à¸£à¸¹à¹‰ |
# |------|--------|---------------------|
# | **5.1** | Setup & à¹€à¸•à¸£à¸µà¸¢à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ | à¹‚à¸«à¸¥à¸” model, à¸ªà¸£à¹‰à¸²à¸‡ image gallery à¹ƒà¸™ pandas |
# | **5.2** | à¸„à¸¥à¸´à¸à¹€à¸¥à¸·à¸­à¸ Object | à¹ƒà¸Šà¹‰ point prompt à¹€à¸à¸·à¹ˆà¸­ segment object à¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸à¸²à¸£ |
# | **5.3** | à¸ªà¸à¸±à¸” Feature Vector | à¸”à¸¶à¸‡ embedding à¸ˆà¸²à¸ object à¸—à¸µà¹ˆà¹€à¸¥à¸·à¸­à¸ |
# | **5.4** | à¸„à¹‰à¸™à¸«à¸²à¸‚à¹‰à¸²à¸¡à¸£à¸¹à¸›à¸ à¸²à¸ | à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸š similarity à¸à¸±à¸š object à¹ƒà¸™à¸£à¸¹à¸›à¸­à¸·à¹ˆà¸™à¹† |
# | **5.5** | à¹à¸ªà¸”à¸‡à¸œà¸¥ Similarity | Visualize à¸œà¸¥à¸à¸²à¸£à¸„à¹‰à¸™à¸«à¸²à¹à¸šà¸š ranking |
#
# ---
#
# ## ğŸ¤” à¹à¸™à¸§à¸„à¸´à¸”à¸«à¸¥à¸±à¸ (Core Idea)
#
# ```
# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
# â”‚  1. à¹€à¸¥à¸·à¸­à¸à¸£à¸¹à¸›à¸ˆà¸²à¸ gallery (pandas DataFrame)              â”‚
# â”‚  2. à¸„à¸¥à¸´à¸ point à¸šà¸™ object à¸—à¸µà¹ˆà¸ªà¸™à¹ƒà¸ˆ                        â”‚
# â”‚  3. SAM 3 segment object â†’ à¹„à¸”à¹‰ mask                     â”‚
# â”‚  4. à¸ªà¸à¸±à¸” feature vector à¸ˆà¸²à¸ masked region               â”‚
# â”‚  5. à¸§à¸™ loop à¸„à¹‰à¸™à¸«à¸² object à¹€à¸”à¸µà¸¢à¸§à¸à¸±à¸™à¹ƒà¸™à¸£à¸¹à¸›à¸­à¸·à¹ˆà¸™à¹†             â”‚
# â”‚  6. à¸ˆà¸±à¸”à¸­à¸±à¸™à¸”à¸±à¸š similarity â†’ à¹à¸ªà¸”à¸‡à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œ                   â”‚
# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
# ```
#
# ### à¸§à¸´à¸˜à¸µà¸§à¸±à¸” Similarity
# à¹€à¸£à¸²à¹ƒà¸Šà¹‰ **Cosine Similarity** à¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡ feature vectors:
# ```
#              A Â· B
# cos(Î¸) = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ = 1.0 (à¹€à¸«à¸¡à¸·à¸­à¸™à¸à¸±à¸™à¹€à¸›à¹Šà¸°) ... 0.0 (à¹„à¸¡à¹ˆà¹€à¸à¸µà¹ˆà¸¢à¸§à¸à¸±à¸™à¹€à¸¥à¸¢)
#           â€–Aâ€– Ã— â€–Bâ€–
# ```

# %% [markdown]
# ---
# # ğŸŸ¢ Step 5.1: Setup & à¹€à¸•à¸£à¸µà¸¢à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸™ Pandas
#
# ### ğŸ¯ à¹€à¸›à¹‰à¸²à¸«à¸¡à¸²à¸¢
# 1. à¹‚à¸«à¸¥à¸” SAM 3 model à¸—à¸±à¹‰à¸‡ 2 à¸•à¸±à¸§ (Text + Tracker)
# 2. à¹‚à¸«à¸¥à¸” FoodSeg103 dataset
# 3. à¸ªà¸£à¹‰à¸²à¸‡ **pandas DataFrame** à¹€à¸›à¹‡à¸™ gallery à¸ªà¸³à¸«à¸£à¸±à¸šà¹€à¸¥à¸·à¸­à¸à¸£à¸¹à¸›

# %%
# ============================================================
# Step 5.1.1: Import libraries
# ============================================================
import torch
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from PIL import Image as PILImage
from datasets import load_dataset
from transformers import (
    Sam3Processor, Sam3Model,
    Sam3TrackerProcessor, Sam3TrackerModel,
)
from scipy import ndimage
from sklearn.metrics.pairwise import cosine_similarity
import torchvision.transforms as T
import random
import pandas as pd
import warnings
warnings.filterwarnings("ignore")

# --- GPU Check ---
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"ğŸ–¥ï¸  Using device: {device}")
if torch.cuda.is_available():
    print(f"   GPU: {torch.cuda.get_device_name(0)}")

# %%
# ============================================================
# Step 5.1.2: à¹‚à¸«à¸¥à¸” SAM 3 Models (Text + Tracker)
# ============================================================
# Text model  â†’ à¹ƒà¸Šà¹‰à¸ªà¸à¸±à¸” vision features (embedding)
# Tracker model â†’ à¹ƒà¸Šà¹‰ segment à¸ˆà¸²à¸ point click

print("â³ Loading SAM 3 models...")

# --- Text/Vision Model (à¸ªà¸³à¸«à¸£à¸±à¸š feature extraction) ---
processor = Sam3Processor.from_pretrained("facebook/sam3")
model = Sam3Model.from_pretrained("facebook/sam3").to(device)
model.eval()

# --- Tracker Model (à¸ªà¸³à¸«à¸£à¸±à¸š point click segmentation) ---
tracker_processor = Sam3TrackerProcessor.from_pretrained("facebook/sam3")
tracker_model = Sam3TrackerModel.from_pretrained("facebook/sam3").to(device)
tracker_model.eval()

print("âœ… Both models loaded!")

# %%
# ============================================================
# Step 5.1.3: à¹‚à¸«à¸¥à¸” FoodSeg103 Dataset
# ============================================================
print("â³ Loading FoodSeg103 dataset...")
ds = load_dataset("EduardoPacheco/FoodSeg103", split="train")
print(f"âœ… Dataset loaded: {len(ds):,} images")

# %%
# ============================================================
# Step 5.1.4: Food Category Labels
# ============================================================
FOODSEG103_LABELS = {
    0: "background", 1: "candy", 2: "egg tart", 3: "french fries", 4: "chocolate",
    5: "biscuit", 6: "popcorn", 7: "pudding", 8: "ice cream", 9: "cheese butter",
    10: "cake", 11: "wine", 12: "milkshake", 13: "coffee", 14: "juice",
    15: "milk", 16: "tea", 17: "almond", 18: "red beans", 19: "cashew",
    20: "dried cranberries", 21: "soy", 22: "walnut", 23: "peanut", 24: "egg",
    25: "apple", 26: "date", 27: "apricot", 28: "avocado", 29: "banana",
    30: "strawberry", 31: "cherry", 32: "blueberry", 33: "raspberry", 34: "mango",
    35: "olives", 36: "peach", 37: "lemon", 38: "pear", 39: "fig",
    40: "pineapple", 41: "grape", 42: "kiwi", 43: "melon", 44: "orange",
    45: "watermelon", 46: "steak", 47: "pork", 48: "chicken duck", 49: "sausage",
    50: "fried meat", 51: "lamb", 52: "sauce", 53: "crab", 54: "fish",
    55: "shellfish", 56: "shrimp", 57: "squid", 58: "bread", 59: "corn",
    60: "dumpling", 61: "hamburger", 62: "pizza", 63: "hanamaki baozi",
    64: "wonton", 65: "pasta", 66: "rice", 67: "noodles", 68: "soup",
    69: "cake", 70: "hotdog", 71: "spring roll", 72: "tofu", 73: "asparagus",
    74: "broccoli", 75: "Brussels sprout", 76: "cabbage", 77: "carrot",
    78: "celery", 79: "corn", 80: "cucumber", 81: "eggplant",
    82: "garlic", 83: "ginger", 84: "lettuce", 85: "mushroom",
    86: "onion", 87: "pepper", 88: "potato", 89: "pumpkin",
    90: "sweet potato", 91: "tomato", 92: "bean sprouts", 93: "green beans",
    94: "spinach", 95: "bell pepper", 96: "white radish", 97: "kidney beans",
    98: "mixed vegetables", 99: "crispy chicken", 100: "chicken wings",
    101: "french beans", 102: "other ingredients", 103: "salad",
}
LABEL_TO_ID = {name: cid for cid, name in FOODSEG103_LABELS.items()}


def get_class_names(class_ids):
    """à¹à¸›à¸¥à¸‡ class IDs â†’ à¸Šà¸·à¹ˆà¸­à¸­à¸²à¸«à¸²à¸£"""
    return [FOODSEG103_LABELS.get(c, f"unknown_{c}") for c in class_ids]


print(f"âœ… {len(FOODSEG103_LABELS)} food categories loaded")

# %%
# ============================================================
# Step 5.1.5: à¸ªà¸£à¹‰à¸²à¸‡ Image Gallery à¹ƒà¸™ Pandas DataFrame
# ============================================================
# à¸ªà¸£à¹‰à¸²à¸‡ DataFrame à¸—à¸µà¹ˆà¹€à¸à¹‡à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸£à¸¹à¸›à¸ à¸²à¸ à¹€à¸à¸·à¹ˆà¸­à¹ƒà¸«à¹‰à¸™à¸±à¸à¸¨à¸¶à¸à¸©à¸²à¹€à¸¥à¸·à¸­à¸à¸£à¸¹à¸›à¸ˆà¸²à¸ table à¹„à¸”à¹‰à¸‡à¹ˆà¸²à¸¢
#
# ğŸ’¡ à¹€à¸£à¸²à¹€à¸¥à¸·à¸­à¸à¹€à¸‰à¸à¸²à¸°à¸£à¸¹à¸›à¸—à¸µà¹ˆà¸¡à¸µ "egg" à¹€à¸à¸·à¹ˆà¸­à¹ƒà¸Šà¹‰à¹€à¸›à¹‡à¸™à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡
#    (à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹€à¸›à¹‡à¸™ food class à¸­à¸·à¹ˆà¸™à¹„à¸”à¹‰ à¹€à¸Šà¹ˆà¸™ "tomato", "rice")

TARGET_FOOD = "egg"
TARGET_ID = LABEL_TO_ID[TARGET_FOOD]

print(f'ğŸ” à¸à¸³à¸¥à¸±à¸‡à¸„à¹‰à¸™à¸«à¸²à¸£à¸¹à¸›à¸—à¸µà¹ˆà¸¡à¸µ "{TARGET_FOOD}" à¹ƒà¸™ dataset...')

# --- à¸ªà¸¸à¹ˆà¸¡à¹€à¸¥à¸·à¸­à¸à¸£à¸¹à¸›à¸—à¸µà¹ˆà¸¡à¸µ target food ---
gallery_records = []
indices = list(range(len(ds)))
random.seed(42)  # à¹ƒà¸«à¹‰à¹„à¸”à¹‰à¸œà¸¥à¹€à¸«à¸¡à¸·à¸­à¸™à¸à¸±à¸™à¸—à¸¸à¸à¸„à¸£à¸±à¹‰à¸‡
random.shuffle(indices)

MAX_GALLERY = 20  # à¸ˆà¸³à¸™à¸§à¸™à¸£à¸¹à¸›à¹ƒà¸™ gallery

for idx in indices:
    if len(gallery_records) >= MAX_GALLERY:
        break
    sample = ds[idx]
    if TARGET_ID in sample["classes_on_image"]:
        names = get_class_names(sample["classes_on_image"])
        food_names = [n for n in names if n != "background"]
        gallery_records.append({
            "gallery_id": len(gallery_records),
            "dataset_idx": idx,
            "food_classes": ", ".join(food_names),
            "num_classes": len(food_names),
            "image_size": f"{sample['image'].size[0]}Ã—{sample['image'].size[1]}",
        })

# --- à¸ªà¸£à¹‰à¸²à¸‡ DataFrame ---
df_gallery = pd.DataFrame(gallery_records)

print(f"\nâœ… à¸ªà¸£à¹‰à¸²à¸‡ Gallery à¸ªà¸³à¹€à¸£à¹‡à¸ˆ: {len(df_gallery)} à¸£à¸¹à¸›à¸—à¸µà¹ˆà¸¡à¸µ '{TARGET_FOOD}'")
print("\nğŸ“‹ Image Gallery DataFrame:")
df_gallery

# %%
# ============================================================
# Step 5.1.6: à¹à¸ªà¸”à¸‡ Gallery à¹€à¸›à¹‡à¸™ Grid
# ============================================================
# à¹à¸ªà¸”à¸‡à¸£à¸¹à¸›à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”à¹ƒà¸™ gallery à¹€à¸à¸·à¹ˆà¸­à¹ƒà¸«à¹‰à¹€à¸¥à¸·à¸­à¸à¸£à¸¹à¸›à¸—à¸µà¹ˆà¸ˆà¸°à¸„à¸¥à¸´à¸

cols = 5
rows = (len(df_gallery) + cols - 1) // cols
fig, axes = plt.subplots(rows, cols, figsize=(20, 4 * rows))
axes_flat = axes.flatten()

for i, (_, row) in enumerate(df_gallery.iterrows()):
    ax = axes_flat[i]
    img = ds[row["dataset_idx"]]["image"]
    ax.imshow(img)
    ax.set_title(f"gallery_id={row['gallery_id']}\n{row['food_classes'][:30]}",
                 fontsize=8, fontweight="bold")
    ax.axis("off")

# à¸‹à¹ˆà¸­à¸™ axes à¸—à¸µà¹ˆà¹€à¸«à¸¥à¸·à¸­
for j in range(len(df_gallery), len(axes_flat)):
    axes_flat[j].axis("off")

plt.suptitle(f'ğŸ–¼ï¸ Image Gallery â€” à¸£à¸¹à¸›à¸—à¸µà¹ˆà¸¡à¸µ "{TARGET_FOOD}" ({len(df_gallery)} à¸£à¸¹à¸›)\n'
             f'à¹€à¸¥à¸·à¸­à¸ gallery_id à¸ªà¸³à¸«à¸£à¸±à¸š Step à¸–à¸±à¸”à¹„à¸›', fontsize=14, fontweight="bold")
plt.tight_layout()
plt.show()

print("ğŸ’¡ à¸ˆà¸” gallery_id à¸‚à¸­à¸‡à¸£à¸¹à¸›à¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸„à¸¥à¸´à¸ à¹à¸¥à¹‰à¸§à¹ƒà¸Šà¹‰à¹ƒà¸™ Step 5.2")

# %% [markdown]
# ---
# # ğŸŸ¢ Step 5.2: à¸„à¸¥à¸´à¸à¹€à¸¥à¸·à¸­à¸ Object à¸ˆà¸²à¸à¸£à¸¹à¸›à¸—à¸µà¹ˆà¹€à¸¥à¸·à¸­à¸
#
# ### ğŸ¯ à¹€à¸›à¹‰à¸²à¸«à¸¡à¸²à¸¢
# 1. à¹€à¸¥à¸·à¸­à¸à¸£à¸¹à¸›à¸ˆà¸²à¸ gallery à¹‚à¸”à¸¢à¹ƒà¸Šà¹‰ `gallery_id`
# 2. à¸”à¸¹ coordinate grid à¹€à¸à¸·à¹ˆà¸­à¸«à¸²à¸•à¸³à¹à¸«à¸™à¹ˆà¸‡ (x, y)
# 3. à¸„à¸¥à¸´à¸ point â†’ SAM 3 segment object â†’ à¹„à¸”à¹‰ mask
#
# ### ğŸ’¡ à¸§à¸´à¸˜à¸µà¸à¸²à¸£
# ```
# à¹€à¸¥à¸·à¸­à¸à¸£à¸¹à¸› (gallery_id) â†’ à¸”à¸¹ grid â†’ à¹€à¸¥à¸·à¸­à¸ (x,y) â†’ SAM 3 segment
# ```

# %%
# ============================================================
# Step 5.2.1: à¹€à¸¥à¸·à¸­à¸à¸£à¸¹à¸›à¸ˆà¸²à¸ Gallery
# ============================================================
# â¬‡ï¸ à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™ SELECTED_GALLERY_ID à¹€à¸à¸·à¹ˆà¸­à¹€à¸¥à¸·à¸­à¸à¸£à¸¹à¸›à¸­à¸·à¹ˆà¸™
SELECTED_GALLERY_ID = 0

# --- à¸”à¸¶à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ˆà¸²à¸ DataFrame ---
selected_row = df_gallery[df_gallery["gallery_id"] == SELECTED_GALLERY_ID].iloc[0]
selected_ds_idx = selected_row["dataset_idx"]

sample = ds[selected_ds_idx]
query_image = sample["image"].convert("RGB")
img_w, img_h = query_image.size

print(f"ğŸ“· à¹€à¸¥à¸·à¸­à¸à¸£à¸¹à¸› gallery_id = {SELECTED_GALLERY_ID}")
print(f"   Dataset index : {selected_ds_idx}")
print(f"   Image size    : {img_w} Ã— {img_h}")
print(f"   Food classes  : {selected_row['food_classes']}")

# %%
# ============================================================
# Step 5.2.2: à¹à¸ªà¸”à¸‡ Coordinate Grid à¹€à¸à¸·à¹ˆà¸­à¹€à¸¥à¸·à¸­à¸à¸•à¸³à¹à¸«à¸™à¹ˆà¸‡à¸„à¸¥à¸´à¸
# ============================================================
fig, ax = plt.subplots(figsize=(10, 8))
ax.imshow(query_image)
ax.set_title(f"ğŸ“ Coordinate Grid â€” gallery_id={SELECTED_GALLERY_ID}\n"
             f"à¸ˆà¸”à¸•à¸³à¹à¸«à¸™à¹ˆà¸‡ (x, y) à¸‚à¸­à¸‡ object à¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸„à¹‰à¸™à¸«à¸²", fontsize=12)
ax.set_xticks(range(0, img_w, 50))
ax.set_yticks(range(0, img_h, 50))
ax.grid(alpha=0.5, color="yellow", linewidth=0.8)
ax.tick_params(labelsize=7)
plt.tight_layout()
plt.show()

print("ğŸ’¡ Tips: à¸”à¸¹à¸•à¸³à¹à¸«à¸™à¹ˆà¸‡ (x, y) à¸ˆà¸²à¸ grid à¹à¸¥à¹‰à¸§à¹ƒà¸ªà¹ˆà¹ƒà¸™ CLICK_POINT à¸”à¹‰à¸²à¸™à¸¥à¹ˆà¸²à¸‡")

# %%
# ============================================================
# Step 5.2.3: à¸„à¸¥à¸´à¸ Point â†’ Segment Object
# ============================================================
# â¬‡ï¸ à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¸„à¹ˆà¸² CLICK_POINT à¹€à¸›à¹‡à¸™à¸•à¸³à¹à¸«à¸™à¹ˆà¸‡ (x, y) à¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸à¸²à¸£
CLICK_POINT = [300, 920]  # â† à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¸•à¸£à¸‡à¸™à¸µà¹‰!

input_points = [[[[CLICK_POINT[0], CLICK_POINT[1]]]]]
input_labels = [[[1]]]  # 1 = positive point

print(f"ğŸ“ Click position: ({CLICK_POINT[0]}, {CLICK_POINT[1]})")
print("â³ à¸à¸³à¸¥à¸±à¸‡ segment...")

# --- Run SAM 3 Tracker ---
inputs = tracker_processor(
    images=query_image,
    input_points=input_points,
    input_labels=input_labels,
    return_tensors="pt",
).to(device)

with torch.no_grad():
    outputs = tracker_model(**inputs)

# --- Extract best mask ---
masks = outputs.pred_masks.squeeze().cpu().numpy()
scores = outputs.iou_scores.squeeze().cpu().numpy()
best_idx = scores.argmax()
best_mask = masks[best_idx]
best_score = scores[best_idx]

# Resize mask to image size
query_mask = np.array(
    PILImage.fromarray(best_mask.astype(np.float32)).resize((img_w, img_h))
) > 0

print(f"âœ… Segment à¸ªà¸³à¹€à¸£à¹‡à¸ˆ!")
print(f"   Confidence score : {best_score:.4f}")
print(f"   Mask pixels      : {int(query_mask.sum()):,}")

# %%
# ============================================================
# Step 5.2.4: à¹à¸ªà¸”à¸‡à¸œà¸¥ Segmentation Result (3 panels)
# ============================================================
img_array = np.array(query_image)

fig, axes = plt.subplots(1, 3, figsize=(18, 6))

# Panel 1: à¸£à¸¹à¸›à¸•à¹‰à¸™à¸‰à¸šà¸±à¸š + à¸ˆà¸¸à¸”à¸—à¸µà¹ˆà¸„à¸¥à¸´à¸
axes[0].imshow(query_image)
axes[0].scatter(CLICK_POINT[0], CLICK_POINT[1], c="lime", s=400, marker="*",
                edgecolors="white", linewidths=2, zorder=5)
axes[0].annotate(f"Click ({CLICK_POINT[0]}, {CLICK_POINT[1]})",
                 (CLICK_POINT[0], CLICK_POINT[1]),
                 textcoords="offset points", xytext=(12, -18), fontsize=10,
                 color="white", bbox=dict(boxstyle="round", facecolor="black", alpha=0.7))
axes[0].set_title("â‘  à¸£à¸¹à¸›à¸•à¹‰à¸™à¸‰à¸šà¸±à¸š + à¸ˆà¸¸à¸”à¸—à¸µà¹ˆà¸„à¸¥à¸´à¸", fontsize=13)
axes[0].axis("off")

# Panel 2: Mask à¸—à¸µà¹ˆà¹„à¸”à¹‰
axes[1].imshow(query_mask, cmap="gray")
axes[1].set_title(f"â‘¡ Predicted Mask (score: {best_score:.3f})", fontsize=13)
axes[1].axis("off")

# Panel 3: Extracted object (à¸à¸·à¹‰à¸™à¸«à¸¥à¸±à¸‡à¸‚à¸²à¸§)
canvas = np.ones_like(img_array) * 255
canvas[query_mask] = img_array[query_mask]
axes[2].imshow(canvas)
axes[2].set_title("â‘¢ Object à¸—à¸µà¹ˆà¸•à¸±à¸”à¸­à¸­à¸à¸¡à¸² (Query Object)", fontsize=13)
axes[2].axis("off")

plt.suptitle(f"ğŸ¯ Query Object â€” gallery_id={SELECTED_GALLERY_ID}",
             fontsize=16, fontweight="bold")
plt.tight_layout()
plt.show()

# %% [markdown]
# ---
# # ğŸŸ¢ Step 5.3: à¸ªà¸à¸±à¸” Feature Vector à¸ˆà¸²à¸ Object
#
# ### ğŸ¯ à¹€à¸›à¹‰à¸²à¸«à¸¡à¸²à¸¢
# à¸ªà¸à¸±à¸” **feature vector** (embedding) à¸ˆà¸²à¸ object à¸—à¸µà¹ˆ segment à¹„à¸”à¹‰
# à¹€à¸à¸·à¹ˆà¸­à¹ƒà¸Šà¹‰à¹€à¸›à¹‡à¸™ "à¸¥à¸²à¸¢à¸™à¸´à¹‰à¸§à¸¡à¸·à¸­" à¹ƒà¸™à¸à¸²à¸£à¸„à¹‰à¸™à¸«à¸² object à¸—à¸µà¹ˆà¸„à¸¥à¹‰à¸²à¸¢à¸à¸±à¸™
#
# ### ğŸ’¡ à¹à¸™à¸§à¸„à¸´à¸”
# ```
# Object à¸—à¸µà¹ˆ segment à¹„à¸”à¹‰
#     â†“
# Crop à¸•à¸²à¸¡ bounding box à¸‚à¸­à¸‡ mask
#     â†“
# à¸ªà¹ˆà¸‡à¹€à¸‚à¹‰à¸² SAM 3 Vision Encoder
#     â†“
# à¹„à¸”à¹‰ Feature Vector (embedding)
#     â†“
# à¹ƒà¸Šà¹‰à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸šà¸à¸±à¸š object à¸­à¸·à¹ˆà¸™à¹†
# ```
#
# ### à¸§à¸´à¸˜à¸µà¸ªà¸à¸±à¸” Feature
# à¹€à¸£à¸²à¹ƒà¸Šà¹‰ **SAM 3 Vision Encoder** à¹€à¸à¸·à¹ˆà¸­à¸ªà¸£à¹‰à¸²à¸‡ feature vector:
# 1. Crop à¸£à¸¹à¸›à¸•à¸²à¸¡ bounding box à¸‚à¸­à¸‡ mask
# 2. Apply mask â†’ à¹€à¸­à¸²à¹€à¸‰à¸à¸²à¸° pixel à¸—à¸µà¹ˆà¹€à¸›à¹‡à¸™ object
# 3. à¸ªà¹ˆà¸‡à¸œà¹ˆà¸²à¸™ vision encoder â†’ à¹„à¸”à¹‰ embedding
# 4. Global Average Pooling â†’ à¹„à¸”à¹‰ vector 1 à¸¡à¸´à¸•à¸´

# %%
# ============================================================
# Step 5.3.1: à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¸ªà¸à¸±à¸” Feature à¸ˆà¸²à¸ Masked Region
# ============================================================

def extract_object_feature(image, mask, model, processor, device):
    """
    à¸ªà¸à¸±à¸” feature vector à¸ˆà¸²à¸ object à¸—à¸µà¹ˆà¸–à¸¹à¸ mask

    Args:
        image: PIL Image (RGB)
        mask: boolean numpy array (H, W) â€” True = object pixel
        model: Sam3Model
        processor: Sam3Processor
        device: "cuda" or "cpu"

    Returns:
        feature_vector: numpy array shape (D,) â€” feature à¸‚à¸­à¸‡ object
    """
    img_array = np.array(image)
    img_h, img_w = img_array.shape[:2]

    # --- Step A: à¸«à¸² bounding box à¸ˆà¸²à¸ mask ---
    ys, xs = np.where(mask)
    if len(ys) == 0:
        return np.zeros(256)  # empty mask â†’ zero vector

    x1, y1, x2, y2 = int(xs.min()), int(ys.min()), int(xs.max()), int(ys.max())

    # à¹€à¸à¸´à¹ˆà¸¡ padding 10% à¸£à¸­à¸š bounding box
    pad_x = int((x2 - x1) * 0.1)
    pad_y = int((y2 - y1) * 0.1)
    x1 = max(0, x1 - pad_x)
    y1 = max(0, y1 - pad_y)
    x2 = min(img_w, x2 + pad_x)
    y2 = min(img_h, y2 + pad_y)

    # --- Step B: Crop + Apply mask ---
    cropped = img_array[y1:y2, x1:x2].copy()
    mask_crop = mask[y1:y2, x1:x2]

    # à¸•à¸±à¹‰à¸‡ pixel à¸—à¸µà¹ˆà¹„à¸¡à¹ˆà¹ƒà¸Šà¹ˆ object à¹€à¸›à¹‡à¸™à¸ªà¸µà¸‚à¸²à¸§ (à¸¥à¸” noise à¸ˆà¸²à¸à¸à¸·à¹‰à¸™à¸«à¸¥à¸±à¸‡)
    cropped[~mask_crop] = 255

    crop_pil = PILImage.fromarray(cropped)

    # --- Step C: à¸ªà¹ˆà¸‡à¸œà¹ˆà¸²à¸™ Vision Encoder ---
    inputs = processor(images=crop_pil, return_tensors="pt").to(device)
    with torch.no_grad():
        vision_output = model.get_vision_features(
            pixel_values=inputs.pixel_values
        )

    # --- Step D: Global Average Pooling â†’ 1D vector ---
    # vision_output à¹€à¸›à¹‡à¸™ Sam3VisionEncoderOutput
    # à¸•à¹‰à¸­à¸‡à¸”à¸¶à¸‡ tensor à¸­à¸­à¸à¸¡à¸²à¸à¹ˆà¸­à¸™: à¹ƒà¸Šà¹‰ .last_hidden_state à¸«à¸£à¸·à¸­ [0]
    if hasattr(vision_output, "last_hidden_state"):
        vision_embeds = vision_output.last_hidden_state
    elif hasattr(vision_output, "image_features"):
        vision_embeds = vision_output.image_features
    else:
        # fallback: à¹ƒà¸Šà¹‰à¸•à¸±à¸§à¹à¸£à¸à¸ˆà¸²à¸ output tuple/object
        vision_embeds = vision_output[0]

    # vision_embeds shape: (1, num_tokens, hidden_dim)
    feature = vision_embeds.mean(dim=1).squeeze().cpu().numpy()

    return feature


print("âœ… à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™ extract_object_feature() à¸à¸£à¹‰à¸­à¸¡à¹ƒà¸Šà¹‰à¸‡à¸²à¸™")

# %%
# ============================================================
# Step 5.3.2: à¸ªà¸à¸±à¸” Feature à¸‚à¸­à¸‡ Query Object
# ============================================================
print("â³ à¸à¸³à¸¥à¸±à¸‡à¸ªà¸à¸±à¸” feature à¸ˆà¸²à¸ query object...")

query_feature = extract_object_feature(
    query_image, query_mask, model, processor, device
)

print(f"âœ… Query Feature Vector:")
print(f"   Shape     : {query_feature.shape}")
print(f"   Norm      : {np.linalg.norm(query_feature):.4f}")
print(f"   Min/Max   : {query_feature.min():.4f} / {query_feature.max():.4f}")
print(f"   First 5   : {query_feature[:5]}")

# %% [markdown]
# ---
# # ğŸŸ¢ Step 5.4: à¸„à¹‰à¸™à¸«à¸² Object à¸—à¸µà¹ˆà¸„à¸¥à¹‰à¸²à¸¢à¸à¸±à¸™à¸‚à¹‰à¸²à¸¡à¸£à¸¹à¸›à¸ à¸²à¸
#
# ### ğŸ¯ à¹€à¸›à¹‰à¸²à¸«à¸¡à¸²à¸¢
# 1. à¸§à¸™ loop à¸—à¸¸à¸à¸£à¸¹à¸›à¹ƒà¸™ gallery (à¸¢à¸à¹€à¸§à¹‰à¸™à¸£à¸¹à¸› query)
# 2. à¹ƒà¸Šà¹‰ text prompt à¹€à¸à¸·à¹ˆà¸­à¸«à¸² object à¹ƒà¸™à¹à¸•à¹ˆà¸¥à¸°à¸£à¸¹à¸›
# 3. à¸ªà¸à¸±à¸” feature â†’ à¸„à¸³à¸™à¸§à¸“ cosine similarity à¸à¸±à¸š query
# 4. à¹€à¸à¹‡à¸šà¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œà¹ƒà¸™ pandas DataFrame
#
# ### ğŸ’¡ Pipeline à¸ªà¸³à¸«à¸£à¸±à¸šà¹à¸•à¹ˆà¸¥à¸°à¸£à¸¹à¸›
# ```
# à¸£à¸¹à¸›à¹ƒà¸™ gallery
#     â†“
# SAM 3 Text Prompt ("egg") â†’ à¸«à¸² instances à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”
#     â†“
# à¹à¸•à¹ˆà¸¥à¸° instance â†’ à¸ªà¸à¸±à¸” feature
#     â†“
# Cosine Similarity à¸à¸±à¸š query feature
#     â†“
# à¸šà¸±à¸™à¸—à¸¶à¸à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œ
# ```

# %%
# ============================================================
# Step 5.4.1: à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¸„à¹‰à¸™à¸«à¸² Object à¹ƒà¸™à¸£à¸¹à¸›à¹€à¸”à¸µà¸¢à¸§
# ============================================================

def find_objects_in_image(image, text_prompt, model, processor, device):
    """
    à¹ƒà¸Šà¹‰ text prompt à¸«à¸² object à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”à¹ƒà¸™à¸£à¸¹à¸› à¹à¸¥à¹‰à¸§ return masks + features

    Args:
        image: PIL Image (RGB)
        text_prompt: à¸Šà¸·à¹ˆà¸­à¸­à¸²à¸«à¸²à¸£à¸—à¸µà¹ˆà¸ˆà¸°à¸„à¹‰à¸™à¸«à¸² (à¹€à¸Šà¹ˆà¸™ "egg")
        model: Sam3Model
        processor: Sam3Processor
        device: "cuda" or "cpu"

    Returns:
        list of dict: [{"mask": np.array, "score": float, "box": list, "feature": np.array}, ...]
    """
    # --- Preprocess ---
    inputs = processor(images=image, text=text_prompt, return_tensors="pt").to(device)

    # --- Inference ---
    with torch.no_grad():
        outputs = model(**inputs)

    # --- Postprocess ---
    results = processor.post_process_instance_segmentation(
        outputs,
        threshold=0.3,
        mask_threshold=0.5,
        target_sizes=inputs.get("original_sizes").tolist(),
    )[0]

    objects = []
    for mask_t, box_t, score_t in zip(
        results.get("masks", []),
        results.get("boxes", []),
        results.get("scores", []),
    ):
        mask_np = mask_t.cpu().numpy() if torch.is_tensor(mask_t) else np.array(mask_t)
        box_np = box_t.cpu().tolist() if torch.is_tensor(box_t) else list(box_t)
        score_val = score_t.item() if torch.is_tensor(score_t) else float(score_t)

        mask_bool = mask_np > 0
        if mask_bool.sum() < 100:  # à¸‚à¹‰à¸²à¸¡ mask à¸—à¸µà¹ˆà¹€à¸¥à¹‡à¸à¹€à¸à¸´à¸™à¹„à¸›
            continue

        # à¸ªà¸à¸±à¸” feature
        feat = extract_object_feature(image, mask_bool, model, processor, device)

        objects.append({
            "mask": mask_bool,
            "score": score_val,
            "box": box_np,
            "feature": feat,
        })

    return objects


print("âœ… à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™ find_objects_in_image() à¸à¸£à¹‰à¸­à¸¡à¹ƒà¸Šà¹‰à¸‡à¸²à¸™")

# %% [markdown]
# ---
# # ğŸŸ¡ Step 5.4.1+ : à¸ªà¸­à¸™à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ `find_objects_in_image()` à¹à¸šà¸šà¸—à¸µà¸¥à¸°à¸‚à¸±à¹‰à¸™
#
# ### ğŸ¯ à¹€à¸›à¹‰à¸²à¸«à¸¡à¸²à¸¢
# à¹€à¸‚à¹‰à¸²à¹ƒà¸ˆà¸§à¸´à¸˜à¸µà¸à¸²à¸£à¸—à¸³à¸‡à¸²à¸™à¸‚à¸­à¸‡à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™ `find_objects_in_image()` à¸­à¸¢à¹ˆà¸²à¸‡à¸¥à¸°à¹€à¸­à¸µà¸¢à¸”
# à¸à¹ˆà¸­à¸™à¸—à¸µà¹ˆà¸ˆà¸°à¸™à¸³à¹„à¸›à¹ƒà¸Šà¹‰à¹ƒà¸™ loop à¸„à¹‰à¸™à¸«à¸²à¸‚à¹‰à¸²à¸¡à¸£à¸¹à¸›à¸ à¸²à¸à¹ƒà¸™ Step 5.4.2
#
# ### ğŸ“– à¸—à¸³à¹„à¸¡à¸•à¹‰à¸­à¸‡à¹€à¸£à¸µà¸¢à¸™à¸£à¸¹à¹‰à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¸™à¸µà¹‰?
# à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™ `find_objects_in_image()` à¹€à¸›à¹‡à¸™ **à¸«à¸±à¸§à¹ƒà¸ˆà¸ªà¸³à¸„à¸±à¸** à¸‚à¸­à¸‡ pipeline à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”
# à¹€à¸à¸£à¸²à¸°à¸¡à¸±à¸™à¸£à¸§à¸¡ 3 à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¹ƒà¸«à¸à¹ˆà¹„à¸§à¹‰à¹ƒà¸™à¸—à¸µà¹ˆà¹€à¸”à¸µà¸¢à¸§:
#
# ```
# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
# â”‚  find_objects_in_image(image, text_prompt, model, ...)  â”‚
# â”‚                                                         â”‚
# â”‚  â‘  Text Prompt â†’ SAM 3 à¸«à¸² object à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”à¹ƒà¸™à¸£à¸¹à¸›          â”‚
# â”‚  â‘¡ Post-process â†’ à¹à¸¢à¸ mask, box, score à¸‚à¸­à¸‡à¹à¸•à¹ˆà¸¥à¸° object  â”‚
# â”‚  â‘¢ Feature Extraction â†’ à¸ªà¸à¸±à¸” embedding à¸ˆà¸²à¸à¹à¸•à¹ˆà¸¥à¸° object  â”‚
# â”‚                                                         â”‚
# â”‚  return: list of {"mask", "score", "box", "feature"}    â”‚
# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
# ```
#
# ### ğŸ“Œ Signature à¸‚à¸­à¸‡à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™
#
# ```python
# find_objects_in_image(
#     image,        # PIL Image (RGB) â€” à¸£à¸¹à¸›à¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸„à¹‰à¸™à¸«à¸²
#     text_prompt,  # str â€” à¸Šà¸·à¹ˆà¸­ object à¹€à¸Šà¹ˆà¸™ "egg", "rice", "tomato"
#     model,        # Sam3Model â€” à¹‚à¸¡à¹€à¸”à¸¥à¸«à¸¥à¸±à¸
#     processor,    # Sam3Processor â€” preprocessor
#     device        # str â€” "cuda" à¸«à¸£à¸·à¸­ "cpu"
# ) â†’ list[dict]
# ```
#
# ### ğŸ“Œ Output Format
# à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¸ˆà¸° return **list à¸‚à¸­à¸‡ dict** à¹‚à¸”à¸¢à¹à¸•à¹ˆà¸¥à¸° dict à¸„à¸·à¸­ 1 object à¸—à¸µà¹ˆà¸à¸š:
#
# | Key | Type | à¸„à¸³à¸­à¸˜à¸´à¸šà¸²à¸¢ |
# |-----|------|----------|
# | `"mask"` | `np.array (H,W) bool` | Boolean mask â€” True = pixel à¸—à¸µà¹ˆà¹€à¸›à¹‡à¸™ object |
# | `"score"` | `float` | à¸„à¹ˆà¸² confidence (0.0â€“1.0) à¸§à¹ˆà¸²à¸¡à¸±à¹ˆà¸™à¹ƒà¸ˆà¹à¸„à¹ˆà¹„à¸«à¸™à¸§à¹ˆà¸²à¹€à¸›à¹‡à¸™ object à¸™à¸±à¹‰à¸™ |
# | `"box"` | `list [x1,y1,x2,y2]` | Bounding box à¸‚à¸­à¸‡ object |
# | `"feature"` | `np.array (D,)` | Feature vector à¸ªà¸³à¸«à¸£à¸±à¸šà¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸š similarity |

# %%
# ============================================================
# Step 5.4.1a: à¸—à¸”à¸¥à¸­à¸‡à¹€à¸£à¸µà¸¢à¸à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¸à¸±à¸šà¸£à¸¹à¸›à¹€à¸”à¸µà¸¢à¸§
# ============================================================
# à¹€à¸¥à¸·à¸­à¸à¸£à¸¹à¸›à¸ˆà¸²à¸ gallery (à¹ƒà¸Šà¹‰à¸£à¸¹à¸›à¸—à¸µà¹ˆà¹„à¸¡à¹ˆà¹ƒà¸Šà¹ˆ query image) à¹à¸¥à¹‰à¸§à¸¥à¸­à¸‡à¸„à¹‰à¸™à¸«à¸²

TEST_GALLERY_ID = 1  # â¬…ï¸ à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹„à¸”à¹‰ (à¸¥à¸­à¸‡à¸£à¸¹à¸›à¸­à¸·à¹ˆà¸™à¹† à¸”à¸¹)

# --- à¹‚à¸«à¸¥à¸”à¸£à¸¹à¸› ---
test_row = df_gallery[df_gallery["gallery_id"] == TEST_GALLERY_ID].iloc[0]
test_image = ds[test_row["dataset_idx"]]["image"].convert("RGB")

print(f"ğŸ“· à¸—à¸”à¸ªà¸­à¸šà¸à¸±à¸š gallery_id={TEST_GALLERY_ID}")
print(f"   Food classes: {test_row['food_classes']}")
print(f"   Image size  : {test_image.size}")

# --- à¹€à¸£à¸µà¸¢à¸à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™ ---
print(f'\nâ³ à¹€à¸£à¸µà¸¢à¸ find_objects_in_image(image, "{TARGET_FOOD}", model, processor, device)...')
found_objects = find_objects_in_image(test_image, TARGET_FOOD, model, processor, device)

# --- à¹à¸ªà¸”à¸‡à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œ ---
print(f"\n{'='*60}")
print(f"âœ… à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œ: à¸à¸š {len(found_objects)} object(s)")
print(f"{'='*60}")

if len(found_objects) == 0:
    print("âŒ à¹„à¸¡à¹ˆà¸à¸š object à¹ƒà¸”à¹€à¸¥à¸¢ â€” à¸¥à¸­à¸‡à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™ TEST_GALLERY_ID à¸«à¸£à¸·à¸­ TARGET_FOOD")
else:
    for i, obj in enumerate(found_objects):
        print(f"\nğŸ“¦ Object #{i}:")
        print(f"   score   = {obj['score']:.4f}  (à¸„à¹ˆà¸² confidence)")
        print(f"   box     = {obj['box']}  (bounding box [x1,y1,x2,y2])")
        print(f"   mask    â†’ shape: {obj['mask'].shape}, pixels: {int(obj['mask'].sum()):,}")
        print(f"   feature â†’ shape: {obj['feature'].shape}, norm: {np.linalg.norm(obj['feature']):.4f}")

# %%
# ============================================================
# Step 5.4.1b: Visualize à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œà¸‚à¸­à¸‡à¹à¸•à¹ˆà¸¥à¸° Object à¸—à¸µà¹ˆà¸à¸š
# ============================================================
# à¹à¸ªà¸”à¸‡à¹à¸•à¹ˆà¸¥à¸° object à¸—à¸µà¹ˆà¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™ return à¸à¸¥à¸±à¸šà¸¡à¸²

if len(found_objects) > 0:
    n_objs = len(found_objects)
    fig, axes = plt.subplots(2, n_objs + 1, figsize=(5 * (n_objs + 1), 10))

    # à¸–à¹‰à¸²à¸¡à¸µ object à¹€à¸”à¸µà¸¢à¸§ à¸•à¹‰à¸­à¸‡à¹à¸›à¸¥à¸‡ axes à¹€à¸›à¹‡à¸™ 2D
    if n_objs == 1:
        axes = axes.reshape(2, -1)

    # --- Column 0: à¸£à¸¹à¸›à¸•à¹‰à¸™à¸‰à¸šà¸±à¸š ---
    axes[0, 0].imshow(test_image)
    axes[0, 0].set_title(f"ğŸ“· à¸£à¸¹à¸›à¸•à¹‰à¸™à¸‰à¸šà¸±à¸š\ngallery_id={TEST_GALLERY_ID}", fontsize=11, fontweight="bold")
    axes[0, 0].axis("off")

    # Row 1, Col 0: à¸£à¸¹à¸›à¸•à¹‰à¸™à¸‰à¸šà¸±à¸š + mask overlay à¸—à¸¸à¸ object
    axes[1, 0].imshow(test_image)
    colors_list = [(1, 0.2, 0.2, 0.4), (0.2, 1, 0.2, 0.4), (0.2, 0.2, 1, 0.4),
                   (1, 1, 0.2, 0.4), (1, 0.2, 1, 0.4)]
    for i, obj in enumerate(found_objects):
        overlay = np.zeros((*obj["mask"].shape, 4))
        overlay[obj["mask"]] = colors_list[i % len(colors_list)]
        axes[1, 0].imshow(overlay)
    axes[1, 0].set_title(f"ğŸ¨ à¸—à¸¸à¸ Object à¸£à¸§à¸¡à¸à¸±à¸™\n({n_objs} objects)", fontsize=11, fontweight="bold")
    axes[1, 0].axis("off")

    # --- à¹à¸•à¹ˆà¸¥à¸° Object ---
    test_arr = np.array(test_image)
    for i, obj in enumerate(found_objects):
        col = i + 1

        # Row 0: Mask à¸‚à¸­à¸‡ object
        axes[0, col].imshow(obj["mask"], cmap="gray")
        box = obj["box"]
        rect = patches.Rectangle(
            (box[0], box[1]), box[2] - box[0], box[3] - box[1],
            linewidth=2, edgecolor="lime", facecolor="none"
        )
        axes[0, col].add_patch(rect)
        axes[0, col].set_title(
            f"Object #{i} â€” Mask\nscore: {obj['score']:.4f}",
            fontsize=10, fontweight="bold"
        )
        axes[0, col].axis("off")

        # Row 1: Extracted object (à¸•à¸±à¸”à¸à¸·à¹‰à¸™à¸«à¸¥à¸±à¸‡à¸­à¸­à¸)
        canvas = np.ones_like(test_arr) * 255
        canvas[obj["mask"]] = test_arr[obj["mask"]]
        axes[1, col].imshow(canvas)
        axes[1, col].set_title(
            f"Object #{i} â€” Extracted\nfeature norm: {np.linalg.norm(obj['feature']):.2f}",
            fontsize=10
        )
        axes[1, col].axis("off")

    plt.suptitle(
        f'ğŸ”¬ find_objects_in_image() à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œ: à¸„à¹‰à¸™à¸«à¸² "{TARGET_FOOD}" à¹ƒà¸™ gallery_id={TEST_GALLERY_ID}\n'
        f'à¸à¸š {n_objs} object(s)',
        fontsize=14, fontweight="bold"
    )
    plt.tight_layout()
    plt.show()
else:
    print("âš ï¸ à¹„à¸¡à¹ˆà¸¡à¸µ object à¹ƒà¸«à¹‰à¹à¸ªà¸”à¸‡à¸œà¸¥ â€” à¸¥à¸­à¸‡à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™ TEST_GALLERY_ID")

# %%
# ============================================================
# Step 5.4.1c: à¸—à¸”à¸¥à¸­à¸‡à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸š Similarity à¸à¸±à¸š Query Object
# ============================================================
# à¸•à¸­à¸™à¸™à¸µà¹‰à¹€à¸£à¸²à¸¡à¸µ query_feature à¸ˆà¸²à¸ Step 5.3 à¹à¸¥à¹‰à¸§
# à¸¥à¸­à¸‡à¸™à¸³ feature à¸‚à¸­à¸‡ object à¸—à¸µà¹ˆà¸à¸šà¸¡à¸²à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸šà¸à¸±à¸š query à¸”à¸¹

if len(found_objects) > 0:
    print(f"ğŸ“Š à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸š Cosine Similarity: Query Object vs Objects à¹ƒà¸™ gallery_id={TEST_GALLERY_ID}")
    print(f"{'='*70}")
    print(f"{'Object':>8} | {'Score':>8} | {'Similarity':>12} | {'à¸£à¸°à¸”à¸±à¸š':>10} | {'Mask Pixels':>12}")
    print(f"{'-'*8}-+-{'-'*8}-+-{'-'*12}-+-{'-'*10}-+-{'-'*12}")

    for i, obj in enumerate(found_objects):
        # à¸„à¸³à¸™à¸§à¸“ cosine similarity
        sim = cosine_similarity(
            query_feature.reshape(1, -1),
            obj["feature"].reshape(1, -1)
        )[0, 0]

        # à¸à¸³à¸«à¸™à¸”à¸£à¸°à¸”à¸±à¸š
        if sim > 0.85:
            level = "ğŸŸ¢ High"
        elif sim > 0.70:
            level = "ğŸŸ¡ Medium"
        else:
            level = "ğŸ”´ Low"

        print(f"  #{i:>5} | {obj['score']:>8.4f} | {sim:>12.4f} | {level:>10} | {int(obj['mask'].sum()):>12,}")

    print(f"\nğŸ’¡ Similarity à¸ªà¸¹à¸‡ â†’ object à¸™à¸±à¹‰à¸™à¸¡à¸µà¸¥à¸±à¸à¸©à¸“à¸°à¸„à¸¥à¹‰à¸²à¸¢à¸à¸±à¸š query object à¸‚à¸­à¸‡à¹€à¸£à¸²")
    print(f"ğŸ’¡ Similarity à¸•à¹ˆà¸³ â†’ à¸­à¸²à¸ˆà¹€à¸›à¹‡à¸™à¸„à¸™à¸¥à¸°à¸Šà¸™à¸´à¸” à¸«à¸£à¸·à¸­à¸¡à¸¸à¸¡à¸¡à¸­à¸‡/à¸‚à¸™à¸²à¸”à¸•à¹ˆà¸²à¸‡à¸à¸±à¸™à¸¡à¸²à¸")

# %% [markdown]
# ---
# ### ğŸ“ à¸ªà¸£à¸¸à¸›à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ `find_objects_in_image()`
#
# #### âœ… à¸§à¸´à¸˜à¸µà¹€à¸£à¸µà¸¢à¸à¹ƒà¸Šà¹‰
# ```python
# # 1. à¹€à¸•à¸£à¸µà¸¢à¸¡ input
# image = ds[idx]["image"].convert("RGB")  # PIL Image
# text_prompt = "egg"                       # à¸Šà¸·à¹ˆà¸­ object à¸—à¸µà¹ˆà¸ˆà¸°à¸„à¹‰à¸™à¸«à¸²
#
# # 2. à¹€à¸£à¸µà¸¢à¸à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™
# objects = find_objects_in_image(image, text_prompt, model, processor, device)
#
# # 3. à¹ƒà¸Šà¹‰à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œ
# for obj in objects:
#     mask    = obj["mask"]      # boolean mask (H, W)
#     score   = obj["score"]     # confidence 0.0â€“1.0
#     box     = obj["box"]       # [x1, y1, x2, y2]
#     feature = obj["feature"]   # feature vector à¸ªà¸³à¸«à¸£à¸±à¸š similarity
# ```
#
# #### âš ï¸ à¸à¸£à¸“à¸µà¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸£à¸°à¸§à¸±à¸‡
#
# | à¸à¸£à¸“à¸µ | à¸ªà¸´à¹ˆà¸‡à¸—à¸µà¹ˆà¹€à¸à¸´à¸”à¸‚à¸¶à¹‰à¸™ | à¸§à¸´à¸˜à¸µà¹à¸à¹‰ |
# |------|----------------|--------|
# | à¹„à¸¡à¹ˆà¸à¸š object à¹€à¸¥à¸¢ | return `[]` (list à¸§à¹ˆà¸²à¸‡) | à¸¥à¸­à¸‡à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™ text_prompt à¸«à¸£à¸·à¸­à¸¥à¸” threshold |
# | à¸à¸šà¸«à¸¥à¸²à¸¢ object | return list à¸«à¸¥à¸²à¸¢ dict | à¸§à¸™ loop à¸”à¸¹à¸—à¸µà¸¥à¸°à¸•à¸±à¸§ |
# | Mask à¹€à¸¥à¹‡à¸à¹€à¸à¸´à¸™à¹„à¸› (<100 px) | à¸–à¸¹à¸à¸à¸£à¸­à¸‡à¸­à¸­à¸à¸­à¸±à¸•à¹‚à¸™à¸¡à¸±à¸•à¸´ | à¸›à¸à¸•à¸´à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¹à¸à¹‰ |
# | Feature à¹€à¸›à¹‡à¸™ zero vector | mask à¸§à¹ˆà¸²à¸‡à¹€à¸›à¸¥à¹ˆà¸² | à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š mask à¸à¹ˆà¸­à¸™à¹ƒà¸Šà¹‰ feature |
#
# #### ğŸ§ª à¸¥à¸­à¸‡à¸—à¸”à¸¥à¸­à¸‡à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¸„à¹ˆà¸²
# 1. à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™ `TEST_GALLERY_ID` â†’ à¸”à¸¹à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œà¸à¸±à¸šà¸£à¸¹à¸›à¸­à¸·à¹ˆà¸™
# 2. à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™ `TARGET_FOOD` à¹€à¸›à¹‡à¸™ `"rice"`, `"tomato"` â†’ à¸„à¹‰à¸™à¸«à¸² object à¸­à¸·à¹ˆà¸™
# 3. à¸ªà¸±à¸‡à¹€à¸à¸•à¸§à¹ˆà¸² score à¸ªà¸¹à¸‡ â‰  similarity à¸ªà¸¹à¸‡ à¹€à¸ªà¸¡à¸­à¹„à¸› (score = à¸„à¸§à¸²à¸¡à¸¡à¸±à¹ˆà¸™à¹ƒà¸ˆà¸§à¹ˆà¸²à¹€à¸ˆà¸­, similarity = à¸„à¸§à¸²à¸¡à¸„à¸¥à¹‰à¸²à¸¢)

# %%
# ============================================================
# Step 5.4.1d: ğŸ§ª à¸—à¸”à¸¥à¸­à¸‡à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™ text_prompt (à¸‚à¸±à¹‰à¸™à¸ªà¸¹à¸‡)
# ============================================================
# à¸¥à¸­à¸‡à¸„à¹‰à¸™à¸«à¸²à¸”à¹‰à¸§à¸¢ text prompt à¸—à¸µà¹ˆà¸•à¹ˆà¸²à¸‡à¸à¸±à¸™ à¹€à¸à¸·à¹ˆà¸­à¸”à¸¹à¸§à¹ˆà¸²à¸œà¸¥à¸•à¹ˆà¸²à¸‡à¸à¸±à¸™à¸­à¸¢à¹ˆà¸²à¸‡à¹„à¸£

PROMPTS_TO_TRY = ["egg", "rice", "tomato"]  # â¬…ï¸ à¹€à¸à¸´à¹ˆà¸¡/à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹„à¸”à¹‰

# à¹ƒà¸Šà¹‰à¸£à¸¹à¸›à¹€à¸”à¸´à¸¡ (TEST_GALLERY_ID)
print(f"ğŸ“· à¸—à¸”à¸ªà¸­à¸šà¸«à¸¥à¸²à¸¢ text prompts à¸à¸±à¸š gallery_id={TEST_GALLERY_ID}")
print(f"   Food classes à¹ƒà¸™à¸£à¸¹à¸›: {test_row['food_classes']}\n")

prompt_results = {}
for prompt in PROMPTS_TO_TRY:
    objs = find_objects_in_image(test_image, prompt, model, processor, device)
    prompt_results[prompt] = objs
    status = f"âœ… à¸à¸š {len(objs)} object(s)" if len(objs) > 0 else "âŒ à¹„à¸¡à¹ˆà¸à¸š"
    print(f'   ğŸ” text_prompt="{prompt:>10}" â†’ {status}')
    for j, o in enumerate(objs):
        print(f'      â””â”€ obj#{j}: score={o["score"]:.4f}, mask_pixels={int(o["mask"].sum()):,}')

print(f"\nğŸ’¡ à¸ªà¸±à¸‡à¹€à¸à¸•: text_prompt à¸—à¸µà¹ˆà¸•à¸£à¸‡à¸à¸±à¸š food à¹ƒà¸™à¸£à¸¹à¸›à¸ˆà¸°à¸à¸š object à¹„à¸”à¹‰")
print(f"ğŸ’¡ text_prompt à¸—à¸µà¹ˆà¹„à¸¡à¹ˆà¸•à¸£à¸‡à¸ˆà¸° return list à¸§à¹ˆà¸²à¸‡ []")

# %% [markdown]
# ---
# #### âœ… à¸à¸£à¹‰à¸­à¸¡à¹à¸¥à¹‰à¸§! à¹€à¸‚à¹‰à¸²à¸ªà¸¹à¹ˆ Step 5.4.2 â€” à¸„à¹‰à¸™à¸«à¸²à¸‚à¹‰à¸²à¸¡à¸—à¸¸à¸à¸£à¸¹à¸›à¹ƒà¸™ Gallery
# à¸•à¸­à¸™à¸™à¸µà¹‰à¹€à¸£à¸²à¹€à¸‚à¹‰à¸²à¹ƒà¸ˆà¹à¸¥à¹‰à¸§à¸§à¹ˆà¸² `find_objects_in_image()` à¸—à¸³à¸‡à¸²à¸™à¸­à¸¢à¹ˆà¸²à¸‡à¹„à¸£
# à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸•à¹ˆà¸­à¹„à¸›à¸„à¸·à¸­à¸à¸²à¸£à¸™à¸³à¹„à¸›à¹ƒà¸Šà¹‰à¹ƒà¸™ loop à¹€à¸à¸·à¹ˆà¸­à¸„à¹‰à¸™à¸«à¸²à¸‚à¹‰à¸²à¸¡à¸—à¸¸à¸à¸£à¸¹à¸›à¹ƒà¸™ gallery

# %%
# ============================================================
# Step 5.4.2: à¸„à¹‰à¸™à¸«à¸²à¸‚à¹‰à¸²à¸¡à¸—à¸¸à¸à¸£à¸¹à¸›à¹ƒà¸™ Gallery
# ============================================================
# à¸§à¸™ loop à¸—à¸¸à¸à¸£à¸¹à¸› (à¸¢à¸à¹€à¸§à¹‰à¸™à¸£à¸¹à¸› query) à¹€à¸à¸·à¹ˆà¸­à¸«à¸² object à¸—à¸µà¹ˆà¸„à¸¥à¹‰à¸²à¸¢à¸à¸±à¸™

print(f'ğŸ” à¹€à¸£à¸´à¹ˆà¸¡à¸„à¹‰à¸™à¸«à¸² "{TARGET_FOOD}" à¸‚à¹‰à¸²à¸¡à¸£à¸¹à¸›à¸ à¸²à¸...')
print(f"   Query : gallery_id={SELECTED_GALLERY_ID}")
print(f"   Search: {len(df_gallery) - 1} à¸£à¸¹à¸›à¸—à¸µà¹ˆà¹€à¸«à¸¥à¸·à¸­\n")

search_results = []

for _, row in df_gallery.iterrows():
    gid = row["gallery_id"]

    # à¸‚à¹‰à¸²à¸¡à¸£à¸¹à¸› query
    if gid == SELECTED_GALLERY_ID:
        continue

    ds_idx = row["dataset_idx"]
    img = ds[ds_idx]["image"].convert("RGB")

    print(f"   ğŸ” gallery_id={gid:>2d} (ds_idx={ds_idx}) ...", end=" ")

    # --- à¸«à¸² objects ---
    objects = find_objects_in_image(img, TARGET_FOOD, model, processor, device)

    if len(objects) == 0:
        print("âŒ à¹„à¸¡à¹ˆà¸à¸š")
        continue

    # --- à¸„à¸³à¸™à¸§à¸“ Similarity à¸à¸±à¸š query ---
    for obj_i, obj in enumerate(objects):
        sim = cosine_similarity(
            query_feature.reshape(1, -1),
            obj["feature"].reshape(1, -1),
        )[0, 0]

        search_results.append({
            "gallery_id": gid,
            "dataset_idx": ds_idx,
            "object_idx": obj_i,
            "confidence": obj["score"],
            "similarity": float(sim),
            "mask_pixels": int(obj["mask"].sum()),
            "box": obj["box"],
            "mask": obj["mask"],          # à¹€à¸à¹‡à¸šà¹„à¸§à¹‰à¸ªà¸³à¸«à¸£à¸±à¸š visualization
            "feature": obj["feature"],
        })

    print(f"âœ… à¸à¸š {len(objects)} instance(s)")

print(f"\n{'='*50}")
print(f"âœ… à¸„à¹‰à¸™à¸«à¸²à¹€à¸ªà¸£à¹‡à¸ˆà¸ªà¸´à¹‰à¸™: à¸à¸š {len(search_results)} objects à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”")

# %%
# ============================================================
# Step 5.4.3: à¸ªà¸£à¹‰à¸²à¸‡ Similarity DataFrame
# ============================================================
# à¸ˆà¸±à¸”à¸­à¸±à¸™à¸”à¸±à¸šà¸œà¸¥à¸à¸²à¸£à¸„à¹‰à¸™à¸«à¸²à¸•à¸²à¸¡ similarity score

df_results = pd.DataFrame([
    {
        "rank": 0,
        "gallery_id": r["gallery_id"],
        "dataset_idx": r["dataset_idx"],
        "object_idx": r["object_idx"],
        "similarity": r["similarity"],
        "confidence": r["confidence"],
        "mask_pixels": r["mask_pixels"],
    }
    for r in search_results
])

# à¸ˆà¸±à¸”à¸­à¸±à¸™à¸”à¸±à¸šà¸•à¸²à¸¡ similarity (à¸¡à¸²à¸à¹„à¸›à¸™à¹‰à¸­à¸¢)
df_results = df_results.sort_values("similarity", ascending=False).reset_index(drop=True)
df_results["rank"] = df_results.index + 1

print("ğŸ“Š à¸œà¸¥à¸à¸²à¸£à¸„à¹‰à¸™à¸«à¸² (à¹€à¸£à¸µà¸¢à¸‡à¸•à¸²à¸¡ Similarity à¸ªà¸¹à¸‡ â†’ à¸•à¹ˆà¸³):")
print(df_results[["rank", "gallery_id", "similarity", "confidence", "mask_pixels"]].to_string(index=False))

# %% [markdown]
# ---
# # ğŸŸ¢ Step 5.5: à¹à¸ªà¸”à¸‡à¸œà¸¥ Similarity à¸‚à¹‰à¸²à¸¡à¸£à¸¹à¸›à¸ à¸²à¸
#
# ### ğŸ¯ à¹€à¸›à¹‰à¸²à¸«à¸¡à¸²à¸¢
# 1. à¹à¸ªà¸”à¸‡ Query Object à¹€à¸—à¸µà¸¢à¸šà¸à¸±à¸š Top-N objects à¸—à¸µà¹ˆà¸„à¸¥à¹‰à¸²à¸¢à¸—à¸µà¹ˆà¸ªà¸¸à¸”
# 2. à¹à¸ªà¸”à¸‡ similarity bar chart
# 3. à¹à¸ªà¸”à¸‡ similarity matrix

# %%
# ============================================================
# Step 5.5.1: à¹à¸ªà¸”à¸‡ Top-N Similar Objects
# ============================================================
TOP_N = min(8, len(search_results))

# --- à¸ˆà¸±à¸”à¹€à¸£à¸µà¸¢à¸‡ results à¸•à¸²à¸¡ similarity ---
sorted_results = sorted(search_results, key=lambda x: x["similarity"], reverse=True)

fig, axes = plt.subplots(2, TOP_N + 1, figsize=(4 * (TOP_N + 1), 9))

# === Row 0: à¸£à¸¹à¸›à¸•à¹‰à¸™à¸‰à¸šà¸±à¸š + à¸ˆà¸¸à¸”à¸—à¸µà¹ˆà¸„à¸¥à¸´à¸ / à¸£à¸¹à¸›à¸œà¸¥à¸à¸²à¸£à¸„à¹‰à¸™à¸«à¸² ===
# Query image
axes[0, 0].imshow(query_image)
axes[0, 0].scatter(CLICK_POINT[0], CLICK_POINT[1], c="lime", s=300, marker="*",
                   edgecolors="white", linewidths=2, zorder=5)
axes[0, 0].set_title("ğŸ¯ QUERY\n(à¸£à¸¹à¸›à¸—à¸µà¹ˆà¸„à¸¥à¸´à¸)", fontsize=10, fontweight="bold", color="blue")
axes[0, 0].axis("off")

# Query extracted object
canvas_q = np.ones_like(np.array(query_image)) * 255
canvas_q[query_mask] = np.array(query_image)[query_mask]
axes[1, 0].imshow(canvas_q)
axes[1, 0].set_title("Query Object", fontsize=10, fontweight="bold", color="blue")
axes[1, 0].axis("off")

# Top-N results
for i in range(TOP_N):
    res = sorted_results[i]
    gid = res["gallery_id"]
    ds_idx = res["dataset_idx"]
    sim = res["similarity"]
    mask = res["mask"]
    img = ds[ds_idx]["image"].convert("RGB")
    img_arr = np.array(img)

    # Row 0: à¸£à¸¹à¸›à¸•à¹‰à¸™à¸‰à¸šà¸±à¸š + mask overlay
    axes[0, i + 1].imshow(img)
    overlay = np.zeros((*mask.shape, 4))
    overlay[mask] = [1, 0.2, 0.2, 0.5]
    axes[0, i + 1].imshow(overlay)

    # à¸ªà¸µà¸•à¸²à¸¡ similarity
    color = "green" if sim > 0.85 else "orange" if sim > 0.7 else "red"
    axes[0, i + 1].set_title(f"#{i+1} gid={gid}\nSim: {sim:.3f}",
                              fontsize=9, fontweight="bold", color=color)
    axes[0, i + 1].axis("off")

    # Row 1: Extracted object
    canvas = np.ones_like(img_arr) * 255
    canvas[mask] = img_arr[mask]
    axes[1, i + 1].imshow(canvas)
    axes[1, i + 1].set_title(f"Extracted Object", fontsize=9)
    axes[1, i + 1].axis("off")

plt.suptitle(f'ğŸ” Object Search Results â€” Query: "{TARGET_FOOD}" à¸„à¸¥à¸´à¸à¸—à¸µà¹ˆ ({CLICK_POINT[0]}, {CLICK_POINT[1]})\n'
             f'à¹à¸ªà¸”à¸‡ Top-{TOP_N} à¸ˆà¸²à¸ {len(search_results)} objects à¸—à¸µà¹ˆà¸à¸š',
             fontsize=14, fontweight="bold")
plt.tight_layout()
plt.show()

# %%
# ============================================================
# Step 5.5.2: Similarity Bar Chart
# ============================================================
fig, ax = plt.subplots(figsize=(12, 5))

# à¹€à¸•à¸£à¸µà¸¢à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥
labels = [f"gid={r['gallery_id']}\nobj#{r['object_idx']}" for r in sorted_results[:TOP_N]]
sims = [r["similarity"] for r in sorted_results[:TOP_N]]
colors = ["#2ecc71" if s > 0.85 else "#f39c12" if s > 0.7 else "#e74c3c" for s in sims]

bars = ax.barh(range(len(labels)), sims, color=colors, edgecolor="white", height=0.6)

# à¹€à¸à¸´à¹ˆà¸¡ value labels
for bar, sim in zip(bars, sims):
    ax.text(bar.get_width() + 0.005, bar.get_y() + bar.get_height() / 2,
            f"{sim:.4f}", va="center", fontsize=10, fontweight="bold")

ax.set_yticks(range(len(labels)))
ax.set_yticklabels(labels, fontsize=9)
ax.set_xlabel("Cosine Similarity", fontsize=12)
ax.set_title(f'ğŸ“Š Similarity Ranking â€” Query Object from gallery_id={SELECTED_GALLERY_ID}',
             fontsize=14, fontweight="bold")
ax.set_xlim(0, 1.1)
ax.invert_yaxis()

# Legend
from matplotlib.patches import Patch
legend_elements = [
    Patch(facecolor="#2ecc71", label="High (> 0.85)"),
    Patch(facecolor="#f39c12", label="Medium (0.70â€“0.85)"),
    Patch(facecolor="#e74c3c", label="Low (< 0.70)"),
]
ax.legend(handles=legend_elements, loc="lower right", fontsize=9)

plt.tight_layout()
plt.show()

# %%
# ============================================================
# Step 5.5.3: Similarity Heatmap à¸‚à¹‰à¸²à¸¡à¸£à¸¹à¸› (Cross-Image Matrix)
# ============================================================
# à¸ªà¸£à¹‰à¸²à¸‡ similarity matrix à¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡ query à¸à¸±à¸š top results

n_show = min(TOP_N, 10)
top_features = [query_feature] + [r["feature"] for r in sorted_results[:n_show]]
top_labels = [f"Query\n(gid={SELECTED_GALLERY_ID})"] + \
             [f"gid={r['gallery_id']}\nobj#{r['object_idx']}" for r in sorted_results[:n_show]]

# à¸„à¸³à¸™à¸§à¸“ pairwise similarity matrix
feat_matrix = np.stack(top_features)
sim_matrix = cosine_similarity(feat_matrix)

fig, ax = plt.subplots(figsize=(10, 8))
im = ax.imshow(sim_matrix, cmap="YlOrRd", vmin=0.5, vmax=1.0)
plt.colorbar(im, ax=ax, label="Cosine Similarity")

# Labels
ax.set_xticks(range(len(top_labels)))
ax.set_yticks(range(len(top_labels)))
ax.set_xticklabels(top_labels, fontsize=8, rotation=45, ha="right")
ax.set_yticklabels(top_labels, fontsize=8)

# à¹ƒà¸ªà¹ˆà¸•à¸±à¸§à¹€à¸¥à¸‚à¹ƒà¸™à¹à¸•à¹ˆà¸¥à¸° cell
for i in range(len(top_labels)):
    for j in range(len(top_labels)):
        color = "white" if sim_matrix[i, j] > 0.85 else "black"
        ax.text(j, i, f"{sim_matrix[i, j]:.3f}", ha="center", va="center",
                fontsize=8, color=color, fontweight="bold")

ax.set_title(f"ğŸ—ºï¸ Cross-Image Similarity Matrix\n"
             f'Query: "{TARGET_FOOD}" à¸ˆà¸²à¸ gallery_id={SELECTED_GALLERY_ID}',
             fontsize=14, fontweight="bold")
plt.tight_layout()
plt.show()

# %%
# ============================================================
# Step 5.5.4: à¸ªà¸£à¸¸à¸›à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œà¹ƒà¸™ DataFrame
# ============================================================
print("=" * 70)
print(f'ğŸ“‹ à¸ªà¸£à¸¸à¸›à¸œà¸¥à¸à¸²à¸£à¸„à¹‰à¸™à¸«à¸² Object: "{TARGET_FOOD}"')
print(f"   Query Image    : gallery_id={SELECTED_GALLERY_ID}")
print(f"   Click Position : ({CLICK_POINT[0]}, {CLICK_POINT[1]})")
print(f"   Objects Found  : {len(search_results)} à¹ƒà¸™ {len(df_gallery) - 1} à¸£à¸¹à¸›")
print("=" * 70)

# à¹à¸ªà¸”à¸‡ DataFrame à¸ªà¸£à¸¸à¸›
df_summary = df_results[["rank", "gallery_id", "similarity", "confidence", "mask_pixels"]].copy()
df_summary["similarity_level"] = df_summary["similarity"].apply(
    lambda s: "ğŸŸ¢ High" if s > 0.85 else "ğŸŸ¡ Medium" if s > 0.7 else "ğŸ”´ Low"
)

print("\nğŸ“Š Similarity Ranking Table:")
print(df_summary.to_string(index=False))

# %%
# ============================================================
# Step 5.5.5: Detailed Side-by-Side: Query vs Best Match
# ============================================================
if len(sorted_results) > 0:
    best = sorted_results[0]
    best_img = ds[best["dataset_idx"]]["image"].convert("RGB")
    best_arr = np.array(best_img)
    best_mask = best["mask"]

    fig, axes = plt.subplots(1, 4, figsize=(24, 6))

    # Panel 1: Query Image
    axes[0].imshow(query_image)
    axes[0].scatter(CLICK_POINT[0], CLICK_POINT[1], c="lime", s=400, marker="*",
                    edgecolors="white", linewidths=2, zorder=5)
    axes[0].set_title(f"ğŸ¯ Query Image (gid={SELECTED_GALLERY_ID})", fontsize=12)
    axes[0].axis("off")

    # Panel 2: Query Object (extracted)
    canvas_q = np.ones_like(np.array(query_image)) * 255
    canvas_q[query_mask] = np.array(query_image)[query_mask]
    axes[1].imshow(canvas_q)
    axes[1].set_title("Query Object", fontsize=12)
    axes[1].axis("off")

    # Panel 3: Best Match Image
    axes[2].imshow(best_img)
    overlay = np.zeros((*best_mask.shape, 4))
    overlay[best_mask] = [0, 1, 0, 0.45]
    axes[2].imshow(overlay)
    axes[2].set_title(f"ğŸ† Best Match (gid={best['gallery_id']})", fontsize=12)
    axes[2].axis("off")

    # Panel 4: Best Match Object (extracted)
    canvas_b = np.ones_like(best_arr) * 255
    canvas_b[best_mask] = best_arr[best_mask]
    axes[3].imshow(canvas_b)
    axes[3].set_title(f"Best Match Object\nSimilarity: {best['similarity']:.4f}", fontsize=12)
    axes[3].axis("off")

    plt.suptitle(f"ğŸ” Query vs Best Match â€” Cosine Similarity: {best['similarity']:.4f}",
                 fontsize=16, fontweight="bold")
    plt.tight_layout()
    plt.show()

# %% [markdown]
# ---
# # ğŸ“ Lab 5 Summary
#
# ## à¸ªà¸´à¹ˆà¸‡à¸—à¸µà¹ˆà¹„à¸”à¹‰à¹€à¸£à¸µà¸¢à¸™à¸£à¸¹à¹‰
#
# | Step | à¸«à¸±à¸§à¸‚à¹‰à¸­ | Key Takeaway |
# |------|--------|--------------|
# | **5.1** | Setup & Gallery | à¸ªà¸£à¹‰à¸²à¸‡ pandas DataFrame à¹€à¸›à¹‡à¸™ image gallery à¸ªà¸³à¸«à¸£à¸±à¸šà¹€à¸¥à¸·à¸­à¸à¸£à¸¹à¸› |
# | **5.2** | Point Click | à¸„à¸¥à¸´à¸ (x,y) â†’ SAM 3 segment â†’ à¹„à¸”à¹‰ mask à¸‚à¸­à¸‡ object |
# | **5.3** | Feature Extraction | à¹ƒà¸Šà¹‰ SAM 3 Vision Encoder à¸ªà¸à¸±à¸” feature vector à¸ˆà¸²à¸ masked object |
# | **5.4** | Cross-Image Search | à¸§à¸™ loop à¸„à¹‰à¸™à¸«à¸² object à¸„à¸¥à¹‰à¸²à¸¢à¹† à¸à¸±à¸™à¹ƒà¸™à¸£à¸¹à¸›à¸­à¸·à¹ˆà¸™ à¸”à¹‰à¸§à¸¢ cosine similarity |
# | **5.5** | Visualization | à¹à¸ªà¸”à¸‡à¸œà¸¥à¹€à¸›à¹‡à¸™ ranking, bar chart, heatmap |
#
# ## Pipeline à¸ªà¸£à¸¸à¸›
#
# ```
# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
# â”‚ à¹€à¸¥à¸·à¸­à¸à¸£à¸¹à¸›à¸ˆà¸²à¸  â”‚ â†’  â”‚ à¸„à¸¥à¸´à¸ point    â”‚ â†’  â”‚ SAM 3 Segment  â”‚
# â”‚ pandas galleryâ”‚    â”‚ à¸šà¸™ object     â”‚    â”‚ â†’ mask + crop  â”‚
# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
#                                                  â”‚
#                                                  â–¼
# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
# â”‚ à¸ˆà¸±à¸”à¸­à¸±à¸™à¸”à¸±à¸š    â”‚ â†  â”‚ Cosine        â”‚ â†  â”‚ Vision Encoder â”‚
# â”‚ Similarity   â”‚    â”‚ Similarity    â”‚    â”‚ â†’ Feature Vec  â”‚
# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
# ```
#
# ## ğŸ§ª à¸¥à¸­à¸‡à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¸„à¹ˆà¸²à¸”à¸¹!
#
# 1. à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™ `TARGET_FOOD = "rice"` à¸«à¸£à¸·à¸­ `"tomato"` â†’ à¸„à¹‰à¸™à¸«à¸² object à¸Šà¸™à¸´à¸”à¸­à¸·à¹ˆà¸™
# 2. à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™ `SELECTED_GALLERY_ID` â†’ à¹€à¸¥à¸·à¸­à¸à¸£à¸¹à¸›à¸­à¸·à¹ˆà¸™à¹€à¸›à¹‡à¸™ query
# 3. à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™ `CLICK_POINT` â†’ à¸„à¸¥à¸´à¸à¸—à¸µà¹ˆ object à¸­à¸·à¹ˆà¸™à¹ƒà¸™à¸£à¸¹à¸›à¹€à¸”à¸µà¸¢à¸§à¸à¸±à¸™
# 4. à¹€à¸à¸´à¹ˆà¸¡ `MAX_GALLERY = 50` â†’ à¸„à¹‰à¸™à¸«à¸²à¹ƒà¸™ gallery à¸—à¸µà¹ˆà¹ƒà¸«à¸à¹ˆà¸‚à¸¶à¹‰à¸™
# 5. à¸¥à¸­à¸‡ threshold à¸­à¸·à¹ˆà¸™ à¹€à¸Šà¹ˆà¸™ `threshold=0.1` â†’ à¸”à¸¹à¸§à¹ˆà¸²à¹€à¸ˆà¸­ object à¹€à¸à¸´à¹ˆà¸¡à¹„à¸«à¸¡
