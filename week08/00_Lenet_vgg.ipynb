{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Lenet:\n",
    "\n",
    "Lenet 5 is considered as the first architecture for Convolutional Neural Networks, which are used to identify handwritten digits in the zip codes in the US. It was introduced in the paper, “Gradient-Based Learning Applied To Document Recognition.”\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1400/0*VjXufJUfN2q3B-j8.jpg\" alt=\"alt\" width=\"50%\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lenet(\n",
       "  (tanh): Tanh()\n",
       "  (pool): AvgPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0)\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv3): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (linear1): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (linear2): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Lenet(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Lenet,self).__init__()\n",
    "    self.tanh = nn.Tanh()      \n",
    "    self.pool = nn.AvgPool2d(kernel_size=(2,2),stride=(2,2))\n",
    "    self.conv1 = nn.Conv2d(in_channels=1,out_channels=6,kernel_size=(5,5),stride=(1,1))\n",
    "    self.conv2 = nn.Conv2d(in_channels=6,out_channels=16,kernel_size=(5,5),stride=(1,1))\n",
    "    self.conv3 = nn.Conv2d(in_channels=16,out_channels=120,kernel_size=(5,5),stride=(1,1))\n",
    "    self.linear1 = nn.Linear(120,84)\n",
    "    self.linear2 = nn.Linear(84,10)\n",
    "\n",
    "  def forward(self,x):\n",
    "    x = self.tanh(self.conv1(x))\n",
    "    x = self.pool(x)\n",
    "    x = self.tanh(self.conv2(x))\n",
    "    x = self.pool(x)\n",
    "    x = self.tanh(self.conv3(x))\n",
    "    x = x.reshape(x.shape[0],-1)\n",
    "    x = self.tanh(self.linear1(x))\n",
    "    x = self.linear2(x)\n",
    "    return x\n",
    "\n",
    "model = Lenet()\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.rand(1,1,32,32)\n",
    "\n",
    "model(input).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "├─Tanh: 1-1                              --\n",
      "├─AvgPool2d: 1-2                         --\n",
      "├─Conv2d: 1-3                            156\n",
      "├─Conv2d: 1-4                            2,416\n",
      "├─Conv2d: 1-5                            48,120\n",
      "├─Linear: 1-6                            10,164\n",
      "├─Linear: 1-7                            850\n",
      "=================================================================\n",
      "Total params: 61,706\n",
      "Trainable params: 61,706\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "├─Tanh: 1-1                              --\n",
       "├─AvgPool2d: 1-2                         --\n",
       "├─Conv2d: 1-3                            156\n",
       "├─Conv2d: 1-4                            2,416\n",
       "├─Conv2d: 1-5                            48,120\n",
       "├─Linear: 1-6                            10,164\n",
       "├─Linear: 1-7                            850\n",
       "=================================================================\n",
       "Total params: 61,706\n",
       "Trainable params: 61,706\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchsummary import summary \n",
    "\n",
    "summary(model, input_size = (1,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (c1): Conv2d(3, 96, kernel_size=(11, 11), stride=(4, 4))\n",
       "  (c2): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (c3): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (c4): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (c5): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "  (fc2): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (fc3): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  (localnorm): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=1.0)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, in_channels=3, classes=1000):\n",
    "        super().__init__()\n",
    "        self.c1 = nn.Conv2d(in_channels=3, out_channels=96, kernel_size=11, stride=4, padding=0)\n",
    "        self.c2 = nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, stride=1, padding=2)\n",
    "        self.c3 = nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, stride=1, padding=1)\n",
    "        self.c4 = nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, stride=1, padding=1)\n",
    "        self.c5 = nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.fc1 = nn.Linear(6*6*256, 4096)\n",
    "        self.fc2 = nn.Linear(4096, 4096)\n",
    "        self.fc3 = nn.Linear(4096, classes)\n",
    "\n",
    "        self.localnorm = nn.LocalResponseNorm(size=5)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "      \n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [batch, 3, 227, 227]\n",
    "        x = self.relu(self.c1(x))\n",
    "        # x shape: [batch, 96, 55, 55]\n",
    "        x = self.maxpool(self.localnorm(x))\n",
    "        # x shape: [batch, 96, 27, 27]\n",
    "        x = self.relu(self.c2(x))\n",
    "        # x shape: [batch, 256, 27, 27]\n",
    "        x = self.maxpool(self.localnorm(x))\n",
    "        # x shape: [batch, 256, 13, 13]\n",
    "        x = self.relu(self.c3(x))\n",
    "        # x shape: [batch, 384, 13, 13]\n",
    "        x = self.relu(self.c4(x))\n",
    "        # x shape: [batch, 384, 13, 13]\n",
    "        x = self.maxpool(self.relu(self.c5(x)))\n",
    "        # x shape: [batch, 256, 6, 6]\n",
    "        x = torch.flatten(x,1)\n",
    "        # x shape: [batch, 256*6*6]\n",
    "        x = self.relu(self.dropout(self.fc1(x)))\n",
    "        # x shape: [batch, 4096]\n",
    "        x = self.relu(self.dropout(self.fc2(x)))\n",
    "        # x shape: [batch, 4096]\n",
    "        x = self.fc3(x)\n",
    "        # x shape: [batch, classes]\n",
    "        return x\n",
    "\n",
    "\n",
    "model = AlexNet()\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1000])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.rand(1,3,227,227)\n",
    "\n",
    "model(input).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG:\n",
    "<img src=\"https://pytorch.org/assets/images/vgg.png\" alt=\"alt\" width=\"50%\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "configs = { \n",
    "        \"VGG11\" : [1,1,2,2,2], # 1x64, 1x128, 2x256, 2x512, 2x512\n",
    "        \"VGG13\" : [2,2,2,2,2], # 2x64, 2x128, 2x256, 2x512, 2x512\n",
    "        \"VGG16\" : [2,2,3,3,3], # 2x64, 2x128, 3x256, 3x512, 3x512\n",
    "        \"VGG19\" : [2,2,4,4,4]  # 2x64, 2x128, 4x256, 4x512, 4x512\n",
    "    }\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, no_layers):\n",
    "        super().__init__()\n",
    "        self.layers = [nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=1), nn.ReLU()]\n",
    "        for i in range(no_layers-1):\n",
    "            self.layers.append(nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=1))\n",
    "            self.layers.append(nn.ReLU())\n",
    "\n",
    "        self.layers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.seq = nn.Sequential(*self.layers)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.seq(x)\n",
    "\n",
    "class VGG(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        model_size : str,\n",
    "        in_channels : int = 3, \n",
    "        classes : int = 1000\n",
    "        ):\n",
    "        super().__init__()\n",
    "   \n",
    "        config = configs[model_size]\n",
    "        channels = [in_channels,64,128,256,512,512]\n",
    "        self.blocks = nn.ModuleList([])\n",
    "        for i in range(len(config)):\n",
    "            self.blocks.append(Block(channels[i], channels[i+1], config[i]))\n",
    "        \n",
    "        self.fc1 = nn.Linear(7*7*512, 4096)\n",
    "        self.fc2 = nn.Linear(4096, 4096)\n",
    "        self.fc3 = nn.Linear(4096, classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "\n",
    "        x = torch.flatten(x,1)\n",
    "        x = self.relu(self.dropout(self.fc1(x)))\n",
    "        x = self.relu(self.dropout(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (blocks): ModuleList(\n",
       "    (0): Block(\n",
       "      (seq): Sequential(\n",
       "        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): ReLU()\n",
       "        (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Block(\n",
       "      (seq): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): ReLU()\n",
       "        (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (2): Block(\n",
       "      (seq): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): ReLU()\n",
       "        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (5): ReLU()\n",
       "        (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (3): Block(\n",
       "      (seq): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): ReLU()\n",
       "        (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (5): ReLU()\n",
       "        (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (4): Block(\n",
       "      (seq): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): ReLU()\n",
       "        (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (5): ReLU()\n",
       "        (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc1): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "  (fc2): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (fc3): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = VGG(\"VGG16\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1000])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.rand(1,3,224,224)\n",
    "\n",
    "model(input).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "├─Tanh: 1-1                              --\n",
      "├─AvgPool2d: 1-2                         --\n",
      "├─Conv2d: 1-3                            156\n",
      "├─Conv2d: 1-4                            2,416\n",
      "├─Conv2d: 1-5                            48,120\n",
      "├─Linear: 1-6                            10,164\n",
      "├─Linear: 1-7                            850\n",
      "=================================================================\n",
      "Total params: 61,706\n",
      "Trainable params: 61,706\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "├─Tanh: 1-1                              --\n",
       "├─AvgPool2d: 1-2                         --\n",
       "├─Conv2d: 1-3                            156\n",
       "├─Conv2d: 1-4                            2,416\n",
       "├─Conv2d: 1-5                            48,120\n",
       "├─Linear: 1-6                            10,164\n",
       "├─Linear: 1-7                            850\n",
       "=================================================================\n",
       "Total params: 61,706\n",
       "Trainable params: 61,706\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchsummary import summary \n",
    "\n",
    "summary(model, input_size = (3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7288f315087fdb0a15835a979a50c8db3e0e21492381bafafe9d84f995bbb7dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
