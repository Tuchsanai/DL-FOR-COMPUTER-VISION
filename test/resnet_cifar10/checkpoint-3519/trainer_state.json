{
  "best_metric": 0.7437919974327087,
  "best_model_checkpoint": "./resnet_cifar10/checkpoint-2346",
  "epoch": 9.0,
  "eval_steps": 500,
  "global_step": 3519,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02557544757033248,
      "grad_norm": 6.560461044311523,
      "learning_rate": 0.0009974424552429667,
      "loss": 2.317,
      "step": 10
    },
    {
      "epoch": 0.05115089514066496,
      "grad_norm": 4.858614444732666,
      "learning_rate": 0.0009948849104859335,
      "loss": 1.8972,
      "step": 20
    },
    {
      "epoch": 0.07672634271099744,
      "grad_norm": 3.7562742233276367,
      "learning_rate": 0.0009923273657289002,
      "loss": 1.8483,
      "step": 30
    },
    {
      "epoch": 0.10230179028132992,
      "grad_norm": 3.120326042175293,
      "learning_rate": 0.000989769820971867,
      "loss": 1.6826,
      "step": 40
    },
    {
      "epoch": 0.1278772378516624,
      "grad_norm": 3.0544543266296387,
      "learning_rate": 0.0009872122762148339,
      "loss": 1.6543,
      "step": 50
    },
    {
      "epoch": 0.1534526854219949,
      "grad_norm": 3.704089403152466,
      "learning_rate": 0.0009846547314578005,
      "loss": 1.5913,
      "step": 60
    },
    {
      "epoch": 0.17902813299232737,
      "grad_norm": 3.1817946434020996,
      "learning_rate": 0.0009820971867007674,
      "loss": 1.5538,
      "step": 70
    },
    {
      "epoch": 0.20460358056265984,
      "grad_norm": 3.757596969604492,
      "learning_rate": 0.000979539641943734,
      "loss": 1.5739,
      "step": 80
    },
    {
      "epoch": 0.23017902813299232,
      "grad_norm": 2.931636333465576,
      "learning_rate": 0.000976982097186701,
      "loss": 1.5326,
      "step": 90
    },
    {
      "epoch": 0.2557544757033248,
      "grad_norm": 2.9103219509124756,
      "learning_rate": 0.0009744245524296675,
      "loss": 1.5629,
      "step": 100
    },
    {
      "epoch": 0.2813299232736573,
      "grad_norm": 4.329400539398193,
      "learning_rate": 0.0009718670076726343,
      "loss": 1.4493,
      "step": 110
    },
    {
      "epoch": 0.3069053708439898,
      "grad_norm": 2.3314871788024902,
      "learning_rate": 0.000969309462915601,
      "loss": 1.4526,
      "step": 120
    },
    {
      "epoch": 0.33248081841432225,
      "grad_norm": 4.193652153015137,
      "learning_rate": 0.0009667519181585678,
      "loss": 1.3622,
      "step": 130
    },
    {
      "epoch": 0.35805626598465473,
      "grad_norm": 2.440829038619995,
      "learning_rate": 0.0009641943734015346,
      "loss": 1.4034,
      "step": 140
    },
    {
      "epoch": 0.3836317135549872,
      "grad_norm": 3.6103391647338867,
      "learning_rate": 0.0009616368286445013,
      "loss": 1.3942,
      "step": 150
    },
    {
      "epoch": 0.4092071611253197,
      "grad_norm": 3.0756587982177734,
      "learning_rate": 0.0009590792838874681,
      "loss": 1.3761,
      "step": 160
    },
    {
      "epoch": 0.43478260869565216,
      "grad_norm": 2.746140480041504,
      "learning_rate": 0.0009565217391304348,
      "loss": 1.3243,
      "step": 170
    },
    {
      "epoch": 0.46035805626598464,
      "grad_norm": 5.0564680099487305,
      "learning_rate": 0.0009539641943734016,
      "loss": 1.3155,
      "step": 180
    },
    {
      "epoch": 0.4859335038363171,
      "grad_norm": 3.365220785140991,
      "learning_rate": 0.0009514066496163683,
      "loss": 1.3803,
      "step": 190
    },
    {
      "epoch": 0.5115089514066496,
      "grad_norm": 3.6780784130096436,
      "learning_rate": 0.0009488491048593351,
      "loss": 1.3148,
      "step": 200
    },
    {
      "epoch": 0.5370843989769821,
      "grad_norm": 3.811976909637451,
      "learning_rate": 0.0009462915601023018,
      "loss": 1.2461,
      "step": 210
    },
    {
      "epoch": 0.5626598465473146,
      "grad_norm": 2.9431912899017334,
      "learning_rate": 0.0009437340153452686,
      "loss": 1.2728,
      "step": 220
    },
    {
      "epoch": 0.5882352941176471,
      "grad_norm": 3.7507107257843018,
      "learning_rate": 0.0009411764705882353,
      "loss": 1.2185,
      "step": 230
    },
    {
      "epoch": 0.6138107416879796,
      "grad_norm": 3.129167079925537,
      "learning_rate": 0.0009386189258312021,
      "loss": 1.235,
      "step": 240
    },
    {
      "epoch": 0.639386189258312,
      "grad_norm": 4.862919807434082,
      "learning_rate": 0.0009360613810741688,
      "loss": 1.2238,
      "step": 250
    },
    {
      "epoch": 0.6649616368286445,
      "grad_norm": 4.46756649017334,
      "learning_rate": 0.0009335038363171356,
      "loss": 1.2457,
      "step": 260
    },
    {
      "epoch": 0.690537084398977,
      "grad_norm": 2.6079392433166504,
      "learning_rate": 0.0009309462915601023,
      "loss": 1.268,
      "step": 270
    },
    {
      "epoch": 0.7161125319693095,
      "grad_norm": 2.9999873638153076,
      "learning_rate": 0.0009283887468030691,
      "loss": 1.2259,
      "step": 280
    },
    {
      "epoch": 0.7416879795396419,
      "grad_norm": 4.223467826843262,
      "learning_rate": 0.0009258312020460357,
      "loss": 1.2283,
      "step": 290
    },
    {
      "epoch": 0.7672634271099744,
      "grad_norm": 3.529348850250244,
      "learning_rate": 0.0009232736572890026,
      "loss": 1.1312,
      "step": 300
    },
    {
      "epoch": 0.7928388746803069,
      "grad_norm": 3.623095989227295,
      "learning_rate": 0.0009207161125319693,
      "loss": 1.1911,
      "step": 310
    },
    {
      "epoch": 0.8184143222506394,
      "grad_norm": 2.668268918991089,
      "learning_rate": 0.0009181585677749361,
      "loss": 1.1505,
      "step": 320
    },
    {
      "epoch": 0.8439897698209718,
      "grad_norm": 3.982362985610962,
      "learning_rate": 0.0009156010230179028,
      "loss": 1.1461,
      "step": 330
    },
    {
      "epoch": 0.8695652173913043,
      "grad_norm": 3.5054357051849365,
      "learning_rate": 0.0009130434782608695,
      "loss": 1.0647,
      "step": 340
    },
    {
      "epoch": 0.8951406649616368,
      "grad_norm": 2.5563175678253174,
      "learning_rate": 0.0009104859335038363,
      "loss": 1.1417,
      "step": 350
    },
    {
      "epoch": 0.9207161125319693,
      "grad_norm": 3.4673984050750732,
      "learning_rate": 0.0009079283887468031,
      "loss": 1.1295,
      "step": 360
    },
    {
      "epoch": 0.9462915601023018,
      "grad_norm": 2.978433609008789,
      "learning_rate": 0.0009053708439897699,
      "loss": 1.1051,
      "step": 370
    },
    {
      "epoch": 0.9718670076726342,
      "grad_norm": 2.489053249359131,
      "learning_rate": 0.0009028132992327366,
      "loss": 1.0949,
      "step": 380
    },
    {
      "epoch": 0.9974424552429667,
      "grad_norm": 3.1431591510772705,
      "learning_rate": 0.0009002557544757032,
      "loss": 1.121,
      "step": 390
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.6007,
      "eval_loss": 1.1146992444992065,
      "eval_runtime": 5.4314,
      "eval_samples_per_second": 1841.149,
      "eval_steps_per_second": 14.545,
      "step": 391
    },
    {
      "epoch": 1.0230179028132993,
      "grad_norm": 4.448899745941162,
      "learning_rate": 0.0008976982097186701,
      "loss": 1.0651,
      "step": 400
    },
    {
      "epoch": 1.0485933503836318,
      "grad_norm": 3.4813833236694336,
      "learning_rate": 0.0008951406649616369,
      "loss": 1.0313,
      "step": 410
    },
    {
      "epoch": 1.0741687979539642,
      "grad_norm": 2.946770429611206,
      "learning_rate": 0.0008925831202046036,
      "loss": 1.0673,
      "step": 420
    },
    {
      "epoch": 1.0997442455242967,
      "grad_norm": 3.261096477508545,
      "learning_rate": 0.0008900255754475704,
      "loss": 0.9839,
      "step": 430
    },
    {
      "epoch": 1.1253196930946292,
      "grad_norm": 3.3818960189819336,
      "learning_rate": 0.000887468030690537,
      "loss": 1.0602,
      "step": 440
    },
    {
      "epoch": 1.1508951406649617,
      "grad_norm": 2.843533754348755,
      "learning_rate": 0.0008849104859335039,
      "loss": 1.0689,
      "step": 450
    },
    {
      "epoch": 1.1764705882352942,
      "grad_norm": 2.587015151977539,
      "learning_rate": 0.0008823529411764706,
      "loss": 1.0226,
      "step": 460
    },
    {
      "epoch": 1.2020460358056266,
      "grad_norm": 3.0906779766082764,
      "learning_rate": 0.0008797953964194374,
      "loss": 0.9723,
      "step": 470
    },
    {
      "epoch": 1.227621483375959,
      "grad_norm": 4.502353668212891,
      "learning_rate": 0.0008772378516624041,
      "loss": 1.0007,
      "step": 480
    },
    {
      "epoch": 1.2531969309462916,
      "grad_norm": 4.9666242599487305,
      "learning_rate": 0.0008746803069053708,
      "loss": 0.9993,
      "step": 490
    },
    {
      "epoch": 1.278772378516624,
      "grad_norm": 3.6311213970184326,
      "learning_rate": 0.0008721227621483376,
      "loss": 0.9705,
      "step": 500
    },
    {
      "epoch": 1.3043478260869565,
      "grad_norm": 2.974996566772461,
      "learning_rate": 0.0008695652173913044,
      "loss": 0.9672,
      "step": 510
    },
    {
      "epoch": 1.329923273657289,
      "grad_norm": 3.7065961360931396,
      "learning_rate": 0.0008670076726342711,
      "loss": 0.9438,
      "step": 520
    },
    {
      "epoch": 1.3554987212276215,
      "grad_norm": 3.0875167846679688,
      "learning_rate": 0.0008644501278772379,
      "loss": 0.9346,
      "step": 530
    },
    {
      "epoch": 1.381074168797954,
      "grad_norm": 4.697050094604492,
      "learning_rate": 0.0008618925831202045,
      "loss": 0.9311,
      "step": 540
    },
    {
      "epoch": 1.4066496163682864,
      "grad_norm": 3.054164171218872,
      "learning_rate": 0.0008593350383631714,
      "loss": 0.9316,
      "step": 550
    },
    {
      "epoch": 1.432225063938619,
      "grad_norm": 3.433302164077759,
      "learning_rate": 0.0008567774936061381,
      "loss": 0.9933,
      "step": 560
    },
    {
      "epoch": 1.4578005115089514,
      "grad_norm": 3.011810064315796,
      "learning_rate": 0.0008542199488491049,
      "loss": 0.9616,
      "step": 570
    },
    {
      "epoch": 1.4833759590792839,
      "grad_norm": 2.430619955062866,
      "learning_rate": 0.0008516624040920716,
      "loss": 0.9683,
      "step": 580
    },
    {
      "epoch": 1.5089514066496164,
      "grad_norm": 2.5590744018554688,
      "learning_rate": 0.0008491048593350383,
      "loss": 0.9683,
      "step": 590
    },
    {
      "epoch": 1.5345268542199488,
      "grad_norm": 2.934986114501953,
      "learning_rate": 0.0008465473145780051,
      "loss": 0.9654,
      "step": 600
    },
    {
      "epoch": 1.5601023017902813,
      "grad_norm": 2.549093246459961,
      "learning_rate": 0.0008439897698209719,
      "loss": 0.8943,
      "step": 610
    },
    {
      "epoch": 1.5856777493606138,
      "grad_norm": 2.877986431121826,
      "learning_rate": 0.0008414322250639387,
      "loss": 0.8854,
      "step": 620
    },
    {
      "epoch": 1.6112531969309463,
      "grad_norm": 2.7243399620056152,
      "learning_rate": 0.0008388746803069054,
      "loss": 1.0112,
      "step": 630
    },
    {
      "epoch": 1.6368286445012787,
      "grad_norm": 2.4620625972747803,
      "learning_rate": 0.000836317135549872,
      "loss": 0.9385,
      "step": 640
    },
    {
      "epoch": 1.6624040920716112,
      "grad_norm": 2.871335029602051,
      "learning_rate": 0.0008337595907928389,
      "loss": 0.9123,
      "step": 650
    },
    {
      "epoch": 1.6879795396419437,
      "grad_norm": 2.810047149658203,
      "learning_rate": 0.0008312020460358057,
      "loss": 0.9387,
      "step": 660
    },
    {
      "epoch": 1.7135549872122762,
      "grad_norm": 2.6671440601348877,
      "learning_rate": 0.0008286445012787724,
      "loss": 0.9715,
      "step": 670
    },
    {
      "epoch": 1.7391304347826086,
      "grad_norm": 2.8162333965301514,
      "learning_rate": 0.0008260869565217392,
      "loss": 0.8909,
      "step": 680
    },
    {
      "epoch": 1.7647058823529411,
      "grad_norm": 3.6977391242980957,
      "learning_rate": 0.0008235294117647058,
      "loss": 0.9094,
      "step": 690
    },
    {
      "epoch": 1.7902813299232738,
      "grad_norm": 1.9946739673614502,
      "learning_rate": 0.0008209718670076727,
      "loss": 0.8202,
      "step": 700
    },
    {
      "epoch": 1.815856777493606,
      "grad_norm": 5.790404796600342,
      "learning_rate": 0.0008184143222506394,
      "loss": 0.9057,
      "step": 710
    },
    {
      "epoch": 1.8414322250639388,
      "grad_norm": 2.515369176864624,
      "learning_rate": 0.0008158567774936062,
      "loss": 0.8924,
      "step": 720
    },
    {
      "epoch": 1.867007672634271,
      "grad_norm": 3.3826849460601807,
      "learning_rate": 0.0008132992327365729,
      "loss": 0.8858,
      "step": 730
    },
    {
      "epoch": 1.8925831202046037,
      "grad_norm": 3.340932846069336,
      "learning_rate": 0.0008107416879795396,
      "loss": 0.8784,
      "step": 740
    },
    {
      "epoch": 1.918158567774936,
      "grad_norm": 3.1425461769104004,
      "learning_rate": 0.0008081841432225064,
      "loss": 0.8729,
      "step": 750
    },
    {
      "epoch": 1.9437340153452687,
      "grad_norm": 4.056018829345703,
      "learning_rate": 0.0008056265984654732,
      "loss": 0.8608,
      "step": 760
    },
    {
      "epoch": 1.969309462915601,
      "grad_norm": 2.536066770553589,
      "learning_rate": 0.0008030690537084399,
      "loss": 0.9198,
      "step": 770
    },
    {
      "epoch": 1.9948849104859336,
      "grad_norm": 3.501835584640503,
      "learning_rate": 0.0008005115089514067,
      "loss": 0.8837,
      "step": 780
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.6684,
      "eval_loss": 0.9555377960205078,
      "eval_runtime": 5.426,
      "eval_samples_per_second": 1842.977,
      "eval_steps_per_second": 14.56,
      "step": 782
    },
    {
      "epoch": 2.020460358056266,
      "grad_norm": 3.667816400527954,
      "learning_rate": 0.0007979539641943733,
      "loss": 0.8098,
      "step": 790
    },
    {
      "epoch": 2.0460358056265986,
      "grad_norm": 2.995882272720337,
      "learning_rate": 0.0007953964194373402,
      "loss": 0.831,
      "step": 800
    },
    {
      "epoch": 2.071611253196931,
      "grad_norm": 2.929013967514038,
      "learning_rate": 0.0007928388746803069,
      "loss": 0.7365,
      "step": 810
    },
    {
      "epoch": 2.0971867007672635,
      "grad_norm": 3.3931901454925537,
      "learning_rate": 0.0007902813299232737,
      "loss": 0.8036,
      "step": 820
    },
    {
      "epoch": 2.122762148337596,
      "grad_norm": 3.471372604370117,
      "learning_rate": 0.0007877237851662404,
      "loss": 0.8213,
      "step": 830
    },
    {
      "epoch": 2.1483375959079285,
      "grad_norm": 3.4239537715911865,
      "learning_rate": 0.0007851662404092071,
      "loss": 0.7979,
      "step": 840
    },
    {
      "epoch": 2.1739130434782608,
      "grad_norm": 2.256803512573242,
      "learning_rate": 0.000782608695652174,
      "loss": 0.7745,
      "step": 850
    },
    {
      "epoch": 2.1994884910485935,
      "grad_norm": 3.219498872756958,
      "learning_rate": 0.0007800511508951407,
      "loss": 0.8004,
      "step": 860
    },
    {
      "epoch": 2.2250639386189257,
      "grad_norm": 2.5375983715057373,
      "learning_rate": 0.0007774936061381073,
      "loss": 0.7752,
      "step": 870
    },
    {
      "epoch": 2.2506393861892584,
      "grad_norm": 2.6708076000213623,
      "learning_rate": 0.0007749360613810742,
      "loss": 0.737,
      "step": 880
    },
    {
      "epoch": 2.2762148337595907,
      "grad_norm": 2.455359935760498,
      "learning_rate": 0.0007723785166240409,
      "loss": 0.6984,
      "step": 890
    },
    {
      "epoch": 2.3017902813299234,
      "grad_norm": 3.8465638160705566,
      "learning_rate": 0.0007698209718670077,
      "loss": 0.7728,
      "step": 900
    },
    {
      "epoch": 2.3273657289002556,
      "grad_norm": 3.5830602645874023,
      "learning_rate": 0.0007672634271099745,
      "loss": 0.7044,
      "step": 910
    },
    {
      "epoch": 2.3529411764705883,
      "grad_norm": 2.8445119857788086,
      "learning_rate": 0.0007647058823529411,
      "loss": 0.7991,
      "step": 920
    },
    {
      "epoch": 2.3785166240409206,
      "grad_norm": 2.5809779167175293,
      "learning_rate": 0.000762148337595908,
      "loss": 0.7518,
      "step": 930
    },
    {
      "epoch": 2.4040920716112533,
      "grad_norm": 2.935708999633789,
      "learning_rate": 0.0007595907928388746,
      "loss": 0.8062,
      "step": 940
    },
    {
      "epoch": 2.4296675191815855,
      "grad_norm": 2.6519179344177246,
      "learning_rate": 0.0007570332480818415,
      "loss": 0.7651,
      "step": 950
    },
    {
      "epoch": 2.455242966751918,
      "grad_norm": 3.164443016052246,
      "learning_rate": 0.0007544757033248082,
      "loss": 0.7522,
      "step": 960
    },
    {
      "epoch": 2.4808184143222505,
      "grad_norm": 2.26080322265625,
      "learning_rate": 0.0007519181585677749,
      "loss": 0.6898,
      "step": 970
    },
    {
      "epoch": 2.506393861892583,
      "grad_norm": 2.3277060985565186,
      "learning_rate": 0.0007493606138107417,
      "loss": 0.7897,
      "step": 980
    },
    {
      "epoch": 2.531969309462916,
      "grad_norm": 3.304030179977417,
      "learning_rate": 0.0007468030690537084,
      "loss": 0.7553,
      "step": 990
    },
    {
      "epoch": 2.557544757033248,
      "grad_norm": 3.5405731201171875,
      "learning_rate": 0.0007442455242966752,
      "loss": 0.7904,
      "step": 1000
    },
    {
      "epoch": 2.5831202046035804,
      "grad_norm": 3.2186787128448486,
      "learning_rate": 0.000741687979539642,
      "loss": 0.7498,
      "step": 1010
    },
    {
      "epoch": 2.608695652173913,
      "grad_norm": 4.007926940917969,
      "learning_rate": 0.0007391304347826086,
      "loss": 0.7168,
      "step": 1020
    },
    {
      "epoch": 2.634271099744246,
      "grad_norm": 3.2454631328582764,
      "learning_rate": 0.0007365728900255755,
      "loss": 0.8082,
      "step": 1030
    },
    {
      "epoch": 2.659846547314578,
      "grad_norm": 3.2967355251312256,
      "learning_rate": 0.0007340153452685422,
      "loss": 0.8149,
      "step": 1040
    },
    {
      "epoch": 2.6854219948849103,
      "grad_norm": 2.959609270095825,
      "learning_rate": 0.000731457800511509,
      "loss": 0.7527,
      "step": 1050
    },
    {
      "epoch": 2.710997442455243,
      "grad_norm": 3.074732542037964,
      "learning_rate": 0.0007289002557544757,
      "loss": 0.7847,
      "step": 1060
    },
    {
      "epoch": 2.7365728900255757,
      "grad_norm": 3.048021078109741,
      "learning_rate": 0.0007263427109974424,
      "loss": 0.7496,
      "step": 1070
    },
    {
      "epoch": 2.762148337595908,
      "grad_norm": 3.4020895957946777,
      "learning_rate": 0.0007237851662404093,
      "loss": 0.7552,
      "step": 1080
    },
    {
      "epoch": 2.78772378516624,
      "grad_norm": 3.2676000595092773,
      "learning_rate": 0.000721227621483376,
      "loss": 0.8071,
      "step": 1090
    },
    {
      "epoch": 2.813299232736573,
      "grad_norm": 2.122976779937744,
      "learning_rate": 0.0007186700767263428,
      "loss": 0.7191,
      "step": 1100
    },
    {
      "epoch": 2.8388746803069056,
      "grad_norm": 2.500875949859619,
      "learning_rate": 0.0007161125319693095,
      "loss": 0.7231,
      "step": 1110
    },
    {
      "epoch": 2.864450127877238,
      "grad_norm": 2.7149910926818848,
      "learning_rate": 0.0007135549872122762,
      "loss": 0.7552,
      "step": 1120
    },
    {
      "epoch": 2.89002557544757,
      "grad_norm": 3.253019094467163,
      "learning_rate": 0.000710997442455243,
      "loss": 0.7377,
      "step": 1130
    },
    {
      "epoch": 2.915601023017903,
      "grad_norm": 4.490123271942139,
      "learning_rate": 0.0007084398976982098,
      "loss": 0.7108,
      "step": 1140
    },
    {
      "epoch": 2.9411764705882355,
      "grad_norm": 3.6895670890808105,
      "learning_rate": 0.0007058823529411765,
      "loss": 0.7647,
      "step": 1150
    },
    {
      "epoch": 2.9667519181585678,
      "grad_norm": 3.415786027908325,
      "learning_rate": 0.0007033248081841433,
      "loss": 0.7193,
      "step": 1160
    },
    {
      "epoch": 2.9923273657289,
      "grad_norm": 2.314748764038086,
      "learning_rate": 0.0007007672634271099,
      "loss": 0.7222,
      "step": 1170
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.7092,
      "eval_loss": 0.8540481328964233,
      "eval_runtime": 5.5515,
      "eval_samples_per_second": 1801.312,
      "eval_steps_per_second": 14.23,
      "step": 1173
    },
    {
      "epoch": 3.0179028132992327,
      "grad_norm": 2.7944998741149902,
      "learning_rate": 0.0006982097186700768,
      "loss": 0.6487,
      "step": 1180
    },
    {
      "epoch": 3.0434782608695654,
      "grad_norm": 3.645268440246582,
      "learning_rate": 0.0006956521739130435,
      "loss": 0.674,
      "step": 1190
    },
    {
      "epoch": 3.0690537084398977,
      "grad_norm": 1.9344900846481323,
      "learning_rate": 0.0006930946291560103,
      "loss": 0.6251,
      "step": 1200
    },
    {
      "epoch": 3.0946291560102304,
      "grad_norm": 2.4395675659179688,
      "learning_rate": 0.000690537084398977,
      "loss": 0.6354,
      "step": 1210
    },
    {
      "epoch": 3.1202046035805626,
      "grad_norm": 3.500967025756836,
      "learning_rate": 0.0006879795396419437,
      "loss": 0.5455,
      "step": 1220
    },
    {
      "epoch": 3.1457800511508953,
      "grad_norm": 2.577641248703003,
      "learning_rate": 0.0006854219948849105,
      "loss": 0.6164,
      "step": 1230
    },
    {
      "epoch": 3.1713554987212276,
      "grad_norm": 2.541400909423828,
      "learning_rate": 0.0006828644501278773,
      "loss": 0.6183,
      "step": 1240
    },
    {
      "epoch": 3.1969309462915603,
      "grad_norm": 3.3994874954223633,
      "learning_rate": 0.000680306905370844,
      "loss": 0.68,
      "step": 1250
    },
    {
      "epoch": 3.2225063938618925,
      "grad_norm": 3.2761268615722656,
      "learning_rate": 0.0006777493606138108,
      "loss": 0.6222,
      "step": 1260
    },
    {
      "epoch": 3.2480818414322252,
      "grad_norm": 2.943943977355957,
      "learning_rate": 0.0006751918158567774,
      "loss": 0.5614,
      "step": 1270
    },
    {
      "epoch": 3.2736572890025575,
      "grad_norm": 2.812709093093872,
      "learning_rate": 0.0006726342710997443,
      "loss": 0.6413,
      "step": 1280
    },
    {
      "epoch": 3.29923273657289,
      "grad_norm": 3.419133424758911,
      "learning_rate": 0.000670076726342711,
      "loss": 0.6878,
      "step": 1290
    },
    {
      "epoch": 3.3248081841432224,
      "grad_norm": 2.607937812805176,
      "learning_rate": 0.0006675191815856778,
      "loss": 0.6291,
      "step": 1300
    },
    {
      "epoch": 3.350383631713555,
      "grad_norm": 2.4234325885772705,
      "learning_rate": 0.0006649616368286446,
      "loss": 0.5805,
      "step": 1310
    },
    {
      "epoch": 3.3759590792838874,
      "grad_norm": 2.5889556407928467,
      "learning_rate": 0.0006624040920716112,
      "loss": 0.6176,
      "step": 1320
    },
    {
      "epoch": 3.40153452685422,
      "grad_norm": 3.451478958129883,
      "learning_rate": 0.0006598465473145781,
      "loss": 0.6016,
      "step": 1330
    },
    {
      "epoch": 3.4271099744245523,
      "grad_norm": 2.823808193206787,
      "learning_rate": 0.0006572890025575448,
      "loss": 0.6003,
      "step": 1340
    },
    {
      "epoch": 3.452685421994885,
      "grad_norm": 3.814810037612915,
      "learning_rate": 0.0006547314578005116,
      "loss": 0.67,
      "step": 1350
    },
    {
      "epoch": 3.4782608695652173,
      "grad_norm": 2.2832412719726562,
      "learning_rate": 0.0006521739130434783,
      "loss": 0.6493,
      "step": 1360
    },
    {
      "epoch": 3.50383631713555,
      "grad_norm": 2.4036266803741455,
      "learning_rate": 0.000649616368286445,
      "loss": 0.634,
      "step": 1370
    },
    {
      "epoch": 3.5294117647058822,
      "grad_norm": 2.3175525665283203,
      "learning_rate": 0.0006470588235294118,
      "loss": 0.6162,
      "step": 1380
    },
    {
      "epoch": 3.554987212276215,
      "grad_norm": 2.804642677307129,
      "learning_rate": 0.0006445012787723786,
      "loss": 0.5812,
      "step": 1390
    },
    {
      "epoch": 3.580562659846547,
      "grad_norm": 2.732877254486084,
      "learning_rate": 0.0006419437340153452,
      "loss": 0.566,
      "step": 1400
    },
    {
      "epoch": 3.60613810741688,
      "grad_norm": 3.0977158546447754,
      "learning_rate": 0.0006393861892583121,
      "loss": 0.646,
      "step": 1410
    },
    {
      "epoch": 3.631713554987212,
      "grad_norm": 2.758206605911255,
      "learning_rate": 0.0006368286445012787,
      "loss": 0.601,
      "step": 1420
    },
    {
      "epoch": 3.657289002557545,
      "grad_norm": 2.6316449642181396,
      "learning_rate": 0.0006342710997442456,
      "loss": 0.62,
      "step": 1430
    },
    {
      "epoch": 3.682864450127877,
      "grad_norm": 3.1904144287109375,
      "learning_rate": 0.0006317135549872123,
      "loss": 0.6403,
      "step": 1440
    },
    {
      "epoch": 3.70843989769821,
      "grad_norm": 3.540193796157837,
      "learning_rate": 0.000629156010230179,
      "loss": 0.6164,
      "step": 1450
    },
    {
      "epoch": 3.734015345268542,
      "grad_norm": 2.449739933013916,
      "learning_rate": 0.0006265984654731458,
      "loss": 0.6271,
      "step": 1460
    },
    {
      "epoch": 3.7595907928388748,
      "grad_norm": 2.289689540863037,
      "learning_rate": 0.0006240409207161125,
      "loss": 0.5775,
      "step": 1470
    },
    {
      "epoch": 3.785166240409207,
      "grad_norm": 2.0853137969970703,
      "learning_rate": 0.0006214833759590793,
      "loss": 0.6084,
      "step": 1480
    },
    {
      "epoch": 3.8107416879795397,
      "grad_norm": 2.6498939990997314,
      "learning_rate": 0.0006189258312020461,
      "loss": 0.5961,
      "step": 1490
    },
    {
      "epoch": 3.836317135549872,
      "grad_norm": 3.225137233734131,
      "learning_rate": 0.0006163682864450127,
      "loss": 0.6312,
      "step": 1500
    },
    {
      "epoch": 3.8618925831202047,
      "grad_norm": 3.1018309593200684,
      "learning_rate": 0.0006138107416879796,
      "loss": 0.6424,
      "step": 1510
    },
    {
      "epoch": 3.887468030690537,
      "grad_norm": 3.214012622833252,
      "learning_rate": 0.0006112531969309462,
      "loss": 0.6189,
      "step": 1520
    },
    {
      "epoch": 3.9130434782608696,
      "grad_norm": 3.1749038696289062,
      "learning_rate": 0.0006086956521739131,
      "loss": 0.5925,
      "step": 1530
    },
    {
      "epoch": 3.938618925831202,
      "grad_norm": 3.513479232788086,
      "learning_rate": 0.0006061381074168799,
      "loss": 0.5865,
      "step": 1540
    },
    {
      "epoch": 3.9641943734015346,
      "grad_norm": 2.7305870056152344,
      "learning_rate": 0.0006035805626598465,
      "loss": 0.6229,
      "step": 1550
    },
    {
      "epoch": 3.9897698209718673,
      "grad_norm": 2.7540552616119385,
      "learning_rate": 0.0006010230179028134,
      "loss": 0.6004,
      "step": 1560
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.741,
      "eval_loss": 0.764710545539856,
      "eval_runtime": 5.2063,
      "eval_samples_per_second": 1920.766,
      "eval_steps_per_second": 15.174,
      "step": 1564
    },
    {
      "epoch": 4.015345268542199,
      "grad_norm": 2.4424779415130615,
      "learning_rate": 0.00059846547314578,
      "loss": 0.5476,
      "step": 1570
    },
    {
      "epoch": 4.040920716112532,
      "grad_norm": 2.7432146072387695,
      "learning_rate": 0.0005959079283887469,
      "loss": 0.473,
      "step": 1580
    },
    {
      "epoch": 4.0664961636828645,
      "grad_norm": 2.664935350418091,
      "learning_rate": 0.0005933503836317136,
      "loss": 0.4558,
      "step": 1590
    },
    {
      "epoch": 4.092071611253197,
      "grad_norm": 2.7306127548217773,
      "learning_rate": 0.0005907928388746803,
      "loss": 0.4683,
      "step": 1600
    },
    {
      "epoch": 4.117647058823529,
      "grad_norm": 2.502739906311035,
      "learning_rate": 0.0005882352941176471,
      "loss": 0.4687,
      "step": 1610
    },
    {
      "epoch": 4.143222506393862,
      "grad_norm": 2.326246976852417,
      "learning_rate": 0.0005856777493606138,
      "loss": 0.4967,
      "step": 1620
    },
    {
      "epoch": 4.168797953964194,
      "grad_norm": 3.030733823776245,
      "learning_rate": 0.0005831202046035806,
      "loss": 0.4992,
      "step": 1630
    },
    {
      "epoch": 4.194373401534527,
      "grad_norm": 2.7898337841033936,
      "learning_rate": 0.0005805626598465474,
      "loss": 0.463,
      "step": 1640
    },
    {
      "epoch": 4.21994884910486,
      "grad_norm": 3.333035945892334,
      "learning_rate": 0.000578005115089514,
      "loss": 0.4752,
      "step": 1650
    },
    {
      "epoch": 4.245524296675192,
      "grad_norm": 3.449336290359497,
      "learning_rate": 0.0005754475703324809,
      "loss": 0.4374,
      "step": 1660
    },
    {
      "epoch": 4.271099744245524,
      "grad_norm": 3.0063796043395996,
      "learning_rate": 0.0005728900255754475,
      "loss": 0.4729,
      "step": 1670
    },
    {
      "epoch": 4.296675191815857,
      "grad_norm": 3.228407621383667,
      "learning_rate": 0.0005703324808184144,
      "loss": 0.4631,
      "step": 1680
    },
    {
      "epoch": 4.322250639386189,
      "grad_norm": 4.984773635864258,
      "learning_rate": 0.0005677749360613811,
      "loss": 0.5134,
      "step": 1690
    },
    {
      "epoch": 4.3478260869565215,
      "grad_norm": 2.2980196475982666,
      "learning_rate": 0.0005652173913043478,
      "loss": 0.4709,
      "step": 1700
    },
    {
      "epoch": 4.373401534526854,
      "grad_norm": 3.167473793029785,
      "learning_rate": 0.0005626598465473146,
      "loss": 0.5095,
      "step": 1710
    },
    {
      "epoch": 4.398976982097187,
      "grad_norm": 2.9786345958709717,
      "learning_rate": 0.0005601023017902813,
      "loss": 0.487,
      "step": 1720
    },
    {
      "epoch": 4.42455242966752,
      "grad_norm": 2.7108163833618164,
      "learning_rate": 0.0005575447570332481,
      "loss": 0.4698,
      "step": 1730
    },
    {
      "epoch": 4.450127877237851,
      "grad_norm": 3.8536171913146973,
      "learning_rate": 0.0005549872122762149,
      "loss": 0.4961,
      "step": 1740
    },
    {
      "epoch": 4.475703324808184,
      "grad_norm": 3.3741374015808105,
      "learning_rate": 0.0005524296675191815,
      "loss": 0.4848,
      "step": 1750
    },
    {
      "epoch": 4.501278772378517,
      "grad_norm": 3.1886463165283203,
      "learning_rate": 0.0005498721227621484,
      "loss": 0.4698,
      "step": 1760
    },
    {
      "epoch": 4.526854219948849,
      "grad_norm": 2.2157187461853027,
      "learning_rate": 0.000547314578005115,
      "loss": 0.4845,
      "step": 1770
    },
    {
      "epoch": 4.552429667519181,
      "grad_norm": 3.1560168266296387,
      "learning_rate": 0.0005447570332480819,
      "loss": 0.5303,
      "step": 1780
    },
    {
      "epoch": 4.578005115089514,
      "grad_norm": 2.7105860710144043,
      "learning_rate": 0.0005421994884910487,
      "loss": 0.4813,
      "step": 1790
    },
    {
      "epoch": 4.603580562659847,
      "grad_norm": 3.074141263961792,
      "learning_rate": 0.0005396419437340153,
      "loss": 0.4897,
      "step": 1800
    },
    {
      "epoch": 4.629156010230179,
      "grad_norm": 3.04917573928833,
      "learning_rate": 0.0005370843989769822,
      "loss": 0.4772,
      "step": 1810
    },
    {
      "epoch": 4.654731457800511,
      "grad_norm": 2.6889312267303467,
      "learning_rate": 0.0005345268542199488,
      "loss": 0.4951,
      "step": 1820
    },
    {
      "epoch": 4.680306905370844,
      "grad_norm": 2.7175233364105225,
      "learning_rate": 0.0005319693094629157,
      "loss": 0.4494,
      "step": 1830
    },
    {
      "epoch": 4.705882352941177,
      "grad_norm": 3.478726625442505,
      "learning_rate": 0.0005294117647058824,
      "loss": 0.483,
      "step": 1840
    },
    {
      "epoch": 4.731457800511509,
      "grad_norm": 3.035256862640381,
      "learning_rate": 0.0005268542199488491,
      "loss": 0.4311,
      "step": 1850
    },
    {
      "epoch": 4.757033248081841,
      "grad_norm": 3.351569652557373,
      "learning_rate": 0.0005242966751918159,
      "loss": 0.5088,
      "step": 1860
    },
    {
      "epoch": 4.782608695652174,
      "grad_norm": 5.402308940887451,
      "learning_rate": 0.0005217391304347826,
      "loss": 0.5031,
      "step": 1870
    },
    {
      "epoch": 4.8081841432225065,
      "grad_norm": 3.070901870727539,
      "learning_rate": 0.0005191815856777494,
      "loss": 0.493,
      "step": 1880
    },
    {
      "epoch": 4.833759590792839,
      "grad_norm": 3.500988483428955,
      "learning_rate": 0.0005166240409207162,
      "loss": 0.4918,
      "step": 1890
    },
    {
      "epoch": 4.859335038363171,
      "grad_norm": 3.6459267139434814,
      "learning_rate": 0.0005140664961636828,
      "loss": 0.4907,
      "step": 1900
    },
    {
      "epoch": 4.884910485933504,
      "grad_norm": 3.0559608936309814,
      "learning_rate": 0.0005115089514066497,
      "loss": 0.5057,
      "step": 1910
    },
    {
      "epoch": 4.910485933503836,
      "grad_norm": 1.9356663227081299,
      "learning_rate": 0.0005089514066496163,
      "loss": 0.4848,
      "step": 1920
    },
    {
      "epoch": 4.936061381074169,
      "grad_norm": 2.79671049118042,
      "learning_rate": 0.0005063938618925832,
      "loss": 0.4838,
      "step": 1930
    },
    {
      "epoch": 4.961636828644501,
      "grad_norm": 2.4194259643554688,
      "learning_rate": 0.0005038363171355499,
      "loss": 0.5328,
      "step": 1940
    },
    {
      "epoch": 4.987212276214834,
      "grad_norm": 2.9354443550109863,
      "learning_rate": 0.0005012787723785166,
      "loss": 0.5142,
      "step": 1950
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.7512,
      "eval_loss": 0.7458837628364563,
      "eval_runtime": 5.2947,
      "eval_samples_per_second": 1888.686,
      "eval_steps_per_second": 14.921,
      "step": 1955
    },
    {
      "epoch": 5.012787723785166,
      "grad_norm": 2.0400850772857666,
      "learning_rate": 0.0004987212276214833,
      "loss": 0.3838,
      "step": 1960
    },
    {
      "epoch": 5.038363171355499,
      "grad_norm": 2.200627088546753,
      "learning_rate": 0.0004961636828644501,
      "loss": 0.3084,
      "step": 1970
    },
    {
      "epoch": 5.063938618925831,
      "grad_norm": 2.4857890605926514,
      "learning_rate": 0.0004936061381074169,
      "loss": 0.3423,
      "step": 1980
    },
    {
      "epoch": 5.089514066496164,
      "grad_norm": 2.435049533843994,
      "learning_rate": 0.0004910485933503837,
      "loss": 0.3557,
      "step": 1990
    },
    {
      "epoch": 5.115089514066496,
      "grad_norm": 2.0620884895324707,
      "learning_rate": 0.0004884910485933504,
      "loss": 0.3134,
      "step": 2000
    },
    {
      "epoch": 5.140664961636829,
      "grad_norm": 2.906205654144287,
      "learning_rate": 0.00048593350383631715,
      "loss": 0.3516,
      "step": 2010
    },
    {
      "epoch": 5.166240409207161,
      "grad_norm": 1.8201605081558228,
      "learning_rate": 0.0004833759590792839,
      "loss": 0.3089,
      "step": 2020
    },
    {
      "epoch": 5.1918158567774935,
      "grad_norm": 3.0602452754974365,
      "learning_rate": 0.00048081841432225065,
      "loss": 0.3356,
      "step": 2030
    },
    {
      "epoch": 5.217391304347826,
      "grad_norm": 3.7379448413848877,
      "learning_rate": 0.0004782608695652174,
      "loss": 0.3736,
      "step": 2040
    },
    {
      "epoch": 5.242966751918159,
      "grad_norm": 2.7852628231048584,
      "learning_rate": 0.00047570332480818416,
      "loss": 0.3529,
      "step": 2050
    },
    {
      "epoch": 5.268542199488491,
      "grad_norm": 2.98350191116333,
      "learning_rate": 0.0004731457800511509,
      "loss": 0.3374,
      "step": 2060
    },
    {
      "epoch": 5.294117647058823,
      "grad_norm": 2.4773707389831543,
      "learning_rate": 0.00047058823529411766,
      "loss": 0.3666,
      "step": 2070
    },
    {
      "epoch": 5.319693094629156,
      "grad_norm": 3.3636295795440674,
      "learning_rate": 0.0004680306905370844,
      "loss": 0.3429,
      "step": 2080
    },
    {
      "epoch": 5.345268542199489,
      "grad_norm": 3.0117969512939453,
      "learning_rate": 0.00046547314578005116,
      "loss": 0.4135,
      "step": 2090
    },
    {
      "epoch": 5.370843989769821,
      "grad_norm": 3.057176113128662,
      "learning_rate": 0.00046291560102301786,
      "loss": 0.3415,
      "step": 2100
    },
    {
      "epoch": 5.396419437340153,
      "grad_norm": 3.554422378540039,
      "learning_rate": 0.00046035805626598467,
      "loss": 0.3992,
      "step": 2110
    },
    {
      "epoch": 5.421994884910486,
      "grad_norm": 3.90144681930542,
      "learning_rate": 0.0004578005115089514,
      "loss": 0.3727,
      "step": 2120
    },
    {
      "epoch": 5.447570332480819,
      "grad_norm": 2.7290210723876953,
      "learning_rate": 0.0004552429667519182,
      "loss": 0.3994,
      "step": 2130
    },
    {
      "epoch": 5.4731457800511505,
      "grad_norm": 2.040438413619995,
      "learning_rate": 0.0004526854219948849,
      "loss": 0.3568,
      "step": 2140
    },
    {
      "epoch": 5.498721227621483,
      "grad_norm": 2.3657846450805664,
      "learning_rate": 0.0004501278772378516,
      "loss": 0.3667,
      "step": 2150
    },
    {
      "epoch": 5.524296675191816,
      "grad_norm": 2.5565638542175293,
      "learning_rate": 0.00044757033248081843,
      "loss": 0.3761,
      "step": 2160
    },
    {
      "epoch": 5.549872122762149,
      "grad_norm": 2.586674690246582,
      "learning_rate": 0.0004450127877237852,
      "loss": 0.3648,
      "step": 2170
    },
    {
      "epoch": 5.57544757033248,
      "grad_norm": 2.0705809593200684,
      "learning_rate": 0.00044245524296675193,
      "loss": 0.3543,
      "step": 2180
    },
    {
      "epoch": 5.601023017902813,
      "grad_norm": 3.16296124458313,
      "learning_rate": 0.0004398976982097187,
      "loss": 0.3831,
      "step": 2190
    },
    {
      "epoch": 5.626598465473146,
      "grad_norm": 3.666292190551758,
      "learning_rate": 0.0004373401534526854,
      "loss": 0.3628,
      "step": 2200
    },
    {
      "epoch": 5.6521739130434785,
      "grad_norm": 3.40330171585083,
      "learning_rate": 0.0004347826086956522,
      "loss": 0.3791,
      "step": 2210
    },
    {
      "epoch": 5.677749360613811,
      "grad_norm": 3.0124151706695557,
      "learning_rate": 0.00043222506393861894,
      "loss": 0.3435,
      "step": 2220
    },
    {
      "epoch": 5.703324808184143,
      "grad_norm": 2.614565849304199,
      "learning_rate": 0.0004296675191815857,
      "loss": 0.3497,
      "step": 2230
    },
    {
      "epoch": 5.728900255754476,
      "grad_norm": 3.911065101623535,
      "learning_rate": 0.00042710997442455245,
      "loss": 0.425,
      "step": 2240
    },
    {
      "epoch": 5.754475703324808,
      "grad_norm": 2.77262282371521,
      "learning_rate": 0.00042455242966751914,
      "loss": 0.3756,
      "step": 2250
    },
    {
      "epoch": 5.78005115089514,
      "grad_norm": 2.476276397705078,
      "learning_rate": 0.00042199488491048595,
      "loss": 0.3138,
      "step": 2260
    },
    {
      "epoch": 5.805626598465473,
      "grad_norm": 2.332343578338623,
      "learning_rate": 0.0004194373401534527,
      "loss": 0.3745,
      "step": 2270
    },
    {
      "epoch": 5.831202046035806,
      "grad_norm": 2.6068968772888184,
      "learning_rate": 0.00041687979539641946,
      "loss": 0.3869,
      "step": 2280
    },
    {
      "epoch": 5.856777493606138,
      "grad_norm": 2.3609273433685303,
      "learning_rate": 0.0004143222506393862,
      "loss": 0.344,
      "step": 2290
    },
    {
      "epoch": 5.882352941176471,
      "grad_norm": 2.6048245429992676,
      "learning_rate": 0.0004117647058823529,
      "loss": 0.3337,
      "step": 2300
    },
    {
      "epoch": 5.907928388746803,
      "grad_norm": 5.043975830078125,
      "learning_rate": 0.0004092071611253197,
      "loss": 0.3621,
      "step": 2310
    },
    {
      "epoch": 5.9335038363171355,
      "grad_norm": 2.3489763736724854,
      "learning_rate": 0.00040664961636828646,
      "loss": 0.3691,
      "step": 2320
    },
    {
      "epoch": 5.959079283887468,
      "grad_norm": 2.7898764610290527,
      "learning_rate": 0.0004040920716112532,
      "loss": 0.3429,
      "step": 2330
    },
    {
      "epoch": 5.9846547314578,
      "grad_norm": 3.2942752838134766,
      "learning_rate": 0.00040153452685421997,
      "loss": 0.3211,
      "step": 2340
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.7663,
      "eval_loss": 0.7437919974327087,
      "eval_runtime": 5.8556,
      "eval_samples_per_second": 1707.778,
      "eval_steps_per_second": 13.491,
      "step": 2346
    },
    {
      "epoch": 6.010230179028133,
      "grad_norm": 2.096179723739624,
      "learning_rate": 0.00039897698209718667,
      "loss": 0.3109,
      "step": 2350
    },
    {
      "epoch": 6.035805626598465,
      "grad_norm": 1.8714807033538818,
      "learning_rate": 0.00039641943734015347,
      "loss": 0.2217,
      "step": 2360
    },
    {
      "epoch": 6.061381074168798,
      "grad_norm": 2.199885606765747,
      "learning_rate": 0.0003938618925831202,
      "loss": 0.2198,
      "step": 2370
    },
    {
      "epoch": 6.086956521739131,
      "grad_norm": 2.01031231880188,
      "learning_rate": 0.000391304347826087,
      "loss": 0.2121,
      "step": 2380
    },
    {
      "epoch": 6.112531969309463,
      "grad_norm": 2.124216079711914,
      "learning_rate": 0.0003887468030690537,
      "loss": 0.2287,
      "step": 2390
    },
    {
      "epoch": 6.138107416879795,
      "grad_norm": 3.156893730163574,
      "learning_rate": 0.0003861892583120204,
      "loss": 0.233,
      "step": 2400
    },
    {
      "epoch": 6.163682864450128,
      "grad_norm": 2.229417562484741,
      "learning_rate": 0.00038363171355498723,
      "loss": 0.2083,
      "step": 2410
    },
    {
      "epoch": 6.189258312020461,
      "grad_norm": 2.335456132888794,
      "learning_rate": 0.000381074168797954,
      "loss": 0.2229,
      "step": 2420
    },
    {
      "epoch": 6.2148337595907925,
      "grad_norm": 3.570197582244873,
      "learning_rate": 0.00037851662404092074,
      "loss": 0.2504,
      "step": 2430
    },
    {
      "epoch": 6.240409207161125,
      "grad_norm": 3.3135809898376465,
      "learning_rate": 0.00037595907928388744,
      "loss": 0.2755,
      "step": 2440
    },
    {
      "epoch": 6.265984654731458,
      "grad_norm": 2.2983710765838623,
      "learning_rate": 0.0003734015345268542,
      "loss": 0.2388,
      "step": 2450
    },
    {
      "epoch": 6.291560102301791,
      "grad_norm": 2.7347588539123535,
      "learning_rate": 0.000370843989769821,
      "loss": 0.2611,
      "step": 2460
    },
    {
      "epoch": 6.3171355498721224,
      "grad_norm": 2.818521499633789,
      "learning_rate": 0.00036828644501278775,
      "loss": 0.2393,
      "step": 2470
    },
    {
      "epoch": 6.342710997442455,
      "grad_norm": 3.132622241973877,
      "learning_rate": 0.0003657289002557545,
      "loss": 0.2512,
      "step": 2480
    },
    {
      "epoch": 6.368286445012788,
      "grad_norm": 3.744020462036133,
      "learning_rate": 0.0003631713554987212,
      "loss": 0.2787,
      "step": 2490
    },
    {
      "epoch": 6.3938618925831205,
      "grad_norm": 2.5355939865112305,
      "learning_rate": 0.000360613810741688,
      "loss": 0.2475,
      "step": 2500
    },
    {
      "epoch": 6.419437340153452,
      "grad_norm": 3.034057378768921,
      "learning_rate": 0.00035805626598465475,
      "loss": 0.2259,
      "step": 2510
    },
    {
      "epoch": 6.445012787723785,
      "grad_norm": 4.3426971435546875,
      "learning_rate": 0.0003554987212276215,
      "loss": 0.2287,
      "step": 2520
    },
    {
      "epoch": 6.470588235294118,
      "grad_norm": 2.524627447128296,
      "learning_rate": 0.00035294117647058826,
      "loss": 0.2099,
      "step": 2530
    },
    {
      "epoch": 6.4961636828644505,
      "grad_norm": 3.6266448497772217,
      "learning_rate": 0.00035038363171355496,
      "loss": 0.2773,
      "step": 2540
    },
    {
      "epoch": 6.521739130434782,
      "grad_norm": 2.5232412815093994,
      "learning_rate": 0.00034782608695652176,
      "loss": 0.247,
      "step": 2550
    },
    {
      "epoch": 6.547314578005115,
      "grad_norm": 2.39734148979187,
      "learning_rate": 0.0003452685421994885,
      "loss": 0.231,
      "step": 2560
    },
    {
      "epoch": 6.572890025575448,
      "grad_norm": 3.6195573806762695,
      "learning_rate": 0.00034271099744245527,
      "loss": 0.2609,
      "step": 2570
    },
    {
      "epoch": 6.59846547314578,
      "grad_norm": 1.9461404085159302,
      "learning_rate": 0.000340153452685422,
      "loss": 0.2364,
      "step": 2580
    },
    {
      "epoch": 6.624040920716112,
      "grad_norm": 3.773437261581421,
      "learning_rate": 0.0003375959079283887,
      "loss": 0.247,
      "step": 2590
    },
    {
      "epoch": 6.649616368286445,
      "grad_norm": 2.647830009460449,
      "learning_rate": 0.0003350383631713555,
      "loss": 0.2558,
      "step": 2600
    },
    {
      "epoch": 6.675191815856778,
      "grad_norm": 2.128427267074585,
      "learning_rate": 0.0003324808184143223,
      "loss": 0.2439,
      "step": 2610
    },
    {
      "epoch": 6.70076726342711,
      "grad_norm": 3.5762569904327393,
      "learning_rate": 0.00032992327365728903,
      "loss": 0.253,
      "step": 2620
    },
    {
      "epoch": 6.726342710997442,
      "grad_norm": 3.3741276264190674,
      "learning_rate": 0.0003273657289002558,
      "loss": 0.2389,
      "step": 2630
    },
    {
      "epoch": 6.751918158567775,
      "grad_norm": 2.9980480670928955,
      "learning_rate": 0.0003248081841432225,
      "loss": 0.2217,
      "step": 2640
    },
    {
      "epoch": 6.7774936061381075,
      "grad_norm": 4.174661159515381,
      "learning_rate": 0.0003222506393861893,
      "loss": 0.2367,
      "step": 2650
    },
    {
      "epoch": 6.80306905370844,
      "grad_norm": 3.5680859088897705,
      "learning_rate": 0.00031969309462915604,
      "loss": 0.2676,
      "step": 2660
    },
    {
      "epoch": 6.828644501278772,
      "grad_norm": 2.549149990081787,
      "learning_rate": 0.0003171355498721228,
      "loss": 0.2421,
      "step": 2670
    },
    {
      "epoch": 6.854219948849105,
      "grad_norm": 5.3413004875183105,
      "learning_rate": 0.0003145780051150895,
      "loss": 0.225,
      "step": 2680
    },
    {
      "epoch": 6.879795396419437,
      "grad_norm": 3.5798962116241455,
      "learning_rate": 0.00031202046035805624,
      "loss": 0.2114,
      "step": 2690
    },
    {
      "epoch": 6.90537084398977,
      "grad_norm": 2.8865840435028076,
      "learning_rate": 0.00030946291560102305,
      "loss": 0.2346,
      "step": 2700
    },
    {
      "epoch": 6.930946291560103,
      "grad_norm": 4.012172222137451,
      "learning_rate": 0.0003069053708439898,
      "loss": 0.2285,
      "step": 2710
    },
    {
      "epoch": 6.956521739130435,
      "grad_norm": 3.2860629558563232,
      "learning_rate": 0.00030434782608695655,
      "loss": 0.2059,
      "step": 2720
    },
    {
      "epoch": 6.982097186700767,
      "grad_norm": 6.131940841674805,
      "learning_rate": 0.00030179028132992325,
      "loss": 0.2558,
      "step": 2730
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.7667,
      "eval_loss": 0.8383706212043762,
      "eval_runtime": 5.7811,
      "eval_samples_per_second": 1729.768,
      "eval_steps_per_second": 13.665,
      "step": 2737
    },
    {
      "epoch": 7.0076726342711,
      "grad_norm": 3.8743810653686523,
      "learning_rate": 0.00029923273657289,
      "loss": 0.191,
      "step": 2740
    },
    {
      "epoch": 7.033248081841432,
      "grad_norm": 2.1112546920776367,
      "learning_rate": 0.0002966751918158568,
      "loss": 0.1317,
      "step": 2750
    },
    {
      "epoch": 7.0588235294117645,
      "grad_norm": 2.183457851409912,
      "learning_rate": 0.00029411764705882356,
      "loss": 0.1354,
      "step": 2760
    },
    {
      "epoch": 7.084398976982097,
      "grad_norm": 1.8926072120666504,
      "learning_rate": 0.0002915601023017903,
      "loss": 0.1114,
      "step": 2770
    },
    {
      "epoch": 7.10997442455243,
      "grad_norm": 2.291935443878174,
      "learning_rate": 0.000289002557544757,
      "loss": 0.1352,
      "step": 2780
    },
    {
      "epoch": 7.135549872122763,
      "grad_norm": 2.030264377593994,
      "learning_rate": 0.00028644501278772376,
      "loss": 0.1161,
      "step": 2790
    },
    {
      "epoch": 7.161125319693094,
      "grad_norm": 2.4620614051818848,
      "learning_rate": 0.00028388746803069057,
      "loss": 0.1343,
      "step": 2800
    },
    {
      "epoch": 7.186700767263427,
      "grad_norm": 2.268226146697998,
      "learning_rate": 0.0002813299232736573,
      "loss": 0.1622,
      "step": 2810
    },
    {
      "epoch": 7.21227621483376,
      "grad_norm": 3.788970708847046,
      "learning_rate": 0.00027877237851662407,
      "loss": 0.14,
      "step": 2820
    },
    {
      "epoch": 7.2378516624040925,
      "grad_norm": 2.9828951358795166,
      "learning_rate": 0.00027621483375959077,
      "loss": 0.1284,
      "step": 2830
    },
    {
      "epoch": 7.263427109974424,
      "grad_norm": 2.9226698875427246,
      "learning_rate": 0.0002736572890025575,
      "loss": 0.1148,
      "step": 2840
    },
    {
      "epoch": 7.289002557544757,
      "grad_norm": 4.108675003051758,
      "learning_rate": 0.00027109974424552433,
      "loss": 0.1116,
      "step": 2850
    },
    {
      "epoch": 7.31457800511509,
      "grad_norm": 2.9205009937286377,
      "learning_rate": 0.0002685421994884911,
      "loss": 0.1538,
      "step": 2860
    },
    {
      "epoch": 7.340153452685422,
      "grad_norm": 3.939190149307251,
      "learning_rate": 0.00026598465473145783,
      "loss": 0.1279,
      "step": 2870
    },
    {
      "epoch": 7.365728900255754,
      "grad_norm": 3.276545286178589,
      "learning_rate": 0.00026342710997442453,
      "loss": 0.1335,
      "step": 2880
    },
    {
      "epoch": 7.391304347826087,
      "grad_norm": 2.9544830322265625,
      "learning_rate": 0.0002608695652173913,
      "loss": 0.1124,
      "step": 2890
    },
    {
      "epoch": 7.41687979539642,
      "grad_norm": 2.9157044887542725,
      "learning_rate": 0.0002583120204603581,
      "loss": 0.1401,
      "step": 2900
    },
    {
      "epoch": 7.442455242966752,
      "grad_norm": 3.9118242263793945,
      "learning_rate": 0.00025575447570332484,
      "loss": 0.1325,
      "step": 2910
    },
    {
      "epoch": 7.468030690537084,
      "grad_norm": 3.6400463581085205,
      "learning_rate": 0.0002531969309462916,
      "loss": 0.1363,
      "step": 2920
    },
    {
      "epoch": 7.493606138107417,
      "grad_norm": 4.1736555099487305,
      "learning_rate": 0.0002506393861892583,
      "loss": 0.1587,
      "step": 2930
    },
    {
      "epoch": 7.5191815856777495,
      "grad_norm": 3.2840237617492676,
      "learning_rate": 0.00024808184143222504,
      "loss": 0.1491,
      "step": 2940
    },
    {
      "epoch": 7.544757033248082,
      "grad_norm": 2.689013719558716,
      "learning_rate": 0.00024552429667519185,
      "loss": 0.1479,
      "step": 2950
    },
    {
      "epoch": 7.570332480818414,
      "grad_norm": 2.5420420169830322,
      "learning_rate": 0.00024296675191815857,
      "loss": 0.134,
      "step": 2960
    },
    {
      "epoch": 7.595907928388747,
      "grad_norm": 3.966015100479126,
      "learning_rate": 0.00024040920716112533,
      "loss": 0.1516,
      "step": 2970
    },
    {
      "epoch": 7.621483375959079,
      "grad_norm": 2.9043161869049072,
      "learning_rate": 0.00023785166240409208,
      "loss": 0.1357,
      "step": 2980
    },
    {
      "epoch": 7.647058823529412,
      "grad_norm": 2.5884790420532227,
      "learning_rate": 0.00023529411764705883,
      "loss": 0.1333,
      "step": 2990
    },
    {
      "epoch": 7.672634271099744,
      "grad_norm": 4.56189489364624,
      "learning_rate": 0.00023273657289002558,
      "loss": 0.1426,
      "step": 3000
    },
    {
      "epoch": 7.698209718670077,
      "grad_norm": 3.6827383041381836,
      "learning_rate": 0.00023017902813299233,
      "loss": 0.1273,
      "step": 3010
    },
    {
      "epoch": 7.723785166240409,
      "grad_norm": 1.9716182947158813,
      "learning_rate": 0.0002276214833759591,
      "loss": 0.1253,
      "step": 3020
    },
    {
      "epoch": 7.749360613810742,
      "grad_norm": 3.325129747390747,
      "learning_rate": 0.0002250639386189258,
      "loss": 0.1345,
      "step": 3030
    },
    {
      "epoch": 7.774936061381074,
      "grad_norm": 2.8675570487976074,
      "learning_rate": 0.0002225063938618926,
      "loss": 0.1282,
      "step": 3040
    },
    {
      "epoch": 7.8005115089514065,
      "grad_norm": 4.178824424743652,
      "learning_rate": 0.00021994884910485934,
      "loss": 0.1374,
      "step": 3050
    },
    {
      "epoch": 7.826086956521739,
      "grad_norm": 2.4866061210632324,
      "learning_rate": 0.0002173913043478261,
      "loss": 0.1418,
      "step": 3060
    },
    {
      "epoch": 7.851662404092072,
      "grad_norm": 3.6031494140625,
      "learning_rate": 0.00021483375959079285,
      "loss": 0.1394,
      "step": 3070
    },
    {
      "epoch": 7.877237851662404,
      "grad_norm": 3.5688893795013428,
      "learning_rate": 0.00021227621483375957,
      "loss": 0.1268,
      "step": 3080
    },
    {
      "epoch": 7.9028132992327365,
      "grad_norm": 3.0883240699768066,
      "learning_rate": 0.00020971867007672635,
      "loss": 0.1313,
      "step": 3090
    },
    {
      "epoch": 7.928388746803069,
      "grad_norm": 3.30466628074646,
      "learning_rate": 0.0002071611253196931,
      "loss": 0.1119,
      "step": 3100
    },
    {
      "epoch": 7.953964194373402,
      "grad_norm": 2.5708274841308594,
      "learning_rate": 0.00020460358056265986,
      "loss": 0.1525,
      "step": 3110
    },
    {
      "epoch": 7.979539641943734,
      "grad_norm": 2.830749750137329,
      "learning_rate": 0.0002020460358056266,
      "loss": 0.1191,
      "step": 3120
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.7707,
      "eval_loss": 0.9491930603981018,
      "eval_runtime": 5.7686,
      "eval_samples_per_second": 1733.533,
      "eval_steps_per_second": 13.695,
      "step": 3128
    },
    {
      "epoch": 8.005115089514067,
      "grad_norm": 2.09741473197937,
      "learning_rate": 0.00019948849104859333,
      "loss": 0.1,
      "step": 3130
    },
    {
      "epoch": 8.030690537084398,
      "grad_norm": 2.419400691986084,
      "learning_rate": 0.0001969309462915601,
      "loss": 0.0716,
      "step": 3140
    },
    {
      "epoch": 8.05626598465473,
      "grad_norm": 1.2077581882476807,
      "learning_rate": 0.00019437340153452684,
      "loss": 0.0613,
      "step": 3150
    },
    {
      "epoch": 8.081841432225064,
      "grad_norm": 1.6406574249267578,
      "learning_rate": 0.00019181585677749362,
      "loss": 0.0623,
      "step": 3160
    },
    {
      "epoch": 8.107416879795396,
      "grad_norm": 1.6799899339675903,
      "learning_rate": 0.00018925831202046037,
      "loss": 0.0569,
      "step": 3170
    },
    {
      "epoch": 8.132992327365729,
      "grad_norm": 3.124452590942383,
      "learning_rate": 0.0001867007672634271,
      "loss": 0.0812,
      "step": 3180
    },
    {
      "epoch": 8.158567774936062,
      "grad_norm": 2.7332849502563477,
      "learning_rate": 0.00018414322250639387,
      "loss": 0.0738,
      "step": 3190
    },
    {
      "epoch": 8.184143222506394,
      "grad_norm": 2.080267906188965,
      "learning_rate": 0.0001815856777493606,
      "loss": 0.0695,
      "step": 3200
    },
    {
      "epoch": 8.209718670076727,
      "grad_norm": 1.2710927724838257,
      "learning_rate": 0.00017902813299232738,
      "loss": 0.064,
      "step": 3210
    },
    {
      "epoch": 8.235294117647058,
      "grad_norm": 1.3933411836624146,
      "learning_rate": 0.00017647058823529413,
      "loss": 0.0527,
      "step": 3220
    },
    {
      "epoch": 8.26086956521739,
      "grad_norm": 1.843343734741211,
      "learning_rate": 0.00017391304347826088,
      "loss": 0.0545,
      "step": 3230
    },
    {
      "epoch": 8.286445012787723,
      "grad_norm": 3.7311179637908936,
      "learning_rate": 0.00017135549872122763,
      "loss": 0.0643,
      "step": 3240
    },
    {
      "epoch": 8.312020460358056,
      "grad_norm": 2.040076732635498,
      "learning_rate": 0.00016879795396419436,
      "loss": 0.0618,
      "step": 3250
    },
    {
      "epoch": 8.337595907928389,
      "grad_norm": 2.4285800457000732,
      "learning_rate": 0.00016624040920716114,
      "loss": 0.0567,
      "step": 3260
    },
    {
      "epoch": 8.363171355498721,
      "grad_norm": 2.028625249862671,
      "learning_rate": 0.0001636828644501279,
      "loss": 0.0706,
      "step": 3270
    },
    {
      "epoch": 8.388746803069054,
      "grad_norm": 1.7228113412857056,
      "learning_rate": 0.00016112531969309464,
      "loss": 0.0591,
      "step": 3280
    },
    {
      "epoch": 8.414322250639387,
      "grad_norm": 1.3235265016555786,
      "learning_rate": 0.0001585677749360614,
      "loss": 0.0502,
      "step": 3290
    },
    {
      "epoch": 8.43989769820972,
      "grad_norm": 2.0895814895629883,
      "learning_rate": 0.00015601023017902812,
      "loss": 0.0497,
      "step": 3300
    },
    {
      "epoch": 8.46547314578005,
      "grad_norm": 1.8043773174285889,
      "learning_rate": 0.0001534526854219949,
      "loss": 0.0665,
      "step": 3310
    },
    {
      "epoch": 8.491048593350383,
      "grad_norm": 3.216782808303833,
      "learning_rate": 0.00015089514066496162,
      "loss": 0.0578,
      "step": 3320
    },
    {
      "epoch": 8.516624040920716,
      "grad_norm": 4.3476409912109375,
      "learning_rate": 0.0001483375959079284,
      "loss": 0.0845,
      "step": 3330
    },
    {
      "epoch": 8.542199488491049,
      "grad_norm": 2.9866678714752197,
      "learning_rate": 0.00014578005115089515,
      "loss": 0.0752,
      "step": 3340
    },
    {
      "epoch": 8.567774936061381,
      "grad_norm": 3.437459707260132,
      "learning_rate": 0.00014322250639386188,
      "loss": 0.0786,
      "step": 3350
    },
    {
      "epoch": 8.593350383631714,
      "grad_norm": 2.660461902618408,
      "learning_rate": 0.00014066496163682866,
      "loss": 0.0604,
      "step": 3360
    },
    {
      "epoch": 8.618925831202047,
      "grad_norm": 2.94138765335083,
      "learning_rate": 0.00013810741687979538,
      "loss": 0.0713,
      "step": 3370
    },
    {
      "epoch": 8.644501278772378,
      "grad_norm": 1.2584220170974731,
      "learning_rate": 0.00013554987212276216,
      "loss": 0.0646,
      "step": 3380
    },
    {
      "epoch": 8.67007672634271,
      "grad_norm": 2.009845495223999,
      "learning_rate": 0.00013299232736572892,
      "loss": 0.0667,
      "step": 3390
    },
    {
      "epoch": 8.695652173913043,
      "grad_norm": 1.2270472049713135,
      "learning_rate": 0.00013043478260869564,
      "loss": 0.0556,
      "step": 3400
    },
    {
      "epoch": 8.721227621483376,
      "grad_norm": 2.6770331859588623,
      "learning_rate": 0.00012787723785166242,
      "loss": 0.0681,
      "step": 3410
    },
    {
      "epoch": 8.746803069053708,
      "grad_norm": 2.260488271713257,
      "learning_rate": 0.00012531969309462915,
      "loss": 0.0517,
      "step": 3420
    },
    {
      "epoch": 8.772378516624041,
      "grad_norm": 1.4671635627746582,
      "learning_rate": 0.00012276214833759592,
      "loss": 0.055,
      "step": 3430
    },
    {
      "epoch": 8.797953964194374,
      "grad_norm": 2.633345127105713,
      "learning_rate": 0.00012020460358056266,
      "loss": 0.0759,
      "step": 3440
    },
    {
      "epoch": 8.823529411764707,
      "grad_norm": 2.101043462753296,
      "learning_rate": 0.00011764705882352942,
      "loss": 0.0543,
      "step": 3450
    },
    {
      "epoch": 8.84910485933504,
      "grad_norm": 2.605454206466675,
      "learning_rate": 0.00011508951406649617,
      "loss": 0.0459,
      "step": 3460
    },
    {
      "epoch": 8.87468030690537,
      "grad_norm": 3.169635534286499,
      "learning_rate": 0.0001125319693094629,
      "loss": 0.06,
      "step": 3470
    },
    {
      "epoch": 8.900255754475703,
      "grad_norm": 0.7837661504745483,
      "learning_rate": 0.00010997442455242967,
      "loss": 0.0619,
      "step": 3480
    },
    {
      "epoch": 8.925831202046036,
      "grad_norm": 2.9332094192504883,
      "learning_rate": 0.00010741687979539642,
      "loss": 0.0658,
      "step": 3490
    },
    {
      "epoch": 8.951406649616368,
      "grad_norm": 2.065887928009033,
      "learning_rate": 0.00010485933503836318,
      "loss": 0.0668,
      "step": 3500
    },
    {
      "epoch": 8.976982097186701,
      "grad_norm": 1.8590641021728516,
      "learning_rate": 0.00010230179028132993,
      "loss": 0.0408,
      "step": 3510
    },
    {
      "epoch": 9.0,
      "eval_accuracy": 0.7798,
      "eval_loss": 1.060359001159668,
      "eval_runtime": 7.4372,
      "eval_samples_per_second": 1344.597,
      "eval_steps_per_second": 10.622,
      "step": 3519
    }
  ],
  "logging_steps": 10,
  "max_steps": 3910,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 128,
  "trial_name": null,
  "trial_params": null
}
