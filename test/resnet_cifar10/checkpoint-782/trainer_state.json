{
  "best_metric": 0.9555377960205078,
  "best_model_checkpoint": "./resnet_cifar10/checkpoint-782",
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 782,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02557544757033248,
      "grad_norm": 6.560461044311523,
      "learning_rate": 0.0009974424552429667,
      "loss": 2.317,
      "step": 10
    },
    {
      "epoch": 0.05115089514066496,
      "grad_norm": 4.858614444732666,
      "learning_rate": 0.0009948849104859335,
      "loss": 1.8972,
      "step": 20
    },
    {
      "epoch": 0.07672634271099744,
      "grad_norm": 3.7562742233276367,
      "learning_rate": 0.0009923273657289002,
      "loss": 1.8483,
      "step": 30
    },
    {
      "epoch": 0.10230179028132992,
      "grad_norm": 3.120326042175293,
      "learning_rate": 0.000989769820971867,
      "loss": 1.6826,
      "step": 40
    },
    {
      "epoch": 0.1278772378516624,
      "grad_norm": 3.0544543266296387,
      "learning_rate": 0.0009872122762148339,
      "loss": 1.6543,
      "step": 50
    },
    {
      "epoch": 0.1534526854219949,
      "grad_norm": 3.704089403152466,
      "learning_rate": 0.0009846547314578005,
      "loss": 1.5913,
      "step": 60
    },
    {
      "epoch": 0.17902813299232737,
      "grad_norm": 3.1817946434020996,
      "learning_rate": 0.0009820971867007674,
      "loss": 1.5538,
      "step": 70
    },
    {
      "epoch": 0.20460358056265984,
      "grad_norm": 3.757596969604492,
      "learning_rate": 0.000979539641943734,
      "loss": 1.5739,
      "step": 80
    },
    {
      "epoch": 0.23017902813299232,
      "grad_norm": 2.931636333465576,
      "learning_rate": 0.000976982097186701,
      "loss": 1.5326,
      "step": 90
    },
    {
      "epoch": 0.2557544757033248,
      "grad_norm": 2.9103219509124756,
      "learning_rate": 0.0009744245524296675,
      "loss": 1.5629,
      "step": 100
    },
    {
      "epoch": 0.2813299232736573,
      "grad_norm": 4.329400539398193,
      "learning_rate": 0.0009718670076726343,
      "loss": 1.4493,
      "step": 110
    },
    {
      "epoch": 0.3069053708439898,
      "grad_norm": 2.3314871788024902,
      "learning_rate": 0.000969309462915601,
      "loss": 1.4526,
      "step": 120
    },
    {
      "epoch": 0.33248081841432225,
      "grad_norm": 4.193652153015137,
      "learning_rate": 0.0009667519181585678,
      "loss": 1.3622,
      "step": 130
    },
    {
      "epoch": 0.35805626598465473,
      "grad_norm": 2.440829038619995,
      "learning_rate": 0.0009641943734015346,
      "loss": 1.4034,
      "step": 140
    },
    {
      "epoch": 0.3836317135549872,
      "grad_norm": 3.6103391647338867,
      "learning_rate": 0.0009616368286445013,
      "loss": 1.3942,
      "step": 150
    },
    {
      "epoch": 0.4092071611253197,
      "grad_norm": 3.0756587982177734,
      "learning_rate": 0.0009590792838874681,
      "loss": 1.3761,
      "step": 160
    },
    {
      "epoch": 0.43478260869565216,
      "grad_norm": 2.746140480041504,
      "learning_rate": 0.0009565217391304348,
      "loss": 1.3243,
      "step": 170
    },
    {
      "epoch": 0.46035805626598464,
      "grad_norm": 5.0564680099487305,
      "learning_rate": 0.0009539641943734016,
      "loss": 1.3155,
      "step": 180
    },
    {
      "epoch": 0.4859335038363171,
      "grad_norm": 3.365220785140991,
      "learning_rate": 0.0009514066496163683,
      "loss": 1.3803,
      "step": 190
    },
    {
      "epoch": 0.5115089514066496,
      "grad_norm": 3.6780784130096436,
      "learning_rate": 0.0009488491048593351,
      "loss": 1.3148,
      "step": 200
    },
    {
      "epoch": 0.5370843989769821,
      "grad_norm": 3.811976909637451,
      "learning_rate": 0.0009462915601023018,
      "loss": 1.2461,
      "step": 210
    },
    {
      "epoch": 0.5626598465473146,
      "grad_norm": 2.9431912899017334,
      "learning_rate": 0.0009437340153452686,
      "loss": 1.2728,
      "step": 220
    },
    {
      "epoch": 0.5882352941176471,
      "grad_norm": 3.7507107257843018,
      "learning_rate": 0.0009411764705882353,
      "loss": 1.2185,
      "step": 230
    },
    {
      "epoch": 0.6138107416879796,
      "grad_norm": 3.129167079925537,
      "learning_rate": 0.0009386189258312021,
      "loss": 1.235,
      "step": 240
    },
    {
      "epoch": 0.639386189258312,
      "grad_norm": 4.862919807434082,
      "learning_rate": 0.0009360613810741688,
      "loss": 1.2238,
      "step": 250
    },
    {
      "epoch": 0.6649616368286445,
      "grad_norm": 4.46756649017334,
      "learning_rate": 0.0009335038363171356,
      "loss": 1.2457,
      "step": 260
    },
    {
      "epoch": 0.690537084398977,
      "grad_norm": 2.6079392433166504,
      "learning_rate": 0.0009309462915601023,
      "loss": 1.268,
      "step": 270
    },
    {
      "epoch": 0.7161125319693095,
      "grad_norm": 2.9999873638153076,
      "learning_rate": 0.0009283887468030691,
      "loss": 1.2259,
      "step": 280
    },
    {
      "epoch": 0.7416879795396419,
      "grad_norm": 4.223467826843262,
      "learning_rate": 0.0009258312020460357,
      "loss": 1.2283,
      "step": 290
    },
    {
      "epoch": 0.7672634271099744,
      "grad_norm": 3.529348850250244,
      "learning_rate": 0.0009232736572890026,
      "loss": 1.1312,
      "step": 300
    },
    {
      "epoch": 0.7928388746803069,
      "grad_norm": 3.623095989227295,
      "learning_rate": 0.0009207161125319693,
      "loss": 1.1911,
      "step": 310
    },
    {
      "epoch": 0.8184143222506394,
      "grad_norm": 2.668268918991089,
      "learning_rate": 0.0009181585677749361,
      "loss": 1.1505,
      "step": 320
    },
    {
      "epoch": 0.8439897698209718,
      "grad_norm": 3.982362985610962,
      "learning_rate": 0.0009156010230179028,
      "loss": 1.1461,
      "step": 330
    },
    {
      "epoch": 0.8695652173913043,
      "grad_norm": 3.5054357051849365,
      "learning_rate": 0.0009130434782608695,
      "loss": 1.0647,
      "step": 340
    },
    {
      "epoch": 0.8951406649616368,
      "grad_norm": 2.5563175678253174,
      "learning_rate": 0.0009104859335038363,
      "loss": 1.1417,
      "step": 350
    },
    {
      "epoch": 0.9207161125319693,
      "grad_norm": 3.4673984050750732,
      "learning_rate": 0.0009079283887468031,
      "loss": 1.1295,
      "step": 360
    },
    {
      "epoch": 0.9462915601023018,
      "grad_norm": 2.978433609008789,
      "learning_rate": 0.0009053708439897699,
      "loss": 1.1051,
      "step": 370
    },
    {
      "epoch": 0.9718670076726342,
      "grad_norm": 2.489053249359131,
      "learning_rate": 0.0009028132992327366,
      "loss": 1.0949,
      "step": 380
    },
    {
      "epoch": 0.9974424552429667,
      "grad_norm": 3.1431591510772705,
      "learning_rate": 0.0009002557544757032,
      "loss": 1.121,
      "step": 390
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.6007,
      "eval_loss": 1.1146992444992065,
      "eval_runtime": 5.4314,
      "eval_samples_per_second": 1841.149,
      "eval_steps_per_second": 14.545,
      "step": 391
    },
    {
      "epoch": 1.0230179028132993,
      "grad_norm": 4.448899745941162,
      "learning_rate": 0.0008976982097186701,
      "loss": 1.0651,
      "step": 400
    },
    {
      "epoch": 1.0485933503836318,
      "grad_norm": 3.4813833236694336,
      "learning_rate": 0.0008951406649616369,
      "loss": 1.0313,
      "step": 410
    },
    {
      "epoch": 1.0741687979539642,
      "grad_norm": 2.946770429611206,
      "learning_rate": 0.0008925831202046036,
      "loss": 1.0673,
      "step": 420
    },
    {
      "epoch": 1.0997442455242967,
      "grad_norm": 3.261096477508545,
      "learning_rate": 0.0008900255754475704,
      "loss": 0.9839,
      "step": 430
    },
    {
      "epoch": 1.1253196930946292,
      "grad_norm": 3.3818960189819336,
      "learning_rate": 0.000887468030690537,
      "loss": 1.0602,
      "step": 440
    },
    {
      "epoch": 1.1508951406649617,
      "grad_norm": 2.843533754348755,
      "learning_rate": 0.0008849104859335039,
      "loss": 1.0689,
      "step": 450
    },
    {
      "epoch": 1.1764705882352942,
      "grad_norm": 2.587015151977539,
      "learning_rate": 0.0008823529411764706,
      "loss": 1.0226,
      "step": 460
    },
    {
      "epoch": 1.2020460358056266,
      "grad_norm": 3.0906779766082764,
      "learning_rate": 0.0008797953964194374,
      "loss": 0.9723,
      "step": 470
    },
    {
      "epoch": 1.227621483375959,
      "grad_norm": 4.502353668212891,
      "learning_rate": 0.0008772378516624041,
      "loss": 1.0007,
      "step": 480
    },
    {
      "epoch": 1.2531969309462916,
      "grad_norm": 4.9666242599487305,
      "learning_rate": 0.0008746803069053708,
      "loss": 0.9993,
      "step": 490
    },
    {
      "epoch": 1.278772378516624,
      "grad_norm": 3.6311213970184326,
      "learning_rate": 0.0008721227621483376,
      "loss": 0.9705,
      "step": 500
    },
    {
      "epoch": 1.3043478260869565,
      "grad_norm": 2.974996566772461,
      "learning_rate": 0.0008695652173913044,
      "loss": 0.9672,
      "step": 510
    },
    {
      "epoch": 1.329923273657289,
      "grad_norm": 3.7065961360931396,
      "learning_rate": 0.0008670076726342711,
      "loss": 0.9438,
      "step": 520
    },
    {
      "epoch": 1.3554987212276215,
      "grad_norm": 3.0875167846679688,
      "learning_rate": 0.0008644501278772379,
      "loss": 0.9346,
      "step": 530
    },
    {
      "epoch": 1.381074168797954,
      "grad_norm": 4.697050094604492,
      "learning_rate": 0.0008618925831202045,
      "loss": 0.9311,
      "step": 540
    },
    {
      "epoch": 1.4066496163682864,
      "grad_norm": 3.054164171218872,
      "learning_rate": 0.0008593350383631714,
      "loss": 0.9316,
      "step": 550
    },
    {
      "epoch": 1.432225063938619,
      "grad_norm": 3.433302164077759,
      "learning_rate": 0.0008567774936061381,
      "loss": 0.9933,
      "step": 560
    },
    {
      "epoch": 1.4578005115089514,
      "grad_norm": 3.011810064315796,
      "learning_rate": 0.0008542199488491049,
      "loss": 0.9616,
      "step": 570
    },
    {
      "epoch": 1.4833759590792839,
      "grad_norm": 2.430619955062866,
      "learning_rate": 0.0008516624040920716,
      "loss": 0.9683,
      "step": 580
    },
    {
      "epoch": 1.5089514066496164,
      "grad_norm": 2.5590744018554688,
      "learning_rate": 0.0008491048593350383,
      "loss": 0.9683,
      "step": 590
    },
    {
      "epoch": 1.5345268542199488,
      "grad_norm": 2.934986114501953,
      "learning_rate": 0.0008465473145780051,
      "loss": 0.9654,
      "step": 600
    },
    {
      "epoch": 1.5601023017902813,
      "grad_norm": 2.549093246459961,
      "learning_rate": 0.0008439897698209719,
      "loss": 0.8943,
      "step": 610
    },
    {
      "epoch": 1.5856777493606138,
      "grad_norm": 2.877986431121826,
      "learning_rate": 0.0008414322250639387,
      "loss": 0.8854,
      "step": 620
    },
    {
      "epoch": 1.6112531969309463,
      "grad_norm": 2.7243399620056152,
      "learning_rate": 0.0008388746803069054,
      "loss": 1.0112,
      "step": 630
    },
    {
      "epoch": 1.6368286445012787,
      "grad_norm": 2.4620625972747803,
      "learning_rate": 0.000836317135549872,
      "loss": 0.9385,
      "step": 640
    },
    {
      "epoch": 1.6624040920716112,
      "grad_norm": 2.871335029602051,
      "learning_rate": 0.0008337595907928389,
      "loss": 0.9123,
      "step": 650
    },
    {
      "epoch": 1.6879795396419437,
      "grad_norm": 2.810047149658203,
      "learning_rate": 0.0008312020460358057,
      "loss": 0.9387,
      "step": 660
    },
    {
      "epoch": 1.7135549872122762,
      "grad_norm": 2.6671440601348877,
      "learning_rate": 0.0008286445012787724,
      "loss": 0.9715,
      "step": 670
    },
    {
      "epoch": 1.7391304347826086,
      "grad_norm": 2.8162333965301514,
      "learning_rate": 0.0008260869565217392,
      "loss": 0.8909,
      "step": 680
    },
    {
      "epoch": 1.7647058823529411,
      "grad_norm": 3.6977391242980957,
      "learning_rate": 0.0008235294117647058,
      "loss": 0.9094,
      "step": 690
    },
    {
      "epoch": 1.7902813299232738,
      "grad_norm": 1.9946739673614502,
      "learning_rate": 0.0008209718670076727,
      "loss": 0.8202,
      "step": 700
    },
    {
      "epoch": 1.815856777493606,
      "grad_norm": 5.790404796600342,
      "learning_rate": 0.0008184143222506394,
      "loss": 0.9057,
      "step": 710
    },
    {
      "epoch": 1.8414322250639388,
      "grad_norm": 2.515369176864624,
      "learning_rate": 0.0008158567774936062,
      "loss": 0.8924,
      "step": 720
    },
    {
      "epoch": 1.867007672634271,
      "grad_norm": 3.3826849460601807,
      "learning_rate": 0.0008132992327365729,
      "loss": 0.8858,
      "step": 730
    },
    {
      "epoch": 1.8925831202046037,
      "grad_norm": 3.340932846069336,
      "learning_rate": 0.0008107416879795396,
      "loss": 0.8784,
      "step": 740
    },
    {
      "epoch": 1.918158567774936,
      "grad_norm": 3.1425461769104004,
      "learning_rate": 0.0008081841432225064,
      "loss": 0.8729,
      "step": 750
    },
    {
      "epoch": 1.9437340153452687,
      "grad_norm": 4.056018829345703,
      "learning_rate": 0.0008056265984654732,
      "loss": 0.8608,
      "step": 760
    },
    {
      "epoch": 1.969309462915601,
      "grad_norm": 2.536066770553589,
      "learning_rate": 0.0008030690537084399,
      "loss": 0.9198,
      "step": 770
    },
    {
      "epoch": 1.9948849104859336,
      "grad_norm": 3.501835584640503,
      "learning_rate": 0.0008005115089514067,
      "loss": 0.8837,
      "step": 780
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.6684,
      "eval_loss": 0.9555377960205078,
      "eval_runtime": 5.426,
      "eval_samples_per_second": 1842.977,
      "eval_steps_per_second": 14.56,
      "step": 782
    }
  ],
  "logging_steps": 10,
  "max_steps": 3910,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 128,
  "trial_name": null,
  "trial_params": null
}
