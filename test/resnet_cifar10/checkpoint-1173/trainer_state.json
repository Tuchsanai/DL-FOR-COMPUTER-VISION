{
  "best_metric": 0.8540481328964233,
  "best_model_checkpoint": "./resnet_cifar10/checkpoint-1173",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 1173,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02557544757033248,
      "grad_norm": 6.560461044311523,
      "learning_rate": 0.0009974424552429667,
      "loss": 2.317,
      "step": 10
    },
    {
      "epoch": 0.05115089514066496,
      "grad_norm": 4.858614444732666,
      "learning_rate": 0.0009948849104859335,
      "loss": 1.8972,
      "step": 20
    },
    {
      "epoch": 0.07672634271099744,
      "grad_norm": 3.7562742233276367,
      "learning_rate": 0.0009923273657289002,
      "loss": 1.8483,
      "step": 30
    },
    {
      "epoch": 0.10230179028132992,
      "grad_norm": 3.120326042175293,
      "learning_rate": 0.000989769820971867,
      "loss": 1.6826,
      "step": 40
    },
    {
      "epoch": 0.1278772378516624,
      "grad_norm": 3.0544543266296387,
      "learning_rate": 0.0009872122762148339,
      "loss": 1.6543,
      "step": 50
    },
    {
      "epoch": 0.1534526854219949,
      "grad_norm": 3.704089403152466,
      "learning_rate": 0.0009846547314578005,
      "loss": 1.5913,
      "step": 60
    },
    {
      "epoch": 0.17902813299232737,
      "grad_norm": 3.1817946434020996,
      "learning_rate": 0.0009820971867007674,
      "loss": 1.5538,
      "step": 70
    },
    {
      "epoch": 0.20460358056265984,
      "grad_norm": 3.757596969604492,
      "learning_rate": 0.000979539641943734,
      "loss": 1.5739,
      "step": 80
    },
    {
      "epoch": 0.23017902813299232,
      "grad_norm": 2.931636333465576,
      "learning_rate": 0.000976982097186701,
      "loss": 1.5326,
      "step": 90
    },
    {
      "epoch": 0.2557544757033248,
      "grad_norm": 2.9103219509124756,
      "learning_rate": 0.0009744245524296675,
      "loss": 1.5629,
      "step": 100
    },
    {
      "epoch": 0.2813299232736573,
      "grad_norm": 4.329400539398193,
      "learning_rate": 0.0009718670076726343,
      "loss": 1.4493,
      "step": 110
    },
    {
      "epoch": 0.3069053708439898,
      "grad_norm": 2.3314871788024902,
      "learning_rate": 0.000969309462915601,
      "loss": 1.4526,
      "step": 120
    },
    {
      "epoch": 0.33248081841432225,
      "grad_norm": 4.193652153015137,
      "learning_rate": 0.0009667519181585678,
      "loss": 1.3622,
      "step": 130
    },
    {
      "epoch": 0.35805626598465473,
      "grad_norm": 2.440829038619995,
      "learning_rate": 0.0009641943734015346,
      "loss": 1.4034,
      "step": 140
    },
    {
      "epoch": 0.3836317135549872,
      "grad_norm": 3.6103391647338867,
      "learning_rate": 0.0009616368286445013,
      "loss": 1.3942,
      "step": 150
    },
    {
      "epoch": 0.4092071611253197,
      "grad_norm": 3.0756587982177734,
      "learning_rate": 0.0009590792838874681,
      "loss": 1.3761,
      "step": 160
    },
    {
      "epoch": 0.43478260869565216,
      "grad_norm": 2.746140480041504,
      "learning_rate": 0.0009565217391304348,
      "loss": 1.3243,
      "step": 170
    },
    {
      "epoch": 0.46035805626598464,
      "grad_norm": 5.0564680099487305,
      "learning_rate": 0.0009539641943734016,
      "loss": 1.3155,
      "step": 180
    },
    {
      "epoch": 0.4859335038363171,
      "grad_norm": 3.365220785140991,
      "learning_rate": 0.0009514066496163683,
      "loss": 1.3803,
      "step": 190
    },
    {
      "epoch": 0.5115089514066496,
      "grad_norm": 3.6780784130096436,
      "learning_rate": 0.0009488491048593351,
      "loss": 1.3148,
      "step": 200
    },
    {
      "epoch": 0.5370843989769821,
      "grad_norm": 3.811976909637451,
      "learning_rate": 0.0009462915601023018,
      "loss": 1.2461,
      "step": 210
    },
    {
      "epoch": 0.5626598465473146,
      "grad_norm": 2.9431912899017334,
      "learning_rate": 0.0009437340153452686,
      "loss": 1.2728,
      "step": 220
    },
    {
      "epoch": 0.5882352941176471,
      "grad_norm": 3.7507107257843018,
      "learning_rate": 0.0009411764705882353,
      "loss": 1.2185,
      "step": 230
    },
    {
      "epoch": 0.6138107416879796,
      "grad_norm": 3.129167079925537,
      "learning_rate": 0.0009386189258312021,
      "loss": 1.235,
      "step": 240
    },
    {
      "epoch": 0.639386189258312,
      "grad_norm": 4.862919807434082,
      "learning_rate": 0.0009360613810741688,
      "loss": 1.2238,
      "step": 250
    },
    {
      "epoch": 0.6649616368286445,
      "grad_norm": 4.46756649017334,
      "learning_rate": 0.0009335038363171356,
      "loss": 1.2457,
      "step": 260
    },
    {
      "epoch": 0.690537084398977,
      "grad_norm": 2.6079392433166504,
      "learning_rate": 0.0009309462915601023,
      "loss": 1.268,
      "step": 270
    },
    {
      "epoch": 0.7161125319693095,
      "grad_norm": 2.9999873638153076,
      "learning_rate": 0.0009283887468030691,
      "loss": 1.2259,
      "step": 280
    },
    {
      "epoch": 0.7416879795396419,
      "grad_norm": 4.223467826843262,
      "learning_rate": 0.0009258312020460357,
      "loss": 1.2283,
      "step": 290
    },
    {
      "epoch": 0.7672634271099744,
      "grad_norm": 3.529348850250244,
      "learning_rate": 0.0009232736572890026,
      "loss": 1.1312,
      "step": 300
    },
    {
      "epoch": 0.7928388746803069,
      "grad_norm": 3.623095989227295,
      "learning_rate": 0.0009207161125319693,
      "loss": 1.1911,
      "step": 310
    },
    {
      "epoch": 0.8184143222506394,
      "grad_norm": 2.668268918991089,
      "learning_rate": 0.0009181585677749361,
      "loss": 1.1505,
      "step": 320
    },
    {
      "epoch": 0.8439897698209718,
      "grad_norm": 3.982362985610962,
      "learning_rate": 0.0009156010230179028,
      "loss": 1.1461,
      "step": 330
    },
    {
      "epoch": 0.8695652173913043,
      "grad_norm": 3.5054357051849365,
      "learning_rate": 0.0009130434782608695,
      "loss": 1.0647,
      "step": 340
    },
    {
      "epoch": 0.8951406649616368,
      "grad_norm": 2.5563175678253174,
      "learning_rate": 0.0009104859335038363,
      "loss": 1.1417,
      "step": 350
    },
    {
      "epoch": 0.9207161125319693,
      "grad_norm": 3.4673984050750732,
      "learning_rate": 0.0009079283887468031,
      "loss": 1.1295,
      "step": 360
    },
    {
      "epoch": 0.9462915601023018,
      "grad_norm": 2.978433609008789,
      "learning_rate": 0.0009053708439897699,
      "loss": 1.1051,
      "step": 370
    },
    {
      "epoch": 0.9718670076726342,
      "grad_norm": 2.489053249359131,
      "learning_rate": 0.0009028132992327366,
      "loss": 1.0949,
      "step": 380
    },
    {
      "epoch": 0.9974424552429667,
      "grad_norm": 3.1431591510772705,
      "learning_rate": 0.0009002557544757032,
      "loss": 1.121,
      "step": 390
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.6007,
      "eval_loss": 1.1146992444992065,
      "eval_runtime": 5.4314,
      "eval_samples_per_second": 1841.149,
      "eval_steps_per_second": 14.545,
      "step": 391
    },
    {
      "epoch": 1.0230179028132993,
      "grad_norm": 4.448899745941162,
      "learning_rate": 0.0008976982097186701,
      "loss": 1.0651,
      "step": 400
    },
    {
      "epoch": 1.0485933503836318,
      "grad_norm": 3.4813833236694336,
      "learning_rate": 0.0008951406649616369,
      "loss": 1.0313,
      "step": 410
    },
    {
      "epoch": 1.0741687979539642,
      "grad_norm": 2.946770429611206,
      "learning_rate": 0.0008925831202046036,
      "loss": 1.0673,
      "step": 420
    },
    {
      "epoch": 1.0997442455242967,
      "grad_norm": 3.261096477508545,
      "learning_rate": 0.0008900255754475704,
      "loss": 0.9839,
      "step": 430
    },
    {
      "epoch": 1.1253196930946292,
      "grad_norm": 3.3818960189819336,
      "learning_rate": 0.000887468030690537,
      "loss": 1.0602,
      "step": 440
    },
    {
      "epoch": 1.1508951406649617,
      "grad_norm": 2.843533754348755,
      "learning_rate": 0.0008849104859335039,
      "loss": 1.0689,
      "step": 450
    },
    {
      "epoch": 1.1764705882352942,
      "grad_norm": 2.587015151977539,
      "learning_rate": 0.0008823529411764706,
      "loss": 1.0226,
      "step": 460
    },
    {
      "epoch": 1.2020460358056266,
      "grad_norm": 3.0906779766082764,
      "learning_rate": 0.0008797953964194374,
      "loss": 0.9723,
      "step": 470
    },
    {
      "epoch": 1.227621483375959,
      "grad_norm": 4.502353668212891,
      "learning_rate": 0.0008772378516624041,
      "loss": 1.0007,
      "step": 480
    },
    {
      "epoch": 1.2531969309462916,
      "grad_norm": 4.9666242599487305,
      "learning_rate": 0.0008746803069053708,
      "loss": 0.9993,
      "step": 490
    },
    {
      "epoch": 1.278772378516624,
      "grad_norm": 3.6311213970184326,
      "learning_rate": 0.0008721227621483376,
      "loss": 0.9705,
      "step": 500
    },
    {
      "epoch": 1.3043478260869565,
      "grad_norm": 2.974996566772461,
      "learning_rate": 0.0008695652173913044,
      "loss": 0.9672,
      "step": 510
    },
    {
      "epoch": 1.329923273657289,
      "grad_norm": 3.7065961360931396,
      "learning_rate": 0.0008670076726342711,
      "loss": 0.9438,
      "step": 520
    },
    {
      "epoch": 1.3554987212276215,
      "grad_norm": 3.0875167846679688,
      "learning_rate": 0.0008644501278772379,
      "loss": 0.9346,
      "step": 530
    },
    {
      "epoch": 1.381074168797954,
      "grad_norm": 4.697050094604492,
      "learning_rate": 0.0008618925831202045,
      "loss": 0.9311,
      "step": 540
    },
    {
      "epoch": 1.4066496163682864,
      "grad_norm": 3.054164171218872,
      "learning_rate": 0.0008593350383631714,
      "loss": 0.9316,
      "step": 550
    },
    {
      "epoch": 1.432225063938619,
      "grad_norm": 3.433302164077759,
      "learning_rate": 0.0008567774936061381,
      "loss": 0.9933,
      "step": 560
    },
    {
      "epoch": 1.4578005115089514,
      "grad_norm": 3.011810064315796,
      "learning_rate": 0.0008542199488491049,
      "loss": 0.9616,
      "step": 570
    },
    {
      "epoch": 1.4833759590792839,
      "grad_norm": 2.430619955062866,
      "learning_rate": 0.0008516624040920716,
      "loss": 0.9683,
      "step": 580
    },
    {
      "epoch": 1.5089514066496164,
      "grad_norm": 2.5590744018554688,
      "learning_rate": 0.0008491048593350383,
      "loss": 0.9683,
      "step": 590
    },
    {
      "epoch": 1.5345268542199488,
      "grad_norm": 2.934986114501953,
      "learning_rate": 0.0008465473145780051,
      "loss": 0.9654,
      "step": 600
    },
    {
      "epoch": 1.5601023017902813,
      "grad_norm": 2.549093246459961,
      "learning_rate": 0.0008439897698209719,
      "loss": 0.8943,
      "step": 610
    },
    {
      "epoch": 1.5856777493606138,
      "grad_norm": 2.877986431121826,
      "learning_rate": 0.0008414322250639387,
      "loss": 0.8854,
      "step": 620
    },
    {
      "epoch": 1.6112531969309463,
      "grad_norm": 2.7243399620056152,
      "learning_rate": 0.0008388746803069054,
      "loss": 1.0112,
      "step": 630
    },
    {
      "epoch": 1.6368286445012787,
      "grad_norm": 2.4620625972747803,
      "learning_rate": 0.000836317135549872,
      "loss": 0.9385,
      "step": 640
    },
    {
      "epoch": 1.6624040920716112,
      "grad_norm": 2.871335029602051,
      "learning_rate": 0.0008337595907928389,
      "loss": 0.9123,
      "step": 650
    },
    {
      "epoch": 1.6879795396419437,
      "grad_norm": 2.810047149658203,
      "learning_rate": 0.0008312020460358057,
      "loss": 0.9387,
      "step": 660
    },
    {
      "epoch": 1.7135549872122762,
      "grad_norm": 2.6671440601348877,
      "learning_rate": 0.0008286445012787724,
      "loss": 0.9715,
      "step": 670
    },
    {
      "epoch": 1.7391304347826086,
      "grad_norm": 2.8162333965301514,
      "learning_rate": 0.0008260869565217392,
      "loss": 0.8909,
      "step": 680
    },
    {
      "epoch": 1.7647058823529411,
      "grad_norm": 3.6977391242980957,
      "learning_rate": 0.0008235294117647058,
      "loss": 0.9094,
      "step": 690
    },
    {
      "epoch": 1.7902813299232738,
      "grad_norm": 1.9946739673614502,
      "learning_rate": 0.0008209718670076727,
      "loss": 0.8202,
      "step": 700
    },
    {
      "epoch": 1.815856777493606,
      "grad_norm": 5.790404796600342,
      "learning_rate": 0.0008184143222506394,
      "loss": 0.9057,
      "step": 710
    },
    {
      "epoch": 1.8414322250639388,
      "grad_norm": 2.515369176864624,
      "learning_rate": 0.0008158567774936062,
      "loss": 0.8924,
      "step": 720
    },
    {
      "epoch": 1.867007672634271,
      "grad_norm": 3.3826849460601807,
      "learning_rate": 0.0008132992327365729,
      "loss": 0.8858,
      "step": 730
    },
    {
      "epoch": 1.8925831202046037,
      "grad_norm": 3.340932846069336,
      "learning_rate": 0.0008107416879795396,
      "loss": 0.8784,
      "step": 740
    },
    {
      "epoch": 1.918158567774936,
      "grad_norm": 3.1425461769104004,
      "learning_rate": 0.0008081841432225064,
      "loss": 0.8729,
      "step": 750
    },
    {
      "epoch": 1.9437340153452687,
      "grad_norm": 4.056018829345703,
      "learning_rate": 0.0008056265984654732,
      "loss": 0.8608,
      "step": 760
    },
    {
      "epoch": 1.969309462915601,
      "grad_norm": 2.536066770553589,
      "learning_rate": 0.0008030690537084399,
      "loss": 0.9198,
      "step": 770
    },
    {
      "epoch": 1.9948849104859336,
      "grad_norm": 3.501835584640503,
      "learning_rate": 0.0008005115089514067,
      "loss": 0.8837,
      "step": 780
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.6684,
      "eval_loss": 0.9555377960205078,
      "eval_runtime": 5.426,
      "eval_samples_per_second": 1842.977,
      "eval_steps_per_second": 14.56,
      "step": 782
    },
    {
      "epoch": 2.020460358056266,
      "grad_norm": 3.667816400527954,
      "learning_rate": 0.0007979539641943733,
      "loss": 0.8098,
      "step": 790
    },
    {
      "epoch": 2.0460358056265986,
      "grad_norm": 2.995882272720337,
      "learning_rate": 0.0007953964194373402,
      "loss": 0.831,
      "step": 800
    },
    {
      "epoch": 2.071611253196931,
      "grad_norm": 2.929013967514038,
      "learning_rate": 0.0007928388746803069,
      "loss": 0.7365,
      "step": 810
    },
    {
      "epoch": 2.0971867007672635,
      "grad_norm": 3.3931901454925537,
      "learning_rate": 0.0007902813299232737,
      "loss": 0.8036,
      "step": 820
    },
    {
      "epoch": 2.122762148337596,
      "grad_norm": 3.471372604370117,
      "learning_rate": 0.0007877237851662404,
      "loss": 0.8213,
      "step": 830
    },
    {
      "epoch": 2.1483375959079285,
      "grad_norm": 3.4239537715911865,
      "learning_rate": 0.0007851662404092071,
      "loss": 0.7979,
      "step": 840
    },
    {
      "epoch": 2.1739130434782608,
      "grad_norm": 2.256803512573242,
      "learning_rate": 0.000782608695652174,
      "loss": 0.7745,
      "step": 850
    },
    {
      "epoch": 2.1994884910485935,
      "grad_norm": 3.219498872756958,
      "learning_rate": 0.0007800511508951407,
      "loss": 0.8004,
      "step": 860
    },
    {
      "epoch": 2.2250639386189257,
      "grad_norm": 2.5375983715057373,
      "learning_rate": 0.0007774936061381073,
      "loss": 0.7752,
      "step": 870
    },
    {
      "epoch": 2.2506393861892584,
      "grad_norm": 2.6708076000213623,
      "learning_rate": 0.0007749360613810742,
      "loss": 0.737,
      "step": 880
    },
    {
      "epoch": 2.2762148337595907,
      "grad_norm": 2.455359935760498,
      "learning_rate": 0.0007723785166240409,
      "loss": 0.6984,
      "step": 890
    },
    {
      "epoch": 2.3017902813299234,
      "grad_norm": 3.8465638160705566,
      "learning_rate": 0.0007698209718670077,
      "loss": 0.7728,
      "step": 900
    },
    {
      "epoch": 2.3273657289002556,
      "grad_norm": 3.5830602645874023,
      "learning_rate": 0.0007672634271099745,
      "loss": 0.7044,
      "step": 910
    },
    {
      "epoch": 2.3529411764705883,
      "grad_norm": 2.8445119857788086,
      "learning_rate": 0.0007647058823529411,
      "loss": 0.7991,
      "step": 920
    },
    {
      "epoch": 2.3785166240409206,
      "grad_norm": 2.5809779167175293,
      "learning_rate": 0.000762148337595908,
      "loss": 0.7518,
      "step": 930
    },
    {
      "epoch": 2.4040920716112533,
      "grad_norm": 2.935708999633789,
      "learning_rate": 0.0007595907928388746,
      "loss": 0.8062,
      "step": 940
    },
    {
      "epoch": 2.4296675191815855,
      "grad_norm": 2.6519179344177246,
      "learning_rate": 0.0007570332480818415,
      "loss": 0.7651,
      "step": 950
    },
    {
      "epoch": 2.455242966751918,
      "grad_norm": 3.164443016052246,
      "learning_rate": 0.0007544757033248082,
      "loss": 0.7522,
      "step": 960
    },
    {
      "epoch": 2.4808184143222505,
      "grad_norm": 2.26080322265625,
      "learning_rate": 0.0007519181585677749,
      "loss": 0.6898,
      "step": 970
    },
    {
      "epoch": 2.506393861892583,
      "grad_norm": 2.3277060985565186,
      "learning_rate": 0.0007493606138107417,
      "loss": 0.7897,
      "step": 980
    },
    {
      "epoch": 2.531969309462916,
      "grad_norm": 3.304030179977417,
      "learning_rate": 0.0007468030690537084,
      "loss": 0.7553,
      "step": 990
    },
    {
      "epoch": 2.557544757033248,
      "grad_norm": 3.5405731201171875,
      "learning_rate": 0.0007442455242966752,
      "loss": 0.7904,
      "step": 1000
    },
    {
      "epoch": 2.5831202046035804,
      "grad_norm": 3.2186787128448486,
      "learning_rate": 0.000741687979539642,
      "loss": 0.7498,
      "step": 1010
    },
    {
      "epoch": 2.608695652173913,
      "grad_norm": 4.007926940917969,
      "learning_rate": 0.0007391304347826086,
      "loss": 0.7168,
      "step": 1020
    },
    {
      "epoch": 2.634271099744246,
      "grad_norm": 3.2454631328582764,
      "learning_rate": 0.0007365728900255755,
      "loss": 0.8082,
      "step": 1030
    },
    {
      "epoch": 2.659846547314578,
      "grad_norm": 3.2967355251312256,
      "learning_rate": 0.0007340153452685422,
      "loss": 0.8149,
      "step": 1040
    },
    {
      "epoch": 2.6854219948849103,
      "grad_norm": 2.959609270095825,
      "learning_rate": 0.000731457800511509,
      "loss": 0.7527,
      "step": 1050
    },
    {
      "epoch": 2.710997442455243,
      "grad_norm": 3.074732542037964,
      "learning_rate": 0.0007289002557544757,
      "loss": 0.7847,
      "step": 1060
    },
    {
      "epoch": 2.7365728900255757,
      "grad_norm": 3.048021078109741,
      "learning_rate": 0.0007263427109974424,
      "loss": 0.7496,
      "step": 1070
    },
    {
      "epoch": 2.762148337595908,
      "grad_norm": 3.4020895957946777,
      "learning_rate": 0.0007237851662404093,
      "loss": 0.7552,
      "step": 1080
    },
    {
      "epoch": 2.78772378516624,
      "grad_norm": 3.2676000595092773,
      "learning_rate": 0.000721227621483376,
      "loss": 0.8071,
      "step": 1090
    },
    {
      "epoch": 2.813299232736573,
      "grad_norm": 2.122976779937744,
      "learning_rate": 0.0007186700767263428,
      "loss": 0.7191,
      "step": 1100
    },
    {
      "epoch": 2.8388746803069056,
      "grad_norm": 2.500875949859619,
      "learning_rate": 0.0007161125319693095,
      "loss": 0.7231,
      "step": 1110
    },
    {
      "epoch": 2.864450127877238,
      "grad_norm": 2.7149910926818848,
      "learning_rate": 0.0007135549872122762,
      "loss": 0.7552,
      "step": 1120
    },
    {
      "epoch": 2.89002557544757,
      "grad_norm": 3.253019094467163,
      "learning_rate": 0.000710997442455243,
      "loss": 0.7377,
      "step": 1130
    },
    {
      "epoch": 2.915601023017903,
      "grad_norm": 4.490123271942139,
      "learning_rate": 0.0007084398976982098,
      "loss": 0.7108,
      "step": 1140
    },
    {
      "epoch": 2.9411764705882355,
      "grad_norm": 3.6895670890808105,
      "learning_rate": 0.0007058823529411765,
      "loss": 0.7647,
      "step": 1150
    },
    {
      "epoch": 2.9667519181585678,
      "grad_norm": 3.415786027908325,
      "learning_rate": 0.0007033248081841433,
      "loss": 0.7193,
      "step": 1160
    },
    {
      "epoch": 2.9923273657289,
      "grad_norm": 2.314748764038086,
      "learning_rate": 0.0007007672634271099,
      "loss": 0.7222,
      "step": 1170
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.7092,
      "eval_loss": 0.8540481328964233,
      "eval_runtime": 5.5515,
      "eval_samples_per_second": 1801.312,
      "eval_steps_per_second": 14.23,
      "step": 1173
    }
  ],
  "logging_steps": 10,
  "max_steps": 3910,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 128,
  "trial_name": null,
  "trial_params": null
}
