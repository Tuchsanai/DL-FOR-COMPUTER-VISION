{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to restart the Kernel. \n",
      "\u001b[1;31mrequest to http://dgx01:9108/api/kernels/1311eb0a-719c-47e2-b120-29495ac7b35a/restart?1712365338495 failed, reason: connect ECONNREFUSED 10.40.29.66:9108. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# Set CUDA_VISIBLE_DEVICES to a specific 7g.80gb MIG device\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1:0\"  # Use MIG 7g.80gb Device 0 under GPU 6\n",
    "\n",
    "# Check the available GPU devices\n",
    "if torch.cuda.is_available():\n",
    "    num_devices = torch.cuda.device_count()\n",
    "    print(f\"Number of available GPU devices: {num_devices}\")\n",
    "    for i in range(num_devices):\n",
    "        device_name = torch.cuda.get_device_name(i)\n",
    "        device_properties = torch.cuda.get_device_properties(i)\n",
    "        total_memory = device_properties.total_memory / (1024 * 1024)  # Convert bytes to MB\n",
    "        device = torch.device(f\"cuda:{i}\")\n",
    "        print(f\"Device {i}: {device}\")\n",
    "        print(f\"Device {i}: {device_name}\")\n",
    "        print(f\"  Total GPU Memory: {total_memory} MB\")\n",
    "else:\n",
    "    print(\"CUDA is not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from   datasets import load_dataset\n",
    "import datasets\n",
    "\n",
    "\n",
    "dataset_name = \"food101\"\n",
    "path_dataset = \"/raid/scratch/tuchsanai/food101\"\n",
    "\n",
    "\n",
    "dataset  = load_dataset(dataset_name, split=\"train[:1000]\")\n",
    "\n",
    "if not os.path.exists(path_dataset):\n",
    "     dataset.save_to_disk(path_dataset)\n",
    "\n",
    "# dataset            =  datasets.load_from_disk(path_dataset)\n",
    "dataset            = dataset.shuffle(seed=42)\n",
    "# Rename the 'label' column to 'labels'\n",
    "dataset = dataset.rename_column(\"label\", \"labels\")\n",
    "\n",
    "\n",
    "train_val_dataset  = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "train_dataset      = train_val_dataset[\"train\"]\n",
    "val_dataset        = train_val_dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = train_val_dataset[\"train\"].features[\"labels\"].names\n",
    "label2id, id2label = dict(), dict()\n",
    "for i, label in enumerate(labels):\n",
    "    label2id[label] = str(i)\n",
    "    id2label[str(i)] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoImageProcessor, AutoModelForImageClassification, TrainingArguments, Trainer\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "# Load the pre-trained model and image processor\n",
    "model_name = \"google/vit-base-patch16-224-in21k\"\n",
    "image_processor = AutoImageProcessor.from_pretrained(model_name)\n",
    "model = AutoModelForImageClassification.from_pretrained(model_name,num_labels=len(labels),id2label=id2label,label2id=label2id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transforms(examples):\n",
    "    examples[\"pixel_values\"] = [jitter(image.convert(\"RGB\")) for image in examples[\"image\"]]\n",
    "    return examples\n",
    "\n",
    "dataset.set_transform(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_transforms(example_batch):\n",
    "    images = [jitter(x) for x in example_batch[\"image\"]]\n",
    "    labels = [x for x in example_batch[\"annotation\"]]\n",
    "    inputs = image_processor(images, labels)\n",
    "    return inputs\n",
    "\n",
    "\n",
    "def val_transforms(example_batch):\n",
    "    images = [x for x in example_batch[\"image\"]]\n",
    "    labels = [x for x in example_batch[\"annotation\"]]\n",
    "    inputs = image_processor(images, labels)\n",
    "    return inputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Preprocess the dataset\n",
    "def preprocess_function(examples):\n",
    "    inputs = image_processor(examples[\"image\"], return_tensors=\"pt\")\n",
    "    inputs[\"labels\"] = examples[\"labels\"]\n",
    "    return inputs\n",
    "\n",
    "\n",
    "\n",
    "processed_dataset = train_val_dataset.map(preprocess_function, batched=True, num_proc=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_processor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "from transformers import AutoModelForImageClassification, TrainingArguments, Trainer\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "# Define the data collator\n",
    "def collate_fn(examples):\n",
    "    pixel_values = torch.stack([torch.tensor(example[\"pixel_values\"]) for example in examples])\n",
    "    labels = torch.tensor([example[\"labels\"] for example in examples])\n",
    "    return {\"pixel_values\": pixel_values, \"labels\": labels}\n",
    "\n",
    "\n",
    "# Define the training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    fp16=True,\n",
    "    remove_unused_columns=False,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=64,\n",
    "    gradient_accumulation_steps=1,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "# Create the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=processed_dataset[\"train\"],\n",
    "    eval_dataset=processed_dataset[\"test\"] ,\n",
    "    tokenizer=image_processor,\n",
    "    data_collator=collate_fn,\n",
    "    compute_metrics=compute_metrics,\n",
    "   \n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "trainer.log_metrics(\"train\", train_results.metrics)\n",
    "trainer.save_metrics(\"train\", train_results.metrics)\n",
    "trainer.save_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
