{"cells":[{"cell_type":"markdown","metadata":{"id":"v5tDiSqVjHux"},"source":["![](https://github.com/rajeevratan84/ModernComputerVision/raw/main/logo_MCV_W.png)\n","\n","# **Neural Style Transfer with OpenCV**\n","\n","####**In this lesson we'll learn how to use pre-trained Models to implement Neural Style Transfer in OpenCV**\n","\n","![](https://github.com/rajeevratan84/ModernComputerVision/raw/main/NSTdemo.png)\n","\n","**About Neural Style Transfers**\n","\n","Introduced by Leon Gatys et al. in 2015, in their paper titled “[A Neural Algorithm for Artistic Style](https://arxiv.org/abs/1508.06576)”, the Neural Style Transfer algorithm went viral resulting in an explosion of further work and mobile apps.\n","\n","Neural Style Transfer enables the artistic style of an image to be applied to another image! It copies the color patterns, combinations, and brush strokes of the original source image and applies it to your input image. And is one the most impressive implementations of Neural Networks in my opinion.\n","\n","![](https://github.com/rajeevratan84/ModernComputerVision/raw/main/NST.png)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7350,"status":"ok","timestamp":1637440522456,"user":{"displayName":"Rajeev Ratan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgtO-hUyDqrPmYR3HGcaXMtwRIq1ObsdPjhiGDSWSw=s64","userId":"08597265227091462140"},"user_tz":0},"id":"YMa6uOqSq1JQ","outputId":"b345deb7-b5c8-4add-b479-33ef11fa7367"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading...\n","From: https://drive.google.com/uc?id=1PXvNLCUxQYx-15S6FnpcnpRLGxp14Ys_\n","To: /content/NeuralStyleTransfer.zip\n","100% 187M/187M [00:01<00:00, 130MB/s]\n"]}],"source":["# import the necessary packages\n","import numpy as np\n","import time\n","import cv2\n","import os\n","from os import listdir\n","from os.path import isfile, join\n","from matplotlib import pyplot as plt \n","\n","# Define our imshow function \n","def imshow(title = \"Image\", image = None, size = 10):\n","    w, h = image.shape[0], image.shape[1]\n","    aspect_ratio = w/h\n","    plt.figure(figsize=(size * aspect_ratio,size))\n","    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n","    plt.title(title)\n","    plt.show()\n","\n","# Download and unzip our images and YOLO files\n","!wget https://moderncomputervision.s3.eu-west-2.amazonaws.com/NeuralStyleTransfer.zip\n","!unzip -qq NeuralStyleTransfer.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1160,"status":"ok","timestamp":1637440523607,"user":{"displayName":"Rajeev Ratan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgtO-hUyDqrPmYR3HGcaXMtwRIq1ObsdPjhiGDSWSw=s64","userId":"08597265227091462140"},"user_tz":0},"id":"n0fQDP3UxJ3A","outputId":"389ef293-9204-43cb-f2b6-26f218b13e4e"},"outputs":[{"name":"stdout","output_type":"stream","text":["--2021-11-20 20:35:22--  https://github.com/rajeevratan84/ModernComputerVision/raw/main/city.jpg\n","Resolving github.com (github.com)... 52.69.186.44\n","Connecting to github.com (github.com)|52.69.186.44|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/rajeevratan84/ModernComputerVision/main/city.jpg [following]\n","--2021-11-20 20:35:22--  https://raw.githubusercontent.com/rajeevratan84/ModernComputerVision/main/city.jpg\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 392132 (383K) [image/jpeg]\n","Saving to: ‘city.jpg’\n","\n","city.jpg            100%[===================>] 382.94K  --.-KB/s    in 0.04s   \n","\n","2021-11-20 20:35:23 (8.75 MB/s) - ‘city.jpg’ saved [392132/392132]\n","\n"]}],"source":["!wget https://github.com/rajeevratan84/ModernComputerVision/raw/main/city.jpg"]},{"cell_type":"markdown","metadata":{"id":"TT7y4eiR1uwU"},"source":["### **Implement Neural Style Transfer using pretrained Models**\n","\n","We use pretrained t7 PyTorch models that can be imported using ``cv2.dnn.readNetFromTouch()```\n","\n","These models we're using come from the paper *Perceptual Losses for Real-Time Style Transfer and Super-Resolution* by Johnson et al. \n","\n","They improved proposing a Neural Style Transfer algorithm that performed 3 times faster by using a super-resolution-like problem based on perceptual loss function."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1ZFAIpKnBQHDbEhpQ8dtrDebA3SIT_Gdl"},"id":"Hza0jpipvl8U","outputId":"2bf9ccfe-5b9d-48a6-bd9d-e7339794055e"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["# Load our t7 neural transfer models\n","model_file_path = \"NeuralStyleTransfer/models/\"\n","model_file_paths = [f for f in listdir(model_file_path) if isfile(join(model_file_path, f))]\n","\n","# Load our test image\n","img = cv2.imread(\"city.jpg\")\n","\n","# Loop through and applying each model style our input image\n","for (i,model) in enumerate(model_file_paths):\n","    # print the model being used\n","    print(str(i+1) + \". Using Model: \" + str(model)[:-3])    \n","    style = cv2.imread(\"NeuralStyleTransfer/art/\"+str(model)[:-3]+\".jpg\")\n","    # loading our neural style transfer model \n","    neuralStyleModel = cv2.dnn.readNetFromTorch(model_file_path+ model)\n","\n","    # Let's resize to a fixed height of 640 (feel free to change)\n","    height, width = int(img.shape[0]), int(img.shape[1])\n","    newWidth = int((640 / height) * width)\n","    resizedImg = cv2.resize(img, (newWidth, 640), interpolation = cv2.INTER_AREA)\n","\n","    # Create our blob from the image and then perform a forward pass run of the network\n","    inpBlob = cv2.dnn.blobFromImage(resizedImg, 1.0, (newWidth, 640), (103.939, 116.779, 123.68), swapRB=False, crop=False)\n","\n","    neuralStyleModel.setInput(inpBlob)\n","    output = neuralStyleModel.forward()\n","\n","    # Reshaping the output tensor, adding back  the mean subtraction and re-ordering the channels \n","    output = output.reshape(3, output.shape[2], output.shape[3])\n","    output[0] += 103.939\n","    output[1] += 116.779\n","    output[2] += 123.68\n","    output /= 255\n","    output = output.transpose(1, 2, 0)\n","    \n","    #Display our original image, the style being applied and the final Neural Style Transfer\n","    imshow(\"Original\", img)\n","    imshow(\"Style\", style)\n","    imshow(\"Neural Style Transfers\", output)"]},{"cell_type":"markdown","metadata":{"id":"5DeMooEJ6KMl"},"source":["## **Using the ECCV16 Updated NST Algorithm**\n","\n","In Ulyanov et al.’s 2017 publication, *Instance Normalization: The Missing Ingredient for Fast Stylization*, it was found that swapping batch normalization for instance normalization (and applying instance normalization at both training and testing), leads to even faster real-time performance and arguably more aesthetically pleasing results as well.\n","\n","Let's now use the models used by Johnson et al. in their ECCV paper.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yrJE2n8J6Jo0"},"outputs":[],"source":["# Load our t7 neural transfer models\n","model_file_path = \"NeuralStyleTransfer/models/ECCV16/\"\n","model_file_paths = [f for f in listdir(model_file_path) if isfile(join(model_file_path, f))]\n","\n","# Load our test image\n","img = cv2.imread(\"city.jpg\")\n","\n","# Loop through and applying each model style our input image\n","for (i,model) in enumerate(model_file_paths):\n","    # print the model being used\n","    print(str(i+1) + \". Using Model: \" + str(model)[:-3])    \n","    style = cv2.imread(\"NeuralStyleTransfer/art/\"+str(model)[:-3]+\".jpg\")\n","    # loading our neural style transfer model \n","    neuralStyleModel = cv2.dnn.readNetFromTorch(model_file_path+ model)\n","\n","    # Let's resize to a fixed height of 640 (feel free to change)\n","    height, width = int(img.shape[0]), int(img.shape[1])\n","    newWidth = int((640 / height) * width)\n","    resizedImg = cv2.resize(img, (newWidth, 640), interpolation = cv2.INTER_AREA)\n","\n","    # Create our blob from the image and then perform a forward pass run of the network\n","    inpBlob = cv2.dnn.blobFromImage(resizedImg, 1.0, (newWidth, 640), (103.939, 116.779, 123.68), swapRB=False, crop=False)\n","\n","    neuralStyleModel.setInput(inpBlob)\n","    output = neuralStyleModel.forward()\n","\n","    # Reshaping the output tensor, adding back  the mean subtraction and re-ordering the channels \n","    output = output.reshape(3, output.shape[2], output.shape[3])\n","    output[0] += 103.939\n","    output[1] += 116.779\n","    output[2] += 123.68\n","    output /= 255\n","    output = output.transpose(1, 2, 0)\n","    \n","    #Display our original image, the style being applied and the final Neural Style Transfer\n","    imshow(\"Original\", img)\n","    imshow(\"Style\", style)\n","    imshow(\"Neural Style Transfers\", output)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":819,"status":"ok","timestamp":1605830252351,"user":{"displayName":"Rajeev Ratan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBYJnwdIGYSJdvGmzIt64rYSF1dDuiFyfRw4Rpeg=s64","userId":"08597265227091462140"},"user_tz":240},"id":"KwxO2qXuxQsp","outputId":"c448369d-73d2-4f52-8bab-68955f34301a"},"outputs":[{"name":"stdout","output_type":"stream","text":["--2020-11-19 23:57:31--  https://github.com/rajeevratan84/ModernComputerVision/raw/main/dj.mp4\n","Resolving github.com (github.com)... 140.82.112.3\n","Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/rajeevratan84/ModernComputerVision/main/dj.mp4 [following]\n","--2020-11-19 23:57:31--  https://raw.githubusercontent.com/rajeevratan84/ModernComputerVision/main/dj.mp4\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 174741 (171K) [application/octet-stream]\n","Saving to: ‘dj.mp4’\n","\n","dj.mp4              100%[===================>] 170.65K  --.-KB/s    in 0.03s   \n","\n","2020-11-19 23:57:32 (5.93 MB/s) - ‘dj.mp4’ saved [174741/174741]\n","\n"]}],"source":["!wget https://github.com/rajeevratan84/ModernComputerVision/raw/main/dj.mp4"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":115817,"status":"ok","timestamp":1605834621241,"user":{"displayName":"Rajeev Ratan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBYJnwdIGYSJdvGmzIt64rYSF1dDuiFyfRw4Rpeg=s64","userId":"08597265227091462140"},"user_tz":240},"id":"N4T20P3hyi2R","outputId":"b8c554a7-7b2a-4142-b4c6-0f59e8a99713"},"outputs":[{"name":"stdout","output_type":"stream","text":["Completed 1 Frame(s)\n","Completed 2 Frame(s)\n","Completed 3 Frame(s)\n","Completed 4 Frame(s)\n","Completed 5 Frame(s)\n","Completed 6 Frame(s)\n","Completed 7 Frame(s)\n","Completed 8 Frame(s)\n","Completed 9 Frame(s)\n","Completed 10 Frame(s)\n","Completed 11 Frame(s)\n","Completed 12 Frame(s)\n","Completed 13 Frame(s)\n","Completed 14 Frame(s)\n","Completed 15 Frame(s)\n","Completed 16 Frame(s)\n","Completed 17 Frame(s)\n","Completed 18 Frame(s)\n","Completed 19 Frame(s)\n","Completed 20 Frame(s)\n","Completed 21 Frame(s)\n","Completed 22 Frame(s)\n","Completed 23 Frame(s)\n","Completed 24 Frame(s)\n","Completed 25 Frame(s)\n","Completed 26 Frame(s)\n","Completed 27 Frame(s)\n","Completed 28 Frame(s)\n","Completed 29 Frame(s)\n","Completed 30 Frame(s)\n","Completed 31 Frame(s)\n","Completed 32 Frame(s)\n","Completed 33 Frame(s)\n"]}],"source":["# Load our t7 neural transfer models\n","model_file_path = \"NeuralStyleTransfer/models/ECCV16/starry_night.t7\"\n","\n","# Load video stream, long clip\n","cap = cv2.VideoCapture('dj.mp4')\n","\n","# Get the height and width of the frame (required to be an interger)\n","w = int(cap.get(3)) \n","h = int(cap.get(4))\n","\n","# Define the codec and create VideoWriter object. The output is stored in '*.avi' file.\n","out = cv2.VideoWriter('NST_Starry_Night.avi', cv2.VideoWriter_fourcc('M','J','P','G'), 30, (w, h))\n","\n","# Loop through and applying each model style our input image\n","#for (i,model) in enumerate(model_file_paths):\n","style = cv2.imread(\"NeuralStyleTransfer/art/starry_night.jpg\")\n","i = 0\n","while(1):\n","\n","    ret, img = cap.read()\n","\n","    if ret == True:  \n","      i += 1\n","      print(\"Completed {} Frame(s)\".format(i))\n","      # loading our neural style transfer model \n","      neuralStyleModel = cv2.dnn.readNetFromTorch(model_file_path)\n","\n","      # Let's resize to a fixed height of 640 (feel free to change)\n","      height, width = int(img.shape[0]), int(img.shape[1])\n","      newWidth = int((640 / height) * width)\n","      resizedImg = cv2.resize(img, (newWidth, 640), interpolation = cv2.INTER_AREA)\n","\n","      # Create our blob from the image and then perform a forward pass run of the network\n","      inpBlob = cv2.dnn.blobFromImage(resizedImg, 1.0, (newWidth, 640),\n","                                (103.939, 116.779, 123.68), swapRB=False, crop=False)\n","\n","      neuralStyleModel.setInput(inpBlob)\n","      output = neuralStyleModel.forward()\n","\n","      # Reshaping the output tensor, adding back  the mean subtraction \n","      # and re-ordering the channels \n","      output = output.reshape(3, output.shape[2], output.shape[3])\n","      output[0] += 103.939\n","      output[1] += 116.779\n","      output[2] += 123.68\n","      output /= 255\n","      output = output.transpose(1, 2, 0)\n","      \n","      #Display our original image, the style being applied and the final Neural Style Transfer\n","      #imshow(\"Original\", img)\n","      #imshow(\"Style\", style)\n","      #imshow(\"Neural Style Transfers\", output)\n","      vid_output = (output * 255).astype(np.uint8)\n","      vid_output = cv2.resize(vid_output, (w, h), interpolation = cv2.INTER_AREA)\n","      out.write(vid_output)\n","    else:\n","      break\n","\n","cap.release()\n","out.release()"]},{"cell_type":"markdown","source":["## **Display your video**"],"metadata":{"id":"lT2qx3vjkmw_"}},{"cell_type":"code","source":["!ffmpeg -i /content/NST_Starry_Night.avi NST_Starry_Night.mp4 -y"],"metadata":{"id":"Xoh5tjVlkivx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from IPython.display import HTML\n","from base64 import b64encode\n"," \n","video_path = '/content/NST_Starry_Night.mp4'\n"," \n","mp4 = open(video_path, \"rb\").read()\n","data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n","HTML(f\"\"\"\n","<video width=600 controls><source src=\"{data_url}\" type=\"video/mp4\">\n","</video>\"\"\")"],"metadata":{"id":"S5k0A0IBkjgs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"btppBi7XIKhp"},"source":["## **Want to train your own NST Model?**\n","\n","## **Look at later sections of the course where we take a look at Implementing our very own Deep Learning NST Algorithm**\n","\n","Alternatively, give this github repo a shot and try it yourself - https://github.com/jcjohnson/fast-neural-style"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"34. Neural Style Transfer with OpenCV.ipynb","provenance":[],"authorship_tag":"ABX9TyNuaIhdcSP1la/6tW8tWhvG"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}