{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e47aa3b8",
   "metadata": {},
   "source": [
    "# üéôÔ∏è Qwen3-TTS Lab: Design Custom Voices with Text Descriptions\n",
    "\n",
    "**Course:** Machine Learning / Deep Learning  \n",
    "**Topic:** Text-to-Speech with Voice Design  \n",
    "**Model:** Qwen3-TTS (Alibaba, January 2025)\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this lab, you will be able to:\n",
    "\n",
    "1. Understand the Qwen3-TTS architecture and model variants\n",
    "2. Set up the environment for TTS generation\n",
    "3. Create custom voices using natural language descriptions\n",
    "4. Use pre-built premium voices with emotion control\n",
    "5. Clone voices from reference audio samples\n",
    "6. Combine voice design and cloning for reusable characters\n",
    "7. Use the speech tokenizer for audio encoding/decoding\n",
    "\n",
    "---\n",
    "\n",
    "## What is Qwen3-TTS?\n",
    "\n",
    "**Qwen3-TTS** is a state-of-the-art text-to-speech model released by Alibaba's Qwen team \n",
    "in January 2025. It represents a major advancement in controllable speech synthesis.\n",
    "\n",
    "### Key Capabilities:\n",
    "\n",
    "| Feature | Description |\n",
    "|---------|-------------|\n",
    "| **Voice Design** | Create new voices from text descriptions |\n",
    "| **Voice Cloning** | Clone any voice from 3-second audio |\n",
    "| **10 Languages** | Chinese, English, Japanese, Korean, German, French, Russian, Portuguese, Spanish, Italian |\n",
    "| **Emotion Control** | Natural language control over tone and emotion |\n",
    "| **Streaming** | Ultra-low latency (97ms first packet) |\n",
    "| **Open Source** | Apache 2.0 license |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04916540",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: Environment Setup\n",
    "\n",
    "First, let's install the required packages and verify our system configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a4fcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1.1: Install Required Packages\n",
    "# Run this cell if packages are not installed\n",
    "# Uncomment to install:\n",
    "!uv pip install -U transformers==4.57.3 numba qwen-tts soundfile \n",
    "# For better performance with FlashAttention 2 (requires compatible GPU):\n",
    "#!pip install -U flash-attn --no-build-isolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d94b523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reinstall torchvision ‡πÉ‡∏´‡πâ match ‡∏Å‡∏±‡∏ö PyTorch + CUDA 12.8\n",
    "!uv pip uninstall torchvision \n",
    "!uv pip install torchvision --index-url https://download.pytorch.org/whl/cu128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef883cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1.2: Import Libraries and Check System\n",
    "\n",
    "import torch\n",
    "import soundfile as sf\n",
    "import os\n",
    "import numpy as np\n",
    "from IPython.display import Audio, display, HTML\n",
    "\n",
    "def print_section(title):\n",
    "    \"\"\"Print a formatted section header\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(f\"  {title}\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "print_section(\"System Information\")\n",
    "\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "    print(f\"GPU Device: {torch.cuda.get_device_name(0)}\")\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    print(f\"GPU Memory: {gpu_memory:.2f} GB\")\n",
    "    \n",
    "    # Check if enough memory for 1.7B model\n",
    "    if gpu_memory >= 8:\n",
    "        print(\"‚úÖ Sufficient GPU memory for 1.7B models\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Limited GPU memory - consider using 0.6B models\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No CUDA GPU detected - will use CPU (slower)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c6599b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Cell 1.3: Create Output Directory\n",
    "\n",
    "OUTPUT_DIR = \"./qwen3_tts_lab_outputs\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "print(f\"‚úÖ Output directory: {OUTPUT_DIR}\")\n",
    "\n",
    "# Helper function to save and play audio\n",
    "def save_and_play(wav, sr, filename, description=\"\"):\n",
    "    \"\"\"Save audio file and display player\"\"\"\n",
    "    filepath = os.path.join(OUTPUT_DIR, filename)\n",
    "    sf.write(filepath, wav, sr)\n",
    "    print(f\"\\nüìÅ Saved: {filepath}\")\n",
    "    if description:\n",
    "        print(f\"   {description}\")\n",
    "    display(Audio(wav, rate=sr))\n",
    "    return filepath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfc100b",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Understanding the Model Family\n",
    "\n",
    "Qwen3-TTS provides several model variants for different use cases:\n",
    "\n",
    "| Model | Size | Purpose | Use Case |\n",
    "|-------|------|---------|----------|\n",
    "| **VoiceDesign** | 1.7B | Create voices from descriptions | Character creation, custom personas |\n",
    "| **CustomVoice** | 0.6B/1.7B | Pre-built premium voices | Quick high-quality TTS |\n",
    "| **Base** | 0.6B/1.7B | Voice cloning | Clone real voices |\n",
    "| **Tokenizer** | - | Audio encoding/decoding | Compression, analysis |\n",
    "\n",
    "### Model Selection Guide:\n",
    "\n",
    "- **1.7B models**: Higher quality, requires ~8GB VRAM\n",
    "- **0.6B models**: Faster, requires ~4GB VRAM\n",
    "- **12Hz tokenizer**: Better compression, newer architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ed4daf",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: Voice Design - Creating Voices from Descriptions\n",
    "\n",
    "The **VoiceDesign** model is the most exciting feature - it allows you to create \n",
    "entirely new voices just by describing them in natural language!\n",
    "\n",
    "### How Voice Design Works:\n",
    "\n",
    "1. You provide a **text** to be spoken\n",
    "2. You provide an **instruction** describing the voice characteristics\n",
    "3. The model generates speech with a voice matching your description\n",
    "\n",
    "### Effective Voice Descriptions Include:\n",
    "\n",
    "- **Demographics**: Age, gender\n",
    "- **Voice Quality**: Deep, bright, raspy, smooth, warm\n",
    "- **Emotion/Tone**: Cheerful, serious, calm, excited\n",
    "- **Speaking Style**: Fast, slow, measured, energetic\n",
    "- **Context**: News anchor, storyteller, teacher, character type\n",
    "\n",
    "### ‚ö†Ô∏è Language Support Note / ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏†‡∏≤‡∏©‡∏≤:\n",
    "\n",
    "**Qwen3-TTS ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö 10 ‡∏†‡∏≤‡∏©‡∏≤:**\n",
    "- Chinese, English, Japanese, Korean\n",
    "- German, French, Russian, Portuguese, Spanish, Italian\n",
    "\n",
    "**‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ (Thai) ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£** - ‡πÅ‡∏ï‡πà‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏ó‡∏î‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏π‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå\n",
    "‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö\n",
    "\n",
    "### Supported Languages Parameter:\n",
    "```python\n",
    "language = \"English\"   # ‚úÖ Supported\n",
    "language = \"Chinese\"   # ‚úÖ Supported  \n",
    "language = \"Japanese\"  # ‚úÖ Supported\n",
    "language = \"Korean\"    # ‚úÖ Supported\n",
    "# Thai ‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏ô official list ‡πÅ‡∏ï‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ó‡∏î‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ \"Chinese\" ‡∏´‡∏£‡∏∑‡∏≠ \"Korean\" ‡πÑ‡∏î‡πâ\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345cf882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3.1: Load the VoiceDesign Model\n",
    "\n",
    "from qwen_tts import Qwen3TTSModel\n",
    "\n",
    "print_section(\"Loading VoiceDesign Model\")\n",
    "print(\"This may take a few minutes on first run (downloading weights)...\")\n",
    "\n",
    "# Model configuration\n",
    "MODEL_NAME = \"Qwen/Qwen3-TTS-12Hz-1.7B-VoiceDesign\"\n",
    "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "DTYPE = torch.bfloat16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "voice_design_model = Qwen3TTSModel.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    device_map=DEVICE,\n",
    "    dtype=DTYPE,\n",
    "    attn_implementation=\"flash_attention_2\" if torch.cuda.is_available() else \"eager\",\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Model loaded successfully!\")\n",
    "print(f\"   Model: {MODEL_NAME}\")\n",
    "print(f\"   Device: {DEVICE}\")\n",
    "print(f\"   Dtype: {DTYPE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385759ff",
   "metadata": {},
   "source": [
    "### 3.2 Basic Examples - English Voice Design\n",
    "\n",
    "‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©‡∏Å‡πà‡∏≠‡∏ô"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedab6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3.2: Example 1 - Professional News Anchor (English)\n",
    "\n",
    "print_section(\"Example 1: Professional News Anchor (English)\")\n",
    "\n",
    "text_en = \"Good evening. Tonight's top story: Scientists have made a groundbreaking discovery in renewable energy that could revolutionize how we power our cities.\"\n",
    "\n",
    "instruction_news = \"\"\"\n",
    "A professional male news anchor in his 40s with a deep, authoritative voice. \n",
    "Clear articulation, measured pace, and confident delivery. \n",
    "The kind of voice you'd hear on a major evening news broadcast.\n",
    "\"\"\"\n",
    "\n",
    "print(f\"üá∫üá∏ Text (English): {text_en[:80]}...\")\n",
    "print(f\"\\nüìù Voice Description:\\n{instruction_news}\")\n",
    "\n",
    "wavs, sr = voice_design_model.generate_voice_design(\n",
    "    text=text_en,\n",
    "    language=\"English\",\n",
    "    instruct=instruction_news,\n",
    ")\n",
    "\n",
    "save_and_play(wavs[0], sr, \"01_news_anchor_en.wav\", \"Professional news anchor voice (English)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e62f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3.3: Example 2 - Warm Storyteller (English)\n",
    "\n",
    "print_section(\"Example 2: Warm Storyteller / Narrator (English)\")\n",
    "\n",
    "text_en = \"Once upon a time, in a small village nestled between rolling hills and ancient forests, there lived a young girl with a curious mind and an adventurous spirit.\"\n",
    "\n",
    "instruction_storyteller = \"\"\"\n",
    "A warm, gentle female storyteller voice, like a grandmother telling bedtime stories.\n",
    "Soft and soothing with natural pauses. Speaks slowly and deliberately, \n",
    "drawing listeners into the narrative. Voice carries wisdom and kindness.\n",
    "\"\"\"\n",
    "\n",
    "print(f\"üá∫üá∏ Text (English): {text_en[:80]}...\")\n",
    "print(f\"\\nüìù Voice Description:\\n{instruction_storyteller}\")\n",
    "\n",
    "wavs, sr = voice_design_model.generate_voice_design(\n",
    "    text=text_en,\n",
    "    language=\"English\",\n",
    "    instruct=instruction_storyteller,\n",
    ")\n",
    "\n",
    "save_and_play(wavs[0], sr, \"02_storyteller_en.wav\", \"Warm storytelling voice (English)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0790c5bd",
   "metadata": {},
   "source": [
    "### 3.3 Thai Language Experiments üáπüá≠\n",
    "\n",
    "‡∏ó‡∏î‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ - ‡πÅ‡∏°‡πâ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏à‡∏∞‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£\n",
    "‡πÅ‡∏ï‡πà‡πÄ‡∏£‡∏≤‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ó‡∏î‡∏•‡∏≠‡∏á‡∏î‡∏π‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÑ‡∏î‡πâ\n",
    "\n",
    "**‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡∏™‡∏±‡∏á‡πÄ‡∏Å‡∏ï:**\n",
    "- ‡∏Å‡∏≤‡∏£‡∏≠‡∏≠‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ß‡∏£‡∏£‡∏ì‡∏¢‡∏∏‡∏Å‡∏ï‡πå\n",
    "- ‡∏Å‡∏≤‡∏£‡πÅ‡∏ö‡πà‡∏á‡∏Ñ‡∏≥‡πÅ‡∏•‡∏∞‡∏ß‡∏£‡∏£‡∏Ñ\n",
    "- ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡∏Ç‡∏≠‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏û‡∏¢‡∏±‡∏ç‡∏ä‡∏ô‡∏∞‡πÅ‡∏•‡∏∞‡∏™‡∏£‡∏∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79b04fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3.4: Thai Storyteller Voice (Experimental)\n",
    "\n",
    "print_section(\"Example 3: Thai Storyteller üáπüá≠ (Experimental)\")\n",
    "\n",
    "text_th = \"\"\"‡∏Å‡∏≤‡∏•‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏ô‡∏≤‡∏ô‡∏°‡∏≤‡πÅ‡∏•‡πâ‡∏ß ‡πÉ‡∏ô‡∏´‡∏°‡∏π‡πà‡∏ö‡πâ‡∏≤‡∏ô‡πÄ‡∏•‡πá‡∏Å‡πÜ ‡∏ó‡∏µ‡πà‡∏ã‡πà‡∏≠‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡∏π‡πà‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏ô‡∏¥‡∏ô‡πÄ‡∏Ç‡∏≤‡πÅ‡∏•‡∏∞‡∏õ‡πà‡∏≤‡πÇ‡∏ö‡∏£‡∏≤‡∏ì \n",
    "‡∏°‡∏µ‡πÄ‡∏î‡πá‡∏Å‡∏´‡∏ç‡∏¥‡∏á‡∏ï‡∏±‡∏ß‡∏ô‡πâ‡∏≠‡∏¢‡∏Ñ‡∏ô‡∏´‡∏ô‡∏∂‡πà‡∏á ‡πÄ‡∏ò‡∏≠‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏≠‡∏¢‡∏≤‡∏Å‡∏£‡∏π‡πâ‡∏≠‡∏¢‡∏≤‡∏Å‡πÄ‡∏´‡πá‡∏ô‡πÅ‡∏•‡∏∞‡∏´‡∏±‡∏ß‡πÉ‡∏à‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏Å‡∏Å‡∏≤‡∏£‡∏ú‡∏à‡∏ç‡∏†‡∏±‡∏¢\"\"\"\n",
    "\n",
    "instruction_th_storyteller = \"\"\"\n",
    "A warm, gentle Thai female storyteller voice, like a grandmother telling bedtime stories.\n",
    "Soft and soothing with natural pauses. Speaks slowly and deliberately.\n",
    "Voice carries wisdom and kindness. Clear Thai pronunciation.\n",
    "\"\"\"\n",
    "\n",
    "print(f\"üáπüá≠ ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° (Thai): {text_th[:60]}...\")\n",
    "print(f\"\\nüìù ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÄ‡∏™‡∏µ‡∏¢‡∏á:\\n{instruction_th_storyteller}\")\n",
    "\n",
    "# ‡∏ó‡∏î‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ language=\"Chinese\" ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏°‡∏µ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤\n",
    "print(\"\\n‚ö†Ô∏è Note: Testing with language='Chinese' as Thai is not officially supported\")\n",
    "\n",
    "wavs, sr = voice_design_model.generate_voice_design(\n",
    "    text=text_th,\n",
    "    language=\"Chinese\",  # ‡∏ó‡∏î‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ Chinese\n",
    "    instruct=instruction_th_storyteller,\n",
    ")\n",
    "\n",
    "save_and_play(wavs[0], sr, \"03_storyteller_th.wav\", \"Thai storyteller voice (Experimental)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab56776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3.5: Thai News Anchor (Experimental)\n",
    "\n",
    "print_section(\"Example 4: Thai News Anchor üáπüá≠ (Experimental)\")\n",
    "\n",
    "text_th_news = \"\"\"‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö ‡∏Ç‡πà‡∏≤‡∏ß‡πÄ‡∏î‡πà‡∏ô‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ ‡∏ô‡∏±‡∏Å‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡∏Ñ‡πâ‡∏ô‡∏û‡∏ö‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡πÉ‡∏´‡∏°‡πà‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ú‡∏•‡∏¥‡∏ï‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô‡∏™‡∏∞‡∏≠‡∏≤‡∏î \n",
    "‡∏ó‡∏µ‡πà‡∏≠‡∏≤‡∏à‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏≠‡∏ô‡∏≤‡∏Ñ‡∏ï‡∏Ç‡∏≠‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÑ‡∏ó‡∏¢‡πÅ‡∏•‡∏∞‡πÇ‡∏•‡∏Å‡πÉ‡∏ö‡∏ô‡∏µ‡πâ\"\"\"\n",
    "\n",
    "instruction_th_news = \"\"\"\n",
    "A professional Thai male news anchor in his 40s with a clear, authoritative voice.\n",
    "Speaks with confidence and measured pace. Clear pronunciation of Thai tones.\n",
    "Professional broadcast quality like Thai evening news.\n",
    "\"\"\"\n",
    "\n",
    "print(f\"üáπüá≠ ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° (Thai): {text_th_news[:60]}...\")\n",
    "print(f\"\\nüìù ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÄ‡∏™‡∏µ‡∏¢‡∏á:\\n{instruction_th_news}\")\n",
    "\n",
    "wavs, sr = voice_design_model.generate_voice_design(\n",
    "    text=text_th_news,\n",
    "    language=\"Chinese\",  # ‡∏ó‡∏î‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ Chinese\n",
    "    instruct=instruction_th_news,\n",
    ")\n",
    "\n",
    "save_and_play(wavs[0], sr, \"04_news_anchor_th.wav\", \"Thai news anchor voice (Experimental)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2634115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3.6: Bilingual Comparison - Same Voice, Two Languages\n",
    "\n",
    "print_section(\"Example 5: Bilingual Comparison üá∫üá∏üáπüá≠\")\n",
    "print(\"‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô ‡∏û‡∏π‡∏î‡∏™‡∏≠‡∏á‡∏†‡∏≤‡∏©‡∏≤\\n\")\n",
    "\n",
    "# ‡πÉ‡∏ä‡πâ voice description ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô\n",
    "instruction_bilingual = \"\"\"\n",
    "A friendly young female teacher in her late 20s. Clear, warm voice with \n",
    "encouraging tone. Speaks at moderate pace with good articulation.\n",
    "Perfect for educational content.\n",
    "\"\"\"\n",
    "\n",
    "# English version\n",
    "text_en_edu = \"Welcome to today's machine learning class. We will learn about neural networks and how they work.\"\n",
    "\n",
    "# Thai version  \n",
    "text_th_edu = \"‡∏¢‡∏¥‡∏ô‡∏î‡∏µ‡∏ï‡πâ‡∏≠‡∏ô‡∏£‡∏±‡∏ö‡∏™‡∏π‡πà‡∏ä‡∏±‡πâ‡∏ô‡πÄ‡∏£‡∏µ‡∏¢‡∏ô Machine Learning ‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö Neural Networks ‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô\"\n",
    "\n",
    "print(f\"üìù Voice Description (same for both):\\n{instruction_bilingual}\")\n",
    "\n",
    "# Generate English\n",
    "print(\"\\nüá∫üá∏ English Version:\")\n",
    "print(f\"   Text: {text_en_edu}\")\n",
    "\n",
    "wavs_en, sr = voice_design_model.generate_voice_design(\n",
    "    text=text_en_edu,\n",
    "    language=\"English\",\n",
    "    instruct=instruction_bilingual,\n",
    ")\n",
    "save_and_play(wavs_en[0], sr, \"05_bilingual_en.wav\", \"Teacher voice - English\")\n",
    "\n",
    "# Generate Thai\n",
    "print(\"\\nüáπüá≠ Thai Version:\")\n",
    "print(f\"   Text: {text_th_edu}\")\n",
    "\n",
    "wavs_th, sr = voice_design_model.generate_voice_design(\n",
    "    text=text_th_edu,\n",
    "    language=\"Chinese\",  # ‡∏ó‡∏î‡∏•‡∏≠‡∏á\n",
    "    instruct=instruction_bilingual,\n",
    ")\n",
    "save_and_play(wavs_th[0], sr, \"05_bilingual_th.wav\", \"Teacher voice - Thai (Experimental)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb86518",
   "metadata": {},
   "source": [
    "### 3.4 Voice Design - Emotional Variations\n",
    "\n",
    "‡∏ó‡∏î‡∏•‡∏≠‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f916b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3.7: Energetic YouTuber (English)\n",
    "\n",
    "print_section(\"Example 6: Energetic YouTuber üé¨\")\n",
    "\n",
    "text_yt = \"Hey everyone! Welcome back to the channel! Today we're diving into something absolutely incredible - you're not gonna believe what we discovered!\"\n",
    "\n",
    "instruction_youtuber = \"\"\"\n",
    "An energetic young male YouTuber in his early 20s. Enthusiastic and slightly fast-paced.\n",
    "Expressive intonation with excitement peaks. Natural, conversational style like \n",
    "talking to friends. High energy but genuine, not forced.\n",
    "\"\"\"\n",
    "\n",
    "print(f\"üá∫üá∏ Text: {text_yt[:80]}...\")\n",
    "print(f\"\\nüìù Voice Description:\\n{instruction_youtuber}\")\n",
    "\n",
    "wavs, sr = voice_design_model.generate_voice_design(\n",
    "    text=text_yt,\n",
    "    language=\"English\",\n",
    "    instruct=instruction_youtuber,\n",
    ")\n",
    "\n",
    "save_and_play(wavs[0], sr, \"06_youtuber_en.wav\", \"Energetic YouTuber voice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76e7ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3.8: Thai YouTuber (Experimental)\n",
    "\n",
    "print_section(\"Example 7: Thai YouTuber üáπüá≠üé¨ (Experimental)\")\n",
    "\n",
    "text_yt_th = \"\"\"‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏ô! ‡∏¢‡∏¥‡∏ô‡∏î‡∏µ‡∏ï‡πâ‡∏≠‡∏ô‡∏£‡∏±‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡∏°‡∏≤‡∏ó‡∏µ‡πà‡∏ä‡πà‡∏≠‡∏á‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á! \n",
    "‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏£‡∏≤‡∏°‡∏µ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏™‡∏∏‡∏î‡πÄ‡∏à‡πã‡∏á‡∏°‡∏≤‡πÄ‡∏•‡πà‡∏≤‡πÉ‡∏´‡πâ‡∏ü‡∏±‡∏á ‡∏û‡∏ß‡∏Å‡∏Ñ‡∏∏‡∏ì‡∏à‡∏∞‡πÑ‡∏°‡πà‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏Ñ‡πâ‡∏ô‡∏û‡∏ö‡πÅ‡∏ô‡πà‡∏ô‡∏≠‡∏ô!\"\"\"\n",
    "\n",
    "instruction_yt_th = \"\"\"\n",
    "An energetic young Thai male YouTuber in his early 20s. Enthusiastic and fast-paced.\n",
    "Very expressive with excitement. Natural Thai speaking style.\n",
    "High energy like popular Thai tech YouTubers.\n",
    "\"\"\"\n",
    "\n",
    "print(f\"üáπüá≠ ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°: {text_yt_th[:60]}...\")\n",
    "print(f\"\\nüìù ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÄ‡∏™‡∏µ‡∏¢‡∏á:\\n{instruction_yt_th}\")\n",
    "\n",
    "wavs, sr = voice_design_model.generate_voice_design(\n",
    "    text=text_yt_th,\n",
    "    language=\"Chinese\",\n",
    "    instruct=instruction_yt_th,\n",
    ")\n",
    "\n",
    "save_and_play(wavs[0], sr, \"07_youtuber_th.wav\", \"Thai YouTuber voice (Experimental)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0bb911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3.9: Calm Meditation Guide (English)\n",
    "\n",
    "print_section(\"Example 8: Calm Meditation Guide üßò\")\n",
    "\n",
    "text_meditation = \"Close your eyes. Take a deep breath in... and slowly release. Feel the tension leaving your body with each exhale. You are safe. You are calm.\"\n",
    "\n",
    "instruction_meditation = \"\"\"\n",
    "A serene, peaceful female voice for guided meditation. Very slow, measured pace\n",
    "with intentional pauses between phrases. Soft, almost whispered tone. \n",
    "Each word flows gently like a calm stream. Deeply relaxing and tranquil.\n",
    "\"\"\"\n",
    "\n",
    "print(f\"üá∫üá∏ Text: {text_meditation[:80]}...\")\n",
    "print(f\"\\nüìù Voice Description:\\n{instruction_meditation}\")\n",
    "\n",
    "wavs, sr = voice_design_model.generate_voice_design(\n",
    "    text=text_meditation,\n",
    "    language=\"English\",\n",
    "    instruct=instruction_meditation,\n",
    ")\n",
    "\n",
    "save_and_play(wavs[0], sr, \"08_meditation_en.wav\", \"Calm meditation guide voice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805c03d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3.10: Thai Meditation Guide (Experimental)\n",
    "\n",
    "print_section(\"Example 9: Thai Meditation Guide üáπüá≠üßò (Experimental)\")\n",
    "\n",
    "text_meditation_th = \"\"\"‡∏´‡∏•‡∏±‡∏ö‡∏ï‡∏≤‡∏•‡∏á... ‡∏´‡∏≤‡∏¢‡πÉ‡∏à‡πÄ‡∏Ç‡πâ‡∏≤‡∏•‡∏∂‡∏Å‡πÜ... ‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡πà‡∏≠‡∏¢‡πÜ ‡∏õ‡∏•‡πà‡∏≠‡∏¢‡∏•‡∏°‡∏´‡∏≤‡∏¢‡πÉ‡∏à‡∏≠‡∏≠‡∏Å \n",
    "‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å‡∏ñ‡∏∂‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡∏∂‡∏á‡πÄ‡∏Ñ‡∏£‡∏µ‡∏¢‡∏î‡∏ó‡∏µ‡πà‡∏Ñ‡πà‡∏≠‡∏¢‡πÜ ‡∏•‡∏∞‡∏•‡∏≤‡∏¢‡∏´‡∏≤‡∏¢‡πÑ‡∏õ‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà‡∏´‡∏≤‡∏¢‡πÉ‡∏à‡∏≠‡∏≠‡∏Å \n",
    "‡∏Ñ‡∏∏‡∏ì‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢... ‡∏Ñ‡∏∏‡∏ì‡∏™‡∏á‡∏ö...\"\"\"\n",
    "\n",
    "instruction_meditation_th = \"\"\"\n",
    "A serene, peaceful Thai female voice for guided meditation. \n",
    "Very slow pace with long pauses. Soft, gentle, almost whispered tone.\n",
    "Deeply relaxing. Clear Thai pronunciation with calming intonation.\n",
    "\"\"\"\n",
    "\n",
    "print(f\"üáπüá≠ ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°: {text_meditation_th[:60]}...\")\n",
    "print(f\"\\nüìù ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÄ‡∏™‡∏µ‡∏¢‡∏á:\\n{instruction_meditation_th}\")\n",
    "\n",
    "wavs, sr = voice_design_model.generate_voice_design(\n",
    "    text=text_meditation_th,\n",
    "    language=\"Korean\",  # ‡∏ó‡∏î‡∏•‡∏≠‡∏á Korean ‡∏î‡∏π‡∏ö‡πâ‡∏≤‡∏á\n",
    "    instruct=instruction_meditation_th,\n",
    ")\n",
    "\n",
    "save_and_play(wavs[0], sr, \"09_meditation_th.wav\", \"Thai meditation guide (Experimental)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eda90c3",
   "metadata": {},
   "source": [
    "### 3.5 Character Voices - Creative Examples\n",
    "\n",
    "‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ï‡∏±‡∏ß‡∏•‡∏∞‡∏Ñ‡∏£‡πÅ‡∏ö‡∏ö‡∏ï‡πà‡∏≤‡∏á‡πÜ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf98d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3.11: Nature Documentary Narrator\n",
    "\n",
    "print_section(\"Example 10: Nature Documentary Narrator üé¨ü¶Å\")\n",
    "\n",
    "text_documentary = \"Deep in the heart of the Amazon rainforest, where sunlight barely reaches the forest floor, a remarkable creature emerges from the shadows.\"\n",
    "\n",
    "instruction_documentary = \"\"\"\n",
    "A mature, authoritative male voice perfect for nature documentaries.\n",
    "Deep, resonant baritone with gravitas. Measured pacing that builds anticipation.\n",
    "Like David Attenborough - conveys wonder and respect for nature.\n",
    "Rich, warm timbre that commands attention.\n",
    "\"\"\"\n",
    "\n",
    "print(f\"üá∫üá∏ Text: {text_documentary[:80]}...\")\n",
    "print(f\"\\nüìù Voice Description:\\n{instruction_documentary}\")\n",
    "\n",
    "wavs, sr = voice_design_model.generate_voice_design(\n",
    "    text=text_documentary,\n",
    "    language=\"English\",\n",
    "    instruct=instruction_documentary,\n",
    ")\n",
    "\n",
    "save_and_play(wavs[0], sr, \"10_documentary_en.wav\", \"Documentary narrator voice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede3751b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3.12: Friendly Robot AI\n",
    "\n",
    "print_section(\"Example 11: Friendly Robot AI ü§ñ\")\n",
    "\n",
    "text_robot = \"Greetings, human. I am your artificial assistant. How may I help you today? I am programmed to be helpful, harmless, and honest.\"\n",
    "\n",
    "instruction_robot = \"\"\"\n",
    "A friendly robot AI assistant voice. Slightly synthetic quality but warm and approachable.\n",
    "Precise articulation with subtle mechanical undertones. Not cold or menacing -\n",
    "think helpful companion robot. Clear enunciation, moderate pace.\n",
    "\"\"\"\n",
    "\n",
    "print(f\"üá∫üá∏ Text: {text_robot[:80]}...\")\n",
    "print(f\"\\nüìù Voice Description:\\n{instruction_robot}\")\n",
    "\n",
    "wavs, sr = voice_design_model.generate_voice_design(\n",
    "    text=text_robot,\n",
    "    language=\"English\",\n",
    "    instruct=instruction_robot,\n",
    ")\n",
    "\n",
    "save_and_play(wavs[0], sr, \"11_robot_en.wav\", \"Friendly robot voice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6da5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3.13: Emotional Delivery - Panic\n",
    "\n",
    "print_section(\"Example 12: Emotional Delivery - Panic üò∞\")\n",
    "\n",
    "text_panic = \"Wait, where is it? I put it right here! It was in this drawer, I'm absolutely certain! Oh no, no, no... this can't be happening!\"\n",
    "\n",
    "instruction_panic = \"\"\"\n",
    "A young woman in her 20s experiencing rising panic. Voice starts confused,\n",
    "then escalates to genuine distress. Breathing becomes faster, pitch rises.\n",
    "Natural emotional progression from confusion to panic. Authentic fear.\n",
    "\"\"\"\n",
    "\n",
    "print(f\"üá∫üá∏ Text: {text_panic[:80]}...\")\n",
    "print(f\"\\nüìù Voice Description:\\n{instruction_panic}\")\n",
    "\n",
    "wavs, sr = voice_design_model.generate_voice_design(\n",
    "    text=text_panic,\n",
    "    language=\"English\",\n",
    "    instruct=instruction_panic,\n",
    ")\n",
    "\n",
    "save_and_play(wavs[0], sr, \"12_panic_en.wav\", \"Panicked emotional voice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d70a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3.14: Thai Character - Wise Elder\n",
    "\n",
    "print_section(\"Example 13: Thai Wise Elder üáπüá≠üë¥ (Experimental)\")\n",
    "\n",
    "text_elder_th = \"\"\"‡∏•‡∏π‡∏Å‡πÄ‡∏≠‡πã‡∏¢ ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏ô‡∏±‡πâ‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏Å‡πá‡∏à‡∏£‡∏¥‡∏á ‡πÅ‡∏ï‡πà‡∏õ‡∏±‡∏ç‡∏ç‡∏≤‡∏ó‡∏µ‡πà‡πÅ‡∏ó‡πâ‡∏à‡∏£‡∏¥‡∏á‡∏ô‡∏±‡πâ‡∏ô‡∏°‡∏≤‡∏à‡∏≤‡∏Å‡∏õ‡∏£‡∏∞‡∏™‡∏ö‡∏Å‡∏≤‡∏£‡∏ì‡πå \n",
    "‡∏à‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏à‡∏≤‡∏Å‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î ‡πÅ‡∏•‡πâ‡∏ß‡πÄ‡∏à‡πâ‡∏≤‡∏à‡∏∞‡πÄ‡∏ï‡∏¥‡∏ö‡πÇ‡∏ï‡∏Ç‡∏∂‡πâ‡∏ô\"\"\"\n",
    "\n",
    "instruction_elder_th = \"\"\"\n",
    "An elderly Thai male voice, like a wise grandfather giving life advice.\n",
    "Slow, deliberate pace with natural pauses for reflection. \n",
    "Warm, kind tone with wisdom in every word. Gentle but carries weight.\n",
    "Traditional Thai elder speaking style.\n",
    "\"\"\"\n",
    "\n",
    "print(f\"üáπüá≠ ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°: {text_elder_th[:60]}...\")\n",
    "print(f\"\\nüìù ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÄ‡∏™‡∏µ‡∏¢‡∏á:\\n{instruction_elder_th}\")\n",
    "\n",
    "wavs, sr = voice_design_model.generate_voice_design(\n",
    "    text=text_elder_th,\n",
    "    language=\"Chinese\",\n",
    "    instruct=instruction_elder_th,\n",
    ")\n",
    "\n",
    "save_and_play(wavs[0], sr, \"13_elder_th.wav\", \"Thai wise elder voice (Experimental)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff65a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3.15: Thai Customer Service\n",
    "\n",
    "print_section(\"Example 14: Thai Customer Service üáπüá≠üìû (Experimental)\")\n",
    "\n",
    "text_service_th = \"\"\"‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡πà‡∏∞ ‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏µ‡πà‡πÇ‡∏ó‡∏£‡∏´‡∏≤‡∏®‡∏π‡∏ô‡∏¢‡πå‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏Ñ‡πà‡∏∞ \n",
    "‡∏î‡∏¥‡∏â‡∏±‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏°‡∏®‡∏£‡∏µ ‡∏¢‡∏¥‡∏ô‡∏î‡∏µ‡πÉ‡∏´‡πâ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏Ñ‡πà‡∏∞ ‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£‡πÉ‡∏´‡πâ‡∏î‡∏¥‡∏â‡∏±‡∏ô‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏Ñ‡∏∞?\"\"\"\n",
    "\n",
    "instruction_service_th = \"\"\"\n",
    "A professional Thai female customer service representative.\n",
    "Polite, warm, and helpful tone. Clear pronunciation with proper Thai \n",
    "polite particles (‡∏Ñ‡πà‡∏∞, ‡∏Ñ‡∏∞). Moderate pace, easy to understand.\n",
    "Professional but friendly, like good Thai customer service.\n",
    "\"\"\"\n",
    "\n",
    "print(f\"üáπüá≠ ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°: {text_service_th[:60]}...\")\n",
    "print(f\"\\nüìù ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÄ‡∏™‡∏µ‡∏¢‡∏á:\\n{instruction_service_th}\")\n",
    "\n",
    "wavs, sr = voice_design_model.generate_voice_design(\n",
    "    text=text_service_th,\n",
    "    language=\"Chinese\",\n",
    "    instruct=instruction_service_th,\n",
    ")\n",
    "\n",
    "save_and_play(wavs[0], sr, \"14_customer_service_th.wav\", \"Thai customer service voice (Experimental)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138df876",
   "metadata": {},
   "source": [
    "### 3.6 Contrast Demo - Same Text, Different Voices\n",
    "\n",
    "‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô\n",
    "‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÄ‡∏´‡πá‡∏ô‡∏ß‡πà‡∏≤ Voice Description ‡∏°‡∏µ‡∏ú‡∏•‡∏ï‡πà‡∏≠‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eadec90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3.16: Contrast Demo - English\n",
    "\n",
    "print_section(\"Example 15: Contrast Demo - Same Text, Different Voices üé≠\")\n",
    "\n",
    "text_contrast = \"The results are in. We've achieved a fifteen percent increase in efficiency.\"\n",
    "\n",
    "voices_contrast = [\n",
    "    {\n",
    "        \"name\": \"Excited Startup CEO\",\n",
    "        \"instruct\": \"An excited young male startup CEO announcing great news. Enthusiastic, slightly fast, building energy. Voice rises with excitement.\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Serious Corporate Executive\",\n",
    "        \"instruct\": \"A serious middle-aged female corporate executive in a board meeting. Professional, measured, matter-of-fact. No emotion, just facts.\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Bored Employee\",\n",
    "        \"instruct\": \"A tired, bored office worker reading numbers. Monotone, low energy, disinterested. Like it's the end of a long day.\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Nervous Intern\",\n",
    "        \"instruct\": \"A nervous young intern presenting for the first time. Slightly shaky voice, uncertain pauses, lacks confidence but trying hard.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"üìù Text (same for all): \\\"{text_contrast}\\\"\\n\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, voice in enumerate(voices_contrast):\n",
    "    print(f\"\\nüé§ Voice {i+1}: {voice['name']}\")\n",
    "    print(f\"   Description: {voice['instruct'][:70]}...\")\n",
    "    \n",
    "    wavs, sr = voice_design_model.generate_voice_design(\n",
    "        text=text_contrast,\n",
    "        language=\"English\",\n",
    "        instruct=voice['instruct'],\n",
    "    )\n",
    "    \n",
    "    filename = f\"15_contrast_{i+1}_{voice['name'].lower().replace(' ', '_')}.wav\"\n",
    "    save_and_play(wavs[0], sr, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac88a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3.17: Contrast Demo - Thai\n",
    "\n",
    "print_section(\"Example 16: Contrast Demo - Thai üáπüá≠üé≠ (Experimental)\")\n",
    "\n",
    "text_contrast_th = \"‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡∏£‡∏±‡∏ö ‡πÄ‡∏£‡∏≤‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡πÑ‡∏î‡πâ‡∏ñ‡∏∂‡∏á‡∏™‡∏¥‡∏ö‡∏´‡πâ‡∏≤‡πÄ‡∏õ‡∏≠‡∏£‡πå‡πÄ‡∏ã‡πá‡∏ô‡∏ï‡πå\"\n",
    "\n",
    "voices_contrast_th = [\n",
    "    {\n",
    "        \"name\": \"Excited Manager\",\n",
    "        \"instruct\": \"An excited Thai male manager announcing good news to his team. Very enthusiastic, fast-paced, voice full of energy and pride.\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Calm Scientist\", \n",
    "        \"instruct\": \"A calm Thai female scientist presenting research findings. Neutral, professional, measured pace. Just stating facts objectively.\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Tired Student\",\n",
    "        \"instruct\": \"A tired Thai university student presenting a project. Low energy, monotone, clearly exhausted from studying all night.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"üìù ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î): \\\"{text_contrast_th}\\\"\\n\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, voice in enumerate(voices_contrast_th):\n",
    "    print(f\"\\nüé§ ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà {i+1}: {voice['name']}\")\n",
    "    print(f\"   ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢: {voice['instruct'][:70]}...\")\n",
    "    \n",
    "    wavs, sr = voice_design_model.generate_voice_design(\n",
    "        text=text_contrast_th,\n",
    "        language=\"Chinese\",  # Experimental for Thai\n",
    "        instruct=voice['instruct'],\n",
    "    )\n",
    "    \n",
    "    filename = f\"16_contrast_th_{i+1}_{voice['name'].lower().replace(' ', '_')}.wav\"\n",
    "    save_and_play(wavs[0], sr, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad025e1e",
   "metadata": {},
   "source": [
    "### 3.7 Technical Terminology Examples\n",
    "\n",
    "‡∏ó‡∏î‡∏•‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏≥‡∏®‡∏±‡∏û‡∏ó‡πå‡∏ó‡∏≤‡∏á‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ - ‡∏ó‡∏±‡πâ‡∏á‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©‡πÅ‡∏•‡∏∞‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏ú‡∏™‡∏°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fa4966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3.18: Technical Content - ML Course Introduction\n",
    "\n",
    "print_section(\"Example 17: ML Course Introduction üìö\")\n",
    "\n",
    "# English version\n",
    "text_ml_en = \"\"\"Today we'll learn about Convolutional Neural Networks, or CNNs.\n",
    "These networks are especially powerful for image recognition tasks.\n",
    "We'll implement one using PyTorch and train it on the CIFAR-10 dataset.\"\"\"\n",
    "\n",
    "instruction_ml = \"\"\"\n",
    "A clear, articulate male university professor in his 30s teaching computer science.\n",
    "Patient and educational tone. Speaks clearly and at moderate pace.\n",
    "Enunciates technical terms carefully. Encouraging and approachable.\n",
    "\"\"\"\n",
    "\n",
    "print(\"üá∫üá∏ English Version:\")\n",
    "print(f\"   Text: {text_ml_en[:80]}...\")\n",
    "\n",
    "wavs, sr = voice_design_model.generate_voice_design(\n",
    "    text=text_ml_en,\n",
    "    language=\"English\",\n",
    "    instruct=instruction_ml,\n",
    ")\n",
    "save_and_play(wavs[0], sr, \"17_ml_course_en.wav\", \"ML Course - English\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61741e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3.19: Thai Technical Content with English Terms\n",
    "\n",
    "print_section(\"Example 18: Thai-English Mixed Technical Content üáπüá≠üíª\")\n",
    "\n",
    "text_ml_th = \"\"\"‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö Convolutional Neural Networks ‡∏´‡∏£‡∏∑‡∏≠ CNNs ‡∏Å‡∏±‡∏ô‡∏Ñ‡∏£‡∏±‡∏ö\n",
    "‡πÄ‡∏Ñ‡∏£‡∏∑‡∏≠‡∏Ç‡πà‡∏≤‡∏¢‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ô‡∏µ‡πâ‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏°‡∏≤‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô Image Recognition\n",
    "‡πÄ‡∏£‡∏≤‡∏à‡∏∞ implement ‡∏î‡πâ‡∏ß‡∏¢ PyTorch ‡πÅ‡∏•‡∏∞ train ‡∏ö‡∏ô CIFAR-10 dataset\"\"\"\n",
    "\n",
    "instruction_ml_th = \"\"\"\n",
    "A clear Thai male university professor teaching computer science.\n",
    "Comfortable mixing Thai and English technical terms naturally.\n",
    "Patient and educational. Moderate pace for student understanding.\n",
    "\"\"\"\n",
    "\n",
    "print(\"üáπüá≠ Thai Version (with English terms):\")\n",
    "print(f\"   ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°: {text_ml_th[:80]}...\")\n",
    "\n",
    "wavs, sr = voice_design_model.generate_voice_design(\n",
    "    text=text_ml_th,\n",
    "    language=\"Chinese\",  # Experimental\n",
    "    instruct=instruction_ml_th,\n",
    ")\n",
    "save_and_play(wavs[0], sr, \"18_ml_course_th.wav\", \"ML Course - Thai (Experimental)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4357e0ac",
   "metadata": {},
   "source": [
    "### 3.8 Voice Description Best Practices Summary\n",
    "\n",
    "‡∏à‡∏≤‡∏Å‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î ‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô Voice Description ‡∏ó‡∏µ‡πà‡∏î‡∏µ:\n",
    "\n",
    "| ‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà | ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏î‡∏µ ‚úÖ | ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏î‡∏µ ‚ùå |\n",
    "|---------|----------------|-------------------|\n",
    "| **‡∏≠‡∏≤‡∏¢‡∏∏/‡πÄ‡∏û‡∏®** | \"A 45-year-old male\" | \"A person\" |\n",
    "| **‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡πÄ‡∏™‡∏µ‡∏¢‡∏á** | \"Deep, resonant baritone\" | \"Nice voice\" |\n",
    "| **‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå** | \"Excited with rising pitch\" | \"Happy\" |\n",
    "| **‡∏ö‡∏£‡∏¥‡∏ö‡∏ó** | \"Like a BBC news anchor\" | \"Professional\" |\n",
    "| **‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß** | \"Slow, measured with pauses\" | \"Normal speed\" |\n",
    "| **‡∏™‡πÑ‡∏ï‡∏•‡πå** | \"Speaks in short, punchy sentences\" | \"Good speaker\" |\n",
    "\n",
    "### Tips for Thai Content:\n",
    "1. ‡∏£‡∏∞‡∏ö‡∏∏‡πÉ‡∏´‡πâ‡∏ä‡∏±‡∏î‡∏ß‡πà‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ \"clear Thai pronunciation\"\n",
    "2. ‡πÉ‡∏™‡πà‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏ó‡∏µ‡πà‡∏Ñ‡∏ô‡πÑ‡∏ó‡∏¢‡∏Ñ‡∏∏‡πâ‡∏ô‡πÄ‡∏Ñ‡∏¢ ‡πÄ‡∏ä‡πà‡∏ô \"like Thai news anchor\"\n",
    "3. ‡∏ó‡∏î‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ `language=\"Chinese\"` ‡∏´‡∏£‡∏∑‡∏≠ `\"Korean\"` ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢\n",
    "4. ‡∏™‡∏±‡∏á‡πÄ‡∏Å‡∏ï‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76204d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3.20: Summary Statistics\n",
    "\n",
    "print_section(\"Part 3 Summary - Generated Audio Files\")\n",
    "\n",
    "# List all files generated in Part 3\n",
    "part3_files = [f for f in os.listdir(OUTPUT_DIR) if f.endswith('.wav')]\n",
    "part3_files.sort()\n",
    "\n",
    "print(f\"\\nüìÅ Total files generated: {len(part3_files)}\")\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "\n",
    "english_files = [f for f in part3_files if '_en' in f or 'contrast_' in f]\n",
    "thai_files = [f for f in part3_files if '_th' in f]\n",
    "\n",
    "print(f\"\\nüá∫üá∏ English examples: {len(english_files)}\")\n",
    "print(f\"üáπüá≠ Thai examples (experimental): {len(thai_files)}\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"\\nAll generated files:\")\n",
    "for f in part3_files:\n",
    "    filepath = os.path.join(OUTPUT_DIR, f)\n",
    "    size = os.path.getsize(filepath) / 1024\n",
    "    print(f\"  ‚Ä¢ {f:<50} {size:>6.1f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207025ae",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4: CustomVoice - Pre-built Premium Speakers\n",
    "\n",
    "If you don't need to design a custom voice, Qwen3-TTS provides **9 pre-built premium voices**\n",
    "that are professionally crafted and ready to use.\n",
    "\n",
    "### Available Speakers:\n",
    "\n",
    "| Speaker | Description | Native Language |\n",
    "|---------|-------------|-----------------|\n",
    "| **Vivian** | Bright, slightly edgy young female | Chinese |\n",
    "| **Serena** | Warm, gentle young female | Chinese |\n",
    "| **Uncle_Fu** | Seasoned male, low mellow timbre | Chinese |\n",
    "| **Dylan** | Youthful Beijing male, clear natural | Chinese (Beijing) |\n",
    "| **Eric** | Lively Chengdu male, slightly husky | Chinese (Sichuan) |\n",
    "| **Ryan** | Dynamic male, strong rhythmic drive | English |\n",
    "| **Aiden** | Sunny American male, clear midrange | English |\n",
    "| **Ono_Anna** | Playful Japanese female, light nimble | Japanese |\n",
    "| **Sohee** | Warm Korean female, rich emotion | Korean |\n",
    "\n",
    "### Note: \n",
    "Each speaker can speak **any supported language**, but sounds best in their native language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1a3859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4.1: Load CustomVoice Model\n",
    "\n",
    "print_section(\"Loading CustomVoice Model\")\n",
    "\n",
    "custom_voice_model = Qwen3TTSModel.from_pretrained(\n",
    "    \"Qwen/Qwen3-TTS-12Hz-1.7B-CustomVoice\",\n",
    "    device_map=DEVICE,\n",
    "    dtype=DTYPE,\n",
    "    attn_implementation=\"flash_attention_2\" if torch.cuda.is_available() else \"eager\",\n",
    ")\n",
    "\n",
    "print(\"‚úÖ CustomVoice Model loaded!\")\n",
    "print(f\"\\nüìã Supported Speakers: {custom_voice_model.get_supported_speakers()}\")\n",
    "print(f\"üìã Supported Languages: {custom_voice_model.get_supported_languages()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add66e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4.2: Basic CustomVoice - English Speakers\n",
    "\n",
    "print_section(\"CustomVoice: English Speakers\")\n",
    "\n",
    "text = \"Hello! Welcome to our artificial intelligence course. Today we'll explore the fascinating world of neural networks.\"\n",
    "\n",
    "# Ryan - Dynamic male\n",
    "print(\"\\nüé§ Speaker: Ryan (Dynamic male, strong rhythmic drive)\")\n",
    "wavs, sr = custom_voice_model.generate_custom_voice(\n",
    "    text=text,\n",
    "    language=\"English\",\n",
    "    speaker=\"Ryan\",\n",
    ")\n",
    "save_and_play(wavs[0], sr, \"19_ryan_normal.wav\", \"Ryan - Normal\")\n",
    "\n",
    "# Aiden - Sunny American male  \n",
    "print(\"\\nüé§ Speaker: Aiden (Sunny American male, clear midrange)\")\n",
    "wavs, sr = custom_voice_model.generate_custom_voice(\n",
    "    text=text,\n",
    "    language=\"English\",\n",
    "    speaker=\"Aiden\",\n",
    ")\n",
    "save_and_play(wavs[0], sr, \"19_aiden_normal.wav\", \"Aiden - Normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d62fc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4.3: CustomVoice with Emotion Instructions\n",
    "\n",
    "print_section(\"CustomVoice with Emotion Control\")\n",
    "\n",
    "text = \"I can't believe it actually worked! After all these months of trying, we finally did it!\"\n",
    "\n",
    "emotions = [\n",
    "    (\"Normal\", \"\"),\n",
    "    (\"Very excited\", \"Speak with extreme excitement and joy, like winning the lottery!\"),\n",
    "    (\"Exhausted relief\", \"Speak with exhausted relief, like finally finishing a marathon.\"),\n",
    "    (\"Skeptical\", \"Speak with skepticism, like you're not quite sure it's real.\"),\n",
    "]\n",
    "\n",
    "print(f\"Text: \\\"{text}\\\"\\n\")\n",
    "print(\"Speaker: Ryan\\n\")\n",
    "\n",
    "for emotion_name, instruction in emotions:\n",
    "    print(f\"üé≠ Emotion: {emotion_name}\")\n",
    "    \n",
    "    wavs, sr = custom_voice_model.generate_custom_voice(\n",
    "        text=text,\n",
    "        language=\"English\",\n",
    "        speaker=\"Ryan\",\n",
    "        instruct=instruction if instruction else None,\n",
    "    )\n",
    "    \n",
    "    filename = f\"20_ryan_{emotion_name.lower().replace(' ', '_')}.wav\"\n",
    "    save_and_play(wavs[0], sr, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53747241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4.4: Batch Generation with Multiple Speakers\n",
    "\n",
    "print_section(\"Batch Generation: Multiple Speakers\")\n",
    "\n",
    "# Same text, different speakers\n",
    "text = \"Welcome to the international AI conference. We're excited to have participants from around the world.\"\n",
    "\n",
    "speakers_to_demo = [\"Ryan\", \"Aiden\", \"Vivian\", \"Ono_Anna\"]\n",
    "\n",
    "print(f\"Text: \\\"{text}\\\"\\n\")\n",
    "\n",
    "for speaker in speakers_to_demo:\n",
    "    print(f\"\\nüé§ Speaker: {speaker}\")\n",
    "    \n",
    "    wavs, sr = custom_voice_model.generate_custom_voice(\n",
    "        text=text,\n",
    "        language=\"English\",  # All speakers can speak English\n",
    "        speaker=speaker,\n",
    "    )\n",
    "    \n",
    "    save_and_play(wavs[0], sr, f\"21_batch_{speaker.lower()}.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b969c0f",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 5: Voice Cloning\n",
    "\n",
    "The **Base** model allows you to clone any voice from a short audio sample (3+ seconds).\n",
    "This is incredibly powerful for:\n",
    "\n",
    "- Creating consistent character voices for games/animations\n",
    "- Personalizing TTS with a specific voice\n",
    "- Audiobook narration matching original author's voice\n",
    "\n",
    "### How Voice Cloning Works:\n",
    "\n",
    "1. Provide a **reference audio** (3+ seconds)\n",
    "2. Provide the **transcript** of the reference audio\n",
    "3. Provide the **new text** you want spoken\n",
    "4. The model generates the new text in the cloned voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dbd9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5.1: Load Base Model for Cloning\n",
    "\n",
    "print_section(\"Loading Base Model for Voice Cloning\")\n",
    "\n",
    "clone_model = Qwen3TTSModel.from_pretrained(\n",
    "    \"Qwen/Qwen3-TTS-12Hz-1.7B-Base\",\n",
    "    device_map=DEVICE,\n",
    "    dtype=DTYPE,\n",
    "    attn_implementation=\"flash_attention_2\" if torch.cuda.is_available() else \"eager\",\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Base Model (Voice Cloning) loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab48610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5.2: Basic Voice Cloning from URL\n",
    "\n",
    "print_section(\"Voice Cloning Example\")\n",
    "\n",
    "\n",
    "# Reference audio from Qwen's repository\n",
    "ref_audio_url = \"lisa3.wav\"\n",
    "ref_text = \"‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡πà‡∏∞ ‡∏ß‡∏π‡πâ‡∏î‡∏î‡∏µ‡πâ‡πÑ‡∏ó‡∏¢‡πÅ‡∏•‡∏ô‡∏î‡πå ‡∏•‡∏¥‡∏ã‡πà‡∏≤‡∏ô‡∏∞‡∏Ñ‡∏∞ ‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡∏û‡∏ß‡∏Å‡πÄ‡∏£‡∏≤‡∏≠‡∏¢‡∏π‡πà‡∏ó‡∏µ‡πà ALTER EGO POP-UP IN BANGKOK ‡∏Ñ‡πà‡∏∞ ‡πÄ‡∏Ñ‡∏£‡∏µ‡∏¢‡∏î ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏°‡∏±‡∏ô‡∏°‡∏≠‡∏á‡πÑ‡∏°‡πà‡πÄ‡∏´‡πá‡∏ô‡∏≠‡∏ô‡∏≤‡∏Ñ‡∏ï‡∏≠‡∏±‡∏ô‡πÉ‡∏Å‡∏•‡πâ‡∏´‡∏•‡∏∞ ‡πÅ‡∏Ñ‡πà‡πÅ‡∏ö‡∏ö‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤ ‡πÄ‡∏£‡∏≤‡∏Å‡πá‡πÑ‡∏°‡πà‡∏£‡∏π‡πâ‡∏ß‡πà‡∏≤‡∏°‡∏±‡∏ô‡∏à‡∏∞‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÑ‡∏´‡∏ô ‡πÄ‡∏£‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ñ‡∏≤‡∏° ‡∏õ‡∏£‡∏∂‡∏Å‡∏©‡∏≤ ‡πÄ‡∏£‡∏≤‡∏°‡∏µ‡πÅ‡∏Ñ‡πà‡∏ó‡∏µ‡∏°‡πÄ‡∏£‡∏≤ ‡πÅ‡∏Ñ‡πà‡∏ô‡∏±‡πâ‡∏ô ‡πÅ‡∏ï‡πà‡∏°‡∏±‡∏ô‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏±‡∏ô‡∏ï‡∏µ‡∏ß‡πà‡∏≤‡∏°‡∏±‡∏ô‡∏à‡∏∞‡πÇ‡∏≠‡πÄ‡∏Ñ ‡∏°‡∏±‡∏ô‡∏à‡∏∞‡πÄ‡∏ß‡∏¥‡∏£‡πå‡∏Ñ‡πÉ‡∏ä‡πà‡πÑ‡∏´‡∏° ‡∏™‡∏£‡∏∏‡∏õ‡πÅ‡∏•‡πâ‡∏ß\"\n",
    "\n",
    "# New text to generate with cloned voice\n",
    "new_text = \"‡∏•‡∏¥‡∏ã‡πà‡∏≤‡∏ô‡∏∞‡∏Ñ‡∏∞ ‡∏ó‡∏∏‡∏Å‡πÜ‡∏Ñ‡∏ô ‡πÄ‡∏™‡∏≤‡∏£‡πå‡∏ô‡∏µ‡πâ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÑ‡∏î‡πâ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏ö‡πâ‡∏≤‡∏ô‡∏ó‡∏µ‡πà ‡∏™‡∏ô‡∏∏‡∏Å‡∏™‡∏ô‡∏≤‡∏ô ‡πÅ‡∏•‡∏∞ ‡∏ó‡πâ‡∏≤‡∏ó‡∏≤‡∏¢ ‡∏°‡∏≤‡∏•‡∏∏‡πâ‡∏ô‡∏Å‡∏±‡∏ô‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤‡∏Å‡∏≤‡∏£‡∏ö‡πâ‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á‡∏ß‡∏±‡∏ô‡πÄ‡∏™‡∏≤‡∏£‡πå‡∏ô‡∏µ‡πâ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£\"\n",
    "\n",
    "\n",
    "print(f\"Reference Audio: {ref_audio_url}\")\n",
    "print(f\"Reference Text: \\\"{ref_text}\\\"\")\n",
    "print(f\"\\nNew Text to Generate: \\\"{new_text}\\\"\")\n",
    "\n",
    "wavs, sr = clone_model.generate_voice_clone(\n",
    "    text=new_text,\n",
    "    language=\"Chinese\",\n",
    "    ref_audio=ref_audio_url,\n",
    "    ref_text=ref_text,\n",
    ")\n",
    "\n",
    "save_and_play(wavs[0], sr, \"22_voice_clone_basic.wav\", \"Cloned voice speaking new text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898c54d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5.3: Reusable Voice Clone Prompt\n",
    "\n",
    "print_section(\"Creating Reusable Voice Clone Prompt\")\n",
    "\n",
    "print(\"Creating a voice prompt that can be reused for multiple generations...\")\n",
    "print(\"(This avoids re-computing features for each generation)\\n\")\n",
    "\n",
    "# Create the prompt once\n",
    "voice_prompt = clone_model.create_voice_clone_prompt(\n",
    "    ref_audio=ref_audio_url,\n",
    "    ref_text=ref_text,\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Voice prompt created!\")\n",
    "\n",
    "# Generate multiple sentences with the same voice\n",
    "sentences = [\n",
    "    \"Chapter one. Introduction to Neural Networks.\",\n",
    "    \"In the beginning, researchers tried to mimic the human brain.\",\n",
    "    \"Today, we have models with billions of parameters.\",\n",
    "]\n",
    "\n",
    "print(\"\\nüìñ Generating multiple sentences with reusable prompt:\\n\")\n",
    "\n",
    "for i, sentence in enumerate(sentences):\n",
    "    print(f\"Sentence {i+1}: \\\"{sentence}\\\"\")\n",
    "    \n",
    "    wavs, sr = clone_model.generate_voice_clone(\n",
    "        text=sentence,\n",
    "        language=\"Chinese\",\n",
    "        voice_clone_prompt=voice_prompt,  # Reuse the prompt\n",
    "    )\n",
    "    \n",
    "    save_and_play(wavs[0], sr, f\"23_clone_reuse_{i+1}.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430a3873",
   "metadata": {},
   "source": [
    "### 5.4 Voice Cloning - Multiple Reference Scenarios\n",
    "\n",
    "Let's explore more advanced voice cloning scenarios including:\n",
    "- Cloning from different audio sources\n",
    "- Cross-language voice cloning\n",
    "- Emotional variation with cloned voices\n",
    "- Creating character voice variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d864e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5.5: Story Narration with Cloned Voice\n",
    "\n",
    "print_section(\"Voice Cloning: Story Narration\")\n",
    "\n",
    "print(\"Creating a short story narration with consistent cloned voice\\n\")\n",
    "\n",
    "story_segments = [\n",
    "    \"‡∏°‡∏µ‡πÄ‡∏î‡πá‡∏Å‡∏´‡∏ç‡∏¥‡∏á‡∏Ñ‡∏ô‡∏´‡∏ô‡∏∂‡πà‡∏á ‡πÄ‡∏ò‡∏≠‡∏ä‡∏≠‡∏ö‡πÄ‡∏î‡∏¥‡∏ô‡πÄ‡∏•‡πà‡∏ô‡πÉ‡∏ô‡∏õ‡πà‡∏≤‡∏ó‡∏∏‡∏Å‡∏ß‡∏±‡∏ô\",\n",
    "    \"‡∏ß‡∏±‡∏ô‡∏´‡∏ô‡∏∂‡πà‡∏á ‡πÄ‡∏ò‡∏≠‡∏û‡∏ö‡∏Å‡∏£‡∏∞‡∏ï‡πà‡∏≤‡∏¢‡∏ï‡∏±‡∏ß‡∏ô‡πâ‡∏≠‡∏¢‡∏ó‡∏µ‡πà‡∏ö‡∏≤‡∏î‡πÄ‡∏à‡πá‡∏ö\",\n",
    "    \"‡πÄ‡∏ò‡∏≠‡∏à‡∏∂‡∏á‡∏û‡∏≤‡∏Å‡∏£‡∏∞‡∏ï‡πà‡∏≤‡∏¢‡∏Å‡∏•‡∏±‡∏ö‡∏ö‡πâ‡∏≤‡∏ô‡πÅ‡∏•‡∏∞‡∏î‡∏π‡πÅ‡∏•‡∏°‡∏±‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏î‡∏µ\",\n",
    "    \"‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏ô‡∏±‡πâ‡∏ô‡πÑ‡∏°‡πà‡∏ô‡∏≤‡∏ô ‡∏Å‡∏£‡∏∞‡∏ï‡πà‡∏≤‡∏¢‡∏Å‡πá‡∏´‡∏≤‡∏¢‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏Å‡∏ï‡∏¥ ‡πÅ‡∏•‡∏∞‡∏Å‡∏•‡∏≤‡∏¢‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏Ç‡∏≠‡∏á‡πÄ‡∏ò‡∏≠\",\n",
    "]\n",
    "\n",
    "print(\"üìñ Story: The Girl and the Rabbit\\n\")\n",
    "\n",
    "for i, segment in enumerate(story_segments):\n",
    "    print(f\"Part {i+1}: {segment}\")\n",
    "    \n",
    "    wavs, sr = clone_model.generate_voice_clone(\n",
    "        text=segment,\n",
    "        language=\"Chinese\",\n",
    "        voice_clone_prompt=voice_prompt,\n",
    "        instruct=\"Speak like a gentle storyteller, with warm tone and natural pauses.\",\n",
    "    )\n",
    "    \n",
    "    save_and_play(wavs[0], sr, f\"29_story_part_{i+1}.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5a66ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5.6: Educational Content with Cloned Voice\n",
    "\n",
    "print_section(\"Voice Cloning: Educational Tutorial\")\n",
    "\n",
    "print(\"Creating an educational tutorial with cloned voice\\n\")\n",
    "\n",
    "tutorial_steps = [\n",
    "    \"‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡πà‡∏∞ ‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏°‡∏≤‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö Machine Learning ‡∏Å‡∏±‡∏ô‡∏ô‡∏∞‡∏Ñ‡∏∞\",\n",
    "    \"‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡πÅ‡∏£‡∏Å ‡πÄ‡∏£‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° dataset ‡πÉ‡∏´‡πâ‡∏û‡∏£‡πâ‡∏≠‡∏°\",\n",
    "    \"‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏≠‡∏á ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏ó‡∏≥‡∏Å‡∏≤‡∏£ train model ‡∏î‡πâ‡∏ß‡∏¢ PyTorch\",\n",
    "    \"‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢ ‡πÄ‡∏£‡∏≤‡∏à‡∏∞ evaluate ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á model\",\n",
    "    \"‡∏Ç‡∏≠‡πÉ‡∏´‡πâ‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏ô‡πÇ‡∏ä‡∏Ñ‡∏î‡∏µ‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏ô‡∏∞‡∏Ñ‡∏∞\",\n",
    "]\n",
    "\n",
    "print(\"üéì Tutorial: Machine Learning Basics\\n\")\n",
    "\n",
    "for i, step in enumerate(tutorial_steps):\n",
    "    print(f\"Step {i+1}: {step}\")\n",
    "    \n",
    "    wavs, sr = clone_model.generate_voice_clone(\n",
    "        text=step,\n",
    "        language=\"Chinese\",\n",
    "        voice_clone_prompt=voice_prompt,\n",
    "        instruct=\"Speak like a clear, patient teacher explaining to students. Moderate pace, encouraging tone.\",\n",
    "    )\n",
    "    \n",
    "    save_and_play(wavs[0], sr, f\"30_tutorial_step_{i+1}.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7929a4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5.7: Podcast Introduction with Cloned Voice\n",
    "\n",
    "print_section(\"Voice Cloning: Podcast Style\")\n",
    "\n",
    "print(\"Creating podcast segments with cloned voice\\n\")\n",
    "\n",
    "podcast_segments = [\n",
    "    {\n",
    "        \"type\": \"intro\",\n",
    "        \"text\": \"‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡πà‡∏∞‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏ô ‡∏¢‡∏¥‡∏ô‡∏î‡∏µ‡∏ï‡πâ‡∏≠‡∏ô‡∏£‡∏±‡∏ö‡∏™‡∏π‡πà Podcast ‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ‡πÅ‡∏•‡∏∞‡∏ô‡∏ß‡∏±‡∏ï‡∏Å‡∏£‡∏£‡∏°\",\n",
    "        \"instruction\": \"Speak with energy and enthusiasm like a podcast host welcoming listeners.\"\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"topic\",\n",
    "        \"text\": \"‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏£‡∏≤‡∏°‡∏µ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏ô‡πà‡∏≤‡∏™‡∏ô‡πÉ‡∏à‡∏°‡∏≤‡∏Å ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏°‡∏≤‡∏Ñ‡∏∏‡∏¢‡∏Å‡∏±‡∏ô‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á AI ‡πÅ‡∏•‡∏∞‡∏≠‡∏ô‡∏≤‡∏Ñ‡∏ï‡∏Ç‡∏≠‡∏á‡∏°‡∏ô‡∏∏‡∏©‡∏¢‡∏ä‡∏≤‡∏ï‡∏¥\",\n",
    "        \"instruction\": \"Speak with curiosity and intrigue, building interest in the topic.\"\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"question\",\n",
    "        \"text\": \"‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏Ñ‡∏¢‡∏™‡∏á‡∏™‡∏±‡∏¢‡πÑ‡∏´‡∏°‡∏Ñ‡∏∞‡∏ß‡πà‡∏≤ AI ‡∏à‡∏∞‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏ä‡∏µ‡∏ß‡∏¥‡∏ï‡πÄ‡∏£‡∏≤‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£‡πÉ‡∏ô‡∏≠‡∏µ‡∏Å 10 ‡∏õ‡∏µ‡∏Ç‡πâ‡∏≤‡∏á‡∏´‡∏ô‡πâ‡∏≤?\",\n",
    "        \"instruction\": \"Ask the question thoughtfully, encouraging listeners to reflect.\"\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"outro\",\n",
    "        \"text\": \"‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏ö‡∏ü‡∏±‡∏á‡∏ô‡∏∞‡∏Ñ‡∏∞ ‡∏û‡∏ö‡∏Å‡∏±‡∏ô‡πÉ‡∏´‡∏°‡πà‡πÉ‡∏ô Episode ‡∏´‡∏ô‡πâ‡∏≤ ‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡πà‡∏∞\",\n",
    "        \"instruction\": \"Speak warmly like saying goodbye to friends, with gratitude.\"\n",
    "    },\n",
    "]\n",
    "\n",
    "print(\"üéôÔ∏è Podcast: Technology and Innovation\\n\")\n",
    "\n",
    "for i, segment in enumerate(podcast_segments):\n",
    "    print(f\"\\n{segment['type'].upper()}: {segment['text'][:60]}...\")\n",
    "    \n",
    "    wavs, sr = clone_model.generate_voice_clone(\n",
    "        text=segment['text'],\n",
    "        language=\"Chinese\",\n",
    "        voice_clone_prompt=voice_prompt,\n",
    "        instruct=segment['instruction'],\n",
    "    )\n",
    "    \n",
    "    filename = f\"31_podcast_{i+1}_{segment['type']}.wav\"\n",
    "    save_and_play(wavs[0], sr, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ba15ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5.8: Character Dialogue with Multiple Cloned Voices\n",
    "\n",
    "print_section(\"Voice Cloning: Multi-Character Dialogue\")\n",
    "\n",
    "print(\"Creating a dialogue between two characters using voice cloning\\n\")\n",
    "\n",
    "# For this example, we'll create two different \"versions\" of the same voice\n",
    "# In practice, you would clone two different reference voices\n",
    "\n",
    "dialogue = [\n",
    "    {\n",
    "        \"character\": \"Lisa (Excited)\",\n",
    "        \"text\": \"‡πÄ‡∏Æ‡πâ! ‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏´‡πá‡∏ô‡∏Ç‡πà‡∏≤‡∏ß‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏ä‡πâ‡∏≤‡∏ô‡∏µ‡πâ‡πÑ‡∏´‡∏°? ‡∏°‡∏±‡∏ô‡∏ô‡πà‡∏≤‡∏ï‡∏∑‡πà‡∏ô‡πÄ‡∏ï‡πâ‡∏ô‡∏°‡∏≤‡∏Å‡πÄ‡∏•‡∏¢!\",\n",
    "        \"instruction\": \"Speak with high energy and excitement, very enthusiastic!\"\n",
    "    },\n",
    "    {\n",
    "        \"character\": \"Lisa (Curious)\",\n",
    "        \"text\": \"‡∏Ç‡πà‡∏≤‡∏ß‡∏≠‡∏∞‡πÑ‡∏£‡∏´‡∏£‡∏≠? ‡πÄ‡∏•‡πà‡∏≤‡∏´‡∏ô‡πà‡∏≠‡∏¢‡∏™‡∏¥ ‡∏â‡∏±‡∏ô‡∏≠‡∏¢‡∏≤‡∏Å‡∏£‡∏π‡πâ‡∏à‡∏±‡∏á\",\n",
    "        \"instruction\": \"Speak with curiosity and interest, asking questions naturally.\"\n",
    "    },\n",
    "    {\n",
    "        \"character\": \"Lisa (Excited)\",\n",
    "        \"text\": \"‡πÄ‡∏Ç‡∏≤‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏®‡πÅ‡∏•‡πâ‡∏ß‡∏ß‡πà‡∏≤‡∏à‡∏∞‡∏°‡∏µ AI ‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏°‡∏ô‡∏∏‡∏©‡∏¢‡πå‡πÑ‡∏î‡πâ!\",\n",
    "        \"instruction\": \"Speak with amazement and share exciting news enthusiastically.\"\n",
    "    },\n",
    "    {\n",
    "        \"character\": \"Lisa (Thoughtful)\",\n",
    "        \"text\": \"‡πÇ‡∏≠‡πâ‡∏ß... ‡∏ô‡πà‡∏≤‡∏™‡∏ô‡πÉ‡∏à‡∏à‡∏±‡∏á ‡πÅ‡∏ï‡πà‡∏°‡∏±‡∏ô‡∏à‡∏∞‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢‡πÑ‡∏´‡∏°‡∏ô‡∏∞?\",\n",
    "        \"instruction\": \"Speak thoughtfully and contemplatively, showing some concern.\"\n",
    "    },\n",
    "]\n",
    "\n",
    "print(\"üé≠ Dialogue: AI News Discussion\\n\")\n",
    "\n",
    "for i, line in enumerate(dialogue):\n",
    "    print(f\"\\n{line['character']}: {line['text']}\")\n",
    "    \n",
    "    wavs, sr = clone_model.generate_voice_clone(\n",
    "        text=line['text'],\n",
    "        language=\"Chinese\",\n",
    "        voice_clone_prompt=voice_prompt,\n",
    "        instruct=line['instruction'],\n",
    "    )\n",
    "    \n",
    "    filename = f\"32_dialogue_{i+1}_{line['character'].lower().replace(' ', '_').replace('(', '').replace(')', '')}.wav\"\n",
    "    save_and_play(wavs[0], sr, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1596a0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5.9: News Broadcast with Cloned Voice\n",
    "\n",
    "print_section(\"Voice Cloning: News Broadcast Style\")\n",
    "\n",
    "print(\"Creating news segments with cloned voice\\n\")\n",
    "\n",
    "news_segments = [\n",
    "    {\n",
    "        \"type\": \"headline\",\n",
    "        \"text\": \"‡∏Ç‡πà‡∏≤‡∏ß‡∏î‡πà‡∏ß‡∏ô ‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÑ‡∏ó‡∏¢‡∏õ‡∏£‡∏∞‡∏™‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤ AI ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢\",\n",
    "        \"instruction\": \"Speak like a professional news anchor delivering breaking news, serious and authoritative.\"\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"detail\",\n",
    "        \"text\": \"‡∏ô‡∏±‡∏Å‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡∏à‡∏≤‡∏Å‡∏°‡∏´‡∏≤‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏•‡∏±‡∏¢‡∏ä‡∏±‡πâ‡∏ô‡∏ô‡∏≥‡πÑ‡∏î‡πâ‡∏û‡∏±‡∏í‡∏ô‡∏≤‡∏£‡∏∞‡∏ö‡∏ö AI ‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥\",\n",
    "        \"instruction\": \"Speak clearly and informatively, providing details professionally.\"\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"quote\",\n",
    "        \"text\": \"‡∏ú‡∏π‡πâ‡∏≠‡∏≥‡∏ô‡∏ß‡∏¢‡∏Å‡∏≤‡∏£‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡∏Å‡∏•‡πà‡∏≤‡∏ß‡∏ß‡πà‡∏≤ ‡∏ô‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡πâ‡∏≤‡∏ß‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÑ‡∏ó‡∏¢\",\n",
    "        \"instruction\": \"Speak in reporting style, quoting someone else's words.\"\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"closing\",\n",
    "        \"text\": \"‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏Ç‡πà‡∏≤‡∏ß‡∏à‡∏≤‡∏Å ‡∏•‡∏¥‡∏ã‡πà‡∏≤ ‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏£‡∏±‡∏ö\",\n",
    "        \"instruction\": \"Speak professionally like signing off from a news report.\"\n",
    "    },\n",
    "]\n",
    "\n",
    "print(\"üì∫ News Report: Thai AI Development\\n\")\n",
    "\n",
    "for i, segment in enumerate(news_segments):\n",
    "    print(f\"\\n[{segment['type'].upper()}]\")\n",
    "    print(f\"Text: {segment['text']}\")\n",
    "    \n",
    "    wavs, sr = clone_model.generate_voice_clone(\n",
    "        text=segment['text'],\n",
    "        language=\"Chinese\",\n",
    "        voice_clone_prompt=voice_prompt,\n",
    "        instruct=segment['instruction'],\n",
    "    )\n",
    "    \n",
    "    filename = f\"33_news_{i+1}_{segment['type']}.wav\"\n",
    "    save_and_play(wavs[0], sr, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0992e350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5.10: Voice Cloning Speed Variations\n",
    "\n",
    "print_section(\"Voice Cloning: Speed & Pace Variations\")\n",
    "\n",
    "print(\"Testing different speaking speeds with the same cloned voice\\n\")\n",
    "\n",
    "test_text = \"‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ Machine Learning ‡∏ô‡∏±‡πâ‡∏ô‡∏™‡∏ô‡∏∏‡∏Å‡πÅ‡∏•‡∏∞‡∏ó‡πâ‡∏≤‡∏ó‡∏≤‡∏¢‡πÉ‡∏ô‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô\"\n",
    "\n",
    "speed_variations = [\n",
    "    (\"Very Slow\", \"Speak very slowly and deliberately, with long pauses between words.\"),\n",
    "    (\"Slow\", \"Speak slowly and carefully, giving time for understanding.\"),\n",
    "    (\"Normal\", None),\n",
    "    (\"Fast\", \"Speak quickly and energetically, with rapid delivery.\"),\n",
    "    (\"Very Fast\", \"Speak very rapidly like in a fast-paced advertisement.\"),\n",
    "]\n",
    "\n",
    "print(f\"üìù Test Text: \\\"{test_text}\\\"\\n\")\n",
    "\n",
    "for speed_name, instruction in speed_variations:\n",
    "    print(f\"‚è±Ô∏è Speed: {speed_name}\")\n",
    "    \n",
    "    wavs, sr = clone_model.generate_voice_clone(\n",
    "        text=test_text,\n",
    "        language=\"Chinese\",\n",
    "        voice_clone_prompt=voice_prompt,\n",
    "        instruct=instruction,\n",
    "    )\n",
    "    \n",
    "    filename = f\"34_speed_{speed_name.lower().replace(' ', '_')}.wav\"\n",
    "    save_and_play(wavs[0], sr, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683fd732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5.11: Cloned Voice for Product Advertisement\n",
    "\n",
    "print_section(\"Voice Cloning: Product Advertisement\")\n",
    "\n",
    "print(\"Creating advertisement copy with cloned voice\\n\")\n",
    "\n",
    "ad_script = [\n",
    "    {\n",
    "        \"segment\": \"hook\",\n",
    "        \"text\": \"‡∏Ñ‡∏∏‡∏ì‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏°‡∏≠‡∏á‡∏´‡∏≤‡∏Ñ‡∏≠‡∏£‡πå‡∏™‡πÄ‡∏£‡∏µ‡∏¢‡∏ô AI ‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ä‡πà‡πÑ‡∏´‡∏°‡∏Ñ‡∏∞?\",\n",
    "        \"instruction\": \"Speak with curiosity and engagement, asking a question that captures attention.\"\n",
    "    },\n",
    "    {\n",
    "        \"segment\": \"feature\",\n",
    "        \"text\": \"‡πÄ‡∏£‡∏≤‡∏°‡∏µ‡∏Ñ‡∏≠‡∏£‡πå‡∏™‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏û‡∏≤‡∏Ñ‡∏∏‡∏ì‡πÑ‡∏õ‡∏à‡∏≤‡∏Å‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏à‡∏ô‡∏ñ‡∏∂‡∏á‡∏£‡∏∞‡∏î‡∏±‡∏ö Expert\",\n",
    "        \"instruction\": \"Speak with confidence and promise, highlighting the benefit.\"\n",
    "    },\n",
    "    {\n",
    "        \"segment\": \"benefit\",\n",
    "        \"text\": \"‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÅ‡∏ö‡∏ö hands-on ‡∏Å‡∏±‡∏ö‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ‡∏à‡∏£‡∏¥‡∏á ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡πÅ‡∏Ñ‡πà‡∏ó‡∏§‡∏©‡∏é‡∏µ\",\n",
    "        \"instruction\": \"Speak persuasively, emphasizing the unique value proposition.\"\n",
    "    },\n",
    "    {\n",
    "        \"segment\": \"cta\",\n",
    "        \"text\": \"‡∏•‡∏á‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ ‡∏£‡∏±‡∏ö‡∏™‡πà‡∏ß‡∏ô‡∏•‡∏î 50% ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö 100 ‡∏Ñ‡∏ô‡πÅ‡∏£‡∏Å‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô!\",\n",
    "        \"instruction\": \"Speak with urgency and excitement, encouraging immediate action!\"\n",
    "    },\n",
    "]\n",
    "\n",
    "print(\"üì¢ Advertisement: AI Course Promotion\\n\")\n",
    "\n",
    "for i, segment in enumerate(ad_script):\n",
    "    print(f\"\\n[{segment['segment'].upper()}]\")\n",
    "    print(f\"{segment['text']}\")\n",
    "    \n",
    "    wavs, sr = clone_model.generate_voice_clone(\n",
    "        text=segment['text'],\n",
    "        language=\"Chinese\",\n",
    "        voice_clone_prompt=voice_prompt,\n",
    "        instruct=segment['instruction'],\n",
    "    )\n",
    "    \n",
    "    filename = f\"35_ad_{i+1}_{segment['segment']}.wav\"\n",
    "    save_and_play(wavs[0], sr, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ef7021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5.12: Voice Clone Summary Statistics\n",
    "\n",
    "print_section(\"Voice Cloning Summary\")\n",
    "\n",
    "# Count files generated in Part 5\n",
    "clone_files = [f for f in os.listdir(OUTPUT_DIR) \n",
    "               if f.endswith('.wav') and any(x in f for x in ['28_', '29_', '30_', '31_', '32_', '33_', '34_', '35_'])]\n",
    "clone_files.sort()\n",
    "\n",
    "print(f\"\\nüìä Voice Cloning Examples Generated: {len(clone_files)}\")\n",
    "print(\"\\nCategories:\")\n",
    "print(f\"  üé≠ Emotional Variations: {len([f for f in clone_files if '28_clone_emotion' in f])}\")\n",
    "print(f\"  üìñ Story Narration: {len([f for f in clone_files if '29_story' in f])}\")\n",
    "print(f\"  üéì Educational Content: {len([f for f in clone_files if '30_tutorial' in f])}\")\n",
    "print(f\"  üéôÔ∏è Podcast Style: {len([f for f in clone_files if '31_podcast' in f])}\")\n",
    "print(f\"  üé≠ Character Dialogue: {len([f for f in clone_files if '32_dialogue' in f])}\")\n",
    "print(f\"  üì∫ News Broadcast: {len([f for f in clone_files if '33_news' in f])}\")\n",
    "print(f\"  ‚è±Ô∏è Speed Variations: {len([f for f in clone_files if '34_speed' in f])}\")\n",
    "print(f\"  üì¢ Advertisement: {len([f for f in clone_files if '35_ad' in f])}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üí° Key Takeaways from Voice Cloning:\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\"\"\n",
    "1. ‚úÖ One voice can express many emotions through instructions\n",
    "2. ‚úÖ Cloned voices maintain consistency across long content\n",
    "3. ‚úÖ Speaking speed and style can be controlled via instructions\n",
    "4. ‚úÖ Same voice works for different contexts (education, news, ads)\n",
    "5. ‚úÖ Voice cloning is powerful for creating character consistency\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237b025a",
   "metadata": {},
   "source": [
    "### 5.13 Advanced Tips for Voice Cloning\n",
    "\n",
    "**Best Practices:**\n",
    "\n",
    "1. **Reference Audio Quality**\n",
    "   - Use clean audio without background noise\n",
    "   - At least 3 seconds of continuous speech\n",
    "   - Clear pronunciation and good recording quality\n",
    "\n",
    "2. **Reference Text Accuracy**\n",
    "   - Transcript must match the audio exactly\n",
    "   - Include punctuation for natural pauses\n",
    "   - Match the language of the audio\n",
    "\n",
    "3. **Instruction Effectiveness**\n",
    "   - Be specific about emotion and style\n",
    "   - Reference concrete examples (\"like a news anchor\")\n",
    "   - Combine multiple attributes (pace + emotion + tone)\n",
    "\n",
    "4. **Reusable Prompts**\n",
    "   - Create prompts once for multiple generations\n",
    "   - Saves computation time\n",
    "   - Ensures consistency across all outputs\n",
    "\n",
    "5. **Language Mixing**\n",
    "   - For Thai content, experiment with `language=\"Chinese\"` or `\"Korean\"`\n",
    "   - English instructions work even for non-English content\n",
    "   - Test different language parameters for best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4997ae",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Cell 5.13: Bonus - Batch Processing Multiple Texts\n",
    "\n",
    "print_section(\"Bonus: Batch Voice Cloning\")\n",
    "\n",
    "print(\"Efficiently generating multiple audio files with the same cloned voice\\n\")\n",
    "\n",
    "batch_texts = [\n",
    "    \"‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏´‡∏ô‡∏∂‡πà‡∏á: AI ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡πÇ‡∏•‡∏Å\",\n",
    "    \"‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏™‡∏≠‡∏á: Machine Learning ‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏ô‡∏≤‡∏Ñ‡∏ï‡∏Ç‡∏≠‡∏á‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ\",\n",
    "    \"‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏°: Deep Learning ‡∏ó‡∏≥‡πÉ‡∏´‡πâ AI ‡∏â‡∏•‡∏≤‡∏î‡∏Ç‡∏∂‡πâ‡∏ô\",\n",
    "    \"‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏™‡∏µ‡πà: Neural Networks ‡πÄ‡∏•‡∏µ‡∏¢‡∏ô‡πÅ‡∏ö‡∏ö‡∏™‡∏°‡∏≠‡∏á‡∏°‡∏ô‡∏∏‡∏©‡∏¢‡πå\",\n",
    "    \"‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏´‡πâ‡∏≤: ‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏ö‡∏ü‡∏±‡∏á‡∏ô‡∏∞‡∏Ñ‡∏∞\",\n",
    "]\n",
    "\n",
    "print(f\"Generating {len(batch_texts)} audio files in batch mode...\\n\")\n",
    "\n",
    "batch_instruction = \"Speak clearly and professionally, like presenting to an audience.\"\n",
    "\n",
    "for i, text in enumerate(batch_texts):\n",
    "    print(f\"[{i+1}/{len(batch_texts)}] {text[:50]}...\")\n",
    "    \n",
    "    wavs, sr = clone_model.generate_voice_clone(\n",
    "        text=text,\n",
    "        language=\"Chinese\",\n",
    "        voice_clone_prompt=voice_prompt,\n",
    "        instruct=batch_instruction,\n",
    "    )\n",
    "    \n",
    "    save_and_play(wavs[0], sr, f\"36_batch_{i+1}.wav\")\n",
    "\n",
    "print(f\"\\n‚úÖ Batch processing complete! Generated {len(batch_texts)} files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1fdc1a",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 6: Advanced Workflow - Voice Design ‚Üí Clone\n",
    "\n",
    "A powerful technique is to combine **Voice Design** and **Voice Cloning**:\n",
    "\n",
    "1. **Design** a unique voice using natural language description\n",
    "2. **Clone** that designed voice for consistent reuse\n",
    "\n",
    "This is perfect for creating consistent character voices from scratch!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58abca67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6.1: Create Character Voice with Design\n",
    "\n",
    "print_section(\"Advanced: Voice Design ‚Üí Clone Workflow\")\n",
    "\n",
    "print(\"Step 1: Design a character voice\\n\")\n",
    "\n",
    "# Define the character\n",
    "character_name = \"Professor Maxwell\"\n",
    "character_ref_text = \"Welcome, students. Today we embark on a journey through the fundamentals of quantum mechanics.\"\n",
    "character_description = \"\"\"\n",
    "An elderly British male professor in his 60s. Distinguished, intellectual voice with \n",
    "a slight Oxford accent. Warm but authoritative. Speaks deliberately with natural \n",
    "academic cadence. Think of a beloved university professor who makes complex \n",
    "topics accessible.\n",
    "\"\"\"\n",
    "\n",
    "print(f\"Character: {character_name}\")\n",
    "print(f\"Description: {character_description}\")\n",
    "\n",
    "# Generate reference audio with VoiceDesign\n",
    "ref_wavs, sr = voice_design_model.generate_voice_design(\n",
    "    text=character_ref_text,\n",
    "    language=\"English\",\n",
    "    instruct=character_description,\n",
    ")\n",
    "\n",
    "save_and_play(ref_wavs[0], sr, \"24_character_reference.wav\", f\"{character_name} - Reference Audio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c32cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6.2: Create Clone Prompt from Designed Voice\n",
    "\n",
    "print(\"\\nStep 2: Create reusable clone prompt from designed voice\\n\")\n",
    "\n",
    "character_prompt = clone_model.create_voice_clone_prompt(\n",
    "    ref_audio=(ref_wavs[0], sr),  # Pass the numpy array directly\n",
    "    ref_text=character_ref_text,\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Character clone prompt created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da590cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6.3: Generate Multiple Lines as Character\n",
    "\n",
    "print(\"\\nStep 3: Generate dialogue lines with character voice\\n\")\n",
    "\n",
    "lecture_lines = [\n",
    "    \"Now, let's consider Schr√∂dinger's famous thought experiment with the cat.\",\n",
    "    \"The beauty of quantum mechanics lies in its counterintuitive nature.\",\n",
    "    \"Don't worry if this seems confusing at first. Even Einstein struggled with these concepts.\",\n",
    "    \"For your homework, please read chapters three and four by next Tuesday.\",\n",
    "]\n",
    "\n",
    "print(f\"Generating {len(lecture_lines)} lines as {character_name}:\\n\")\n",
    "\n",
    "for i, line in enumerate(lecture_lines):\n",
    "    print(f\"Line {i+1}: \\\"{line[:50]}...\\\"\")\n",
    "    \n",
    "    wavs, sr = clone_model.generate_voice_clone(\n",
    "        text=line,\n",
    "        language=\"English\",\n",
    "        voice_clone_prompt=character_prompt,\n",
    "    )\n",
    "    \n",
    "    save_and_play(wavs[0], sr, f\"25_professor_line_{i+1}.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3655c434",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 7: Speech Tokenizer\n",
    "\n",
    "The **Qwen3-TTS-Tokenizer** converts audio to/from discrete tokens.\n",
    "This is useful for:\n",
    "\n",
    "- **Audio compression**: Represent audio as compact token sequences\n",
    "- **Model training**: Prepare data for fine-tuning\n",
    "- **Audio analysis**: Study the acoustic representation\n",
    "\n",
    "### Tokenizer Specifications:\n",
    "\n",
    "- **12Hz**: 12 tokens per second of audio\n",
    "- **Multi-codebook**: 16 layers of codes for high fidelity\n",
    "- **Efficient**: Extreme compression with good quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc7f4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7.1: Load Tokenizer\n",
    "\n",
    "from qwen_tts import Qwen3TTSTokenizer\n",
    "\n",
    "print_section(\"Loading Speech Tokenizer\")\n",
    "\n",
    "tokenizer = Qwen3TTSTokenizer.from_pretrained(\n",
    "    \"Qwen/Qwen3-TTS-Tokenizer-12Hz\",\n",
    "    device_map=DEVICE,\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Tokenizer loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffc3d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7.2: Encode and Decode Audio\n",
    "\n",
    "print_section(\"Audio Encoding/Decoding\")\n",
    "\n",
    "# Use sample audio\n",
    "sample_audio_url = \"https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3-TTS-Repo/tokenizer_demo_1.wav\"\n",
    "\n",
    "print(f\"Original audio: {sample_audio_url}\\n\")\n",
    "\n",
    "# Encode\n",
    "print(\"Encoding audio to tokens...\")\n",
    "encoded = tokenizer.encode(sample_audio_url)\n",
    "print(f\"‚úÖ Encoded shape: {encoded.shape}\")\n",
    "print(f\"   Sequence length: {encoded.shape[1]} frames\")\n",
    "print(f\"   At 12Hz = {encoded.shape[1]/12:.2f} seconds of audio\")\n",
    "\n",
    "# Decode\n",
    "print(\"\\nDecoding tokens back to audio...\")\n",
    "decoded_wavs, sr = tokenizer.decode(encoded)\n",
    "print(f\"‚úÖ Decoded audio: {len(decoded_wavs[0])} samples at {sr}Hz\")\n",
    "\n",
    "save_and_play(decoded_wavs[0], sr, \"26_tokenizer_roundtrip.wav\", \"Encoded ‚Üí Decoded audio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbefa7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7.3: Encode Generated Audio\n",
    "\n",
    "print_section(\"Tokenize Our Generated Audio\")\n",
    "\n",
    "# Encode one of our generated files\n",
    "generated_file = os.path.join(OUTPUT_DIR, \"10_documentary_en.wav\")\n",
    "\n",
    "if os.path.exists(generated_file):\n",
    "    print(f\"Encoding: {generated_file}\\n\")\n",
    "    \n",
    "    # Encode\n",
    "    encoded = tokenizer.encode(generated_file)\n",
    "    print(f\"Encoded shape: {encoded.shape}\")\n",
    "    print(f\"Duration: {encoded.shape[1]/12:.2f} seconds\")\n",
    "    \n",
    "    # Decode\n",
    "    decoded_wavs, sr = tokenizer.decode(encoded)\n",
    "    save_and_play(decoded_wavs[0], sr, \"27_documentary_roundtrip.wav\", \"Documentary voice after encode/decode\")\n",
    "else:\n",
    "    print(f\"File not found: {generated_file}\")\n",
    "    print(\"Run the Voice Design examples first!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831c28a0",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 8: Summary and Best Practices\n",
    "\n",
    "### Voice Description Tips:\n",
    "\n",
    "| Aspect | Good Example | Bad Example |\n",
    "|--------|--------------|-------------|\n",
    "| **Age/Gender** | \"A 45-year-old male\" | \"A person\" |\n",
    "| **Voice Quality** | \"Deep, resonant baritone\" | \"Nice voice\" |\n",
    "| **Emotion** | \"Excited with rising pitch\" | \"Happy\" |\n",
    "| **Context** | \"Like a BBC news anchor\" | \"Professional\" |\n",
    "| **Pace** | \"Slow, measured with pauses\" | \"Normal speed\" |\n",
    "\n",
    "### Model Selection Guide:\n",
    "\n",
    "| Need | Model | Why |\n",
    "|------|-------|-----|\n",
    "| Create unique voices | VoiceDesign | Natural language ‚Üí Voice |\n",
    "| Quick quality TTS | CustomVoice | Pre-built premium voices |\n",
    "| Match existing voice | Base | Clone from audio |\n",
    "| Multiple lines, same character | Design ‚Üí Clone | Consistent reusable voice |\n",
    "\n",
    "### Performance Tips:\n",
    "\n",
    "1. **Use bfloat16** for GPU (saves memory, maintains quality)\n",
    "2. **FlashAttention 2** for faster inference\n",
    "3. **Batch processing** for multiple generations\n",
    "4. **Reusable prompts** for voice cloning\n",
    "\n",
    "### Thai Language Tips:\n",
    "\n",
    "1. ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£\n",
    "2. ‡∏ó‡∏î‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ `language=\"Chinese\"` ‡∏´‡∏£‡∏∑‡∏≠ `\"Korean\"` \n",
    "3. ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏≠‡∏≤‡∏à‡πÑ‡∏°‡πà‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå‡πÅ‡∏ö‡∏ö ‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ß‡∏£‡∏£‡∏ì‡∏¢‡∏∏‡∏Å‡∏ï‡πå\n",
    "4. ‡∏£‡∏≠‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏° updates ‡∏à‡∏≤‡∏Å Qwen team ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÉ‡∏ô‡∏≠‡∏ô‡∏≤‡∏Ñ‡∏ï"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90768e0",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Cell 8.1: Memory Usage Summary\n",
    "\n",
    "print_section(\"Memory and File Summary\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU Memory Usage:\")\n",
    "    print(f\"  Allocated: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")\n",
    "    print(f\"  Cached: {torch.cuda.memory_reserved() / 1e9:.2f} GB\")\n",
    "\n",
    "print(f\"\\nGenerated Files in {OUTPUT_DIR}:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "if os.path.exists(OUTPUT_DIR):\n",
    "    files = sorted([f for f in os.listdir(OUTPUT_DIR) if f.endswith('.wav')])\n",
    "    total_size = 0\n",
    "    for f in files:\n",
    "        filepath = os.path.join(OUTPUT_DIR, f)\n",
    "        size = os.path.getsize(filepath) / 1024\n",
    "        total_size += size\n",
    "        print(f\"  {f:<50} {size:>8.1f} KB\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"  Total: {len(files)} files, {total_size/1024:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae6b2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8.2: Cleanup Function (Optional)\n",
    "\n",
    "def cleanup_models():\n",
    "    \"\"\"Free GPU memory by deleting models\"\"\"\n",
    "    global voice_design_model, custom_voice_model, clone_model, tokenizer\n",
    "    \n",
    "    models_to_delete = [\n",
    "        ('voice_design_model', 'VoiceDesign'),\n",
    "        ('custom_voice_model', 'CustomVoice'),\n",
    "        ('clone_model', 'Clone'),\n",
    "        ('tokenizer', 'Tokenizer'),\n",
    "    ]\n",
    "    \n",
    "    for var_name, display_name in models_to_delete:\n",
    "        if var_name in globals():\n",
    "            del globals()[var_name]\n",
    "            print(f\"‚úÖ Deleted {display_name} model\")\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.synchronize()\n",
    "        print(\"‚úÖ GPU cache cleared\")\n",
    "\n",
    "# Uncomment to run cleanup:\n",
    "# cleanup_models()\n",
    "\n",
    "print(\"To free GPU memory, run: cleanup_models()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936b8451",
   "metadata": {},
   "source": [
    "---\n",
    "## üìù Lab Exercises\n",
    "\n",
    "Complete the following exercises to practice what you've learned:\n",
    "\n",
    "### Exercise 1: Design Your Own Voice (English)\n",
    "Create a unique voice for one of these scenarios:\n",
    "- A pirate captain\n",
    "- A sci-fi spaceship AI\n",
    "- A sports commentator\n",
    "- A children's cartoon character\n",
    "\n",
    "### Exercise 2: Thai Voice Experiment üáπüá≠\n",
    "‡∏ó‡∏î‡∏•‡∏≠‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÉ‡∏ô‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏ï‡πà‡∏≤‡∏á‡πÜ:\n",
    "- ‡∏û‡∏¥‡∏ò‡∏µ‡∏Å‡∏£‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡∏ß‡∏µ\n",
    "- ‡∏Ñ‡∏£‡∏π‡∏™‡∏≠‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢\n",
    "- ‡∏î‡∏µ‡πÄ‡∏à‡∏ß‡∏¥‡∏ó‡∏¢‡∏∏\n",
    "- ‡∏û‡∏£‡∏∞‡∏™‡∏á‡∏Ü‡πå‡πÄ‡∏ó‡∏®‡∏ô‡πå\n",
    "\n",
    "### Exercise 3: Emotion Comparison\n",
    "Take one sentence and generate it with 5 different emotions using CustomVoice.\n",
    "\n",
    "### Exercise 4: Character Dialogue (Bilingual)\n",
    "Create two different characters using VoiceDesign and generate a short dialogue \n",
    "between them - one speaks English, one speaks Thai.\n",
    "\n",
    "### Exercise 5: Clone and Extend\n",
    "Use the Voice Design ‚Üí Clone workflow to create a consistent character voice\n",
    "and generate a 5-sentence monologue.\n",
    "\n",
    "### Exercise 6: Audio Analysis\n",
    "Use the tokenizer to encode several different voice types and compare the token statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b14aecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise Space - Write your code here!\n",
    "\n",
    "print_section(\"Exercise Space\")\n",
    "\n",
    "# Exercise 1: Pirate Captain\n",
    "print(\"=\" * 60)\n",
    "print(\"Exercise 1: Create a pirate captain voice\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Uncomment and modify:\n",
    "# pirate_text = \"Arrr! All hands on deck! We've spotted treasure on the horizon!\"\n",
    "# pirate_description = \"\"\"\n",
    "# A gruff male pirate captain with a raspy, weathered voice.\n",
    "# Speaks with enthusiasm and a slight growl. Commanding presence.\n",
    "# Think of a classic movie pirate - boisterous and larger than life.\n",
    "# \"\"\"\n",
    "# \n",
    "# wavs, sr = voice_design_model.generate_voice_design(\n",
    "#     text=pirate_text,\n",
    "#     language=\"English\",\n",
    "#     instruct=pirate_description,\n",
    "# )\n",
    "# save_and_play(wavs[0], sr, \"ex1_pirate.wav\", \"Pirate captain voice\")\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# Exercise 2: Thai Voice\n",
    "print(\"=\" * 60)\n",
    "print(\"Exercise 2: Thai TV Host Voice üáπüá≠\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Uncomment and modify:\n",
    "# tv_host_text = \"\"\"‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡πà‡∏∞‡∏ó‡∏∏‡∏Å‡∏ó‡πà‡∏≤‡∏ô ‡∏¢‡∏¥‡∏ô‡∏î‡∏µ‡∏ï‡πâ‡∏≠‡∏ô‡∏£‡∏±‡∏ö‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤ \n",
    "# ‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏£‡∏≤‡∏°‡∏µ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ô‡πà‡∏≤‡∏™‡∏ô‡πÉ‡∏à‡∏°‡∏≤‡∏Å‡∏°‡∏≤‡∏¢‡∏°‡∏≤‡πÄ‡∏•‡πà‡∏≤‡πÉ‡∏´‡πâ‡∏ü‡∏±‡∏á‡∏Ñ‡πà‡∏∞\"\"\"\n",
    "# \n",
    "# tv_host_description = \"\"\"\n",
    "# A cheerful Thai female TV host in her 30s. Energetic and engaging.\n",
    "# Clear pronunciation with proper polite particles.\n",
    "# Warm smile in her voice. Professional but friendly.\n",
    "# \"\"\"\n",
    "# \n",
    "# wavs, sr = voice_design_model.generate_voice_design(\n",
    "#     text=tv_host_text,\n",
    "#     language=\"Chinese\",  # Experimental for Thai\n",
    "#     instruct=tv_host_description,\n",
    "# )\n",
    "# save_and_play(wavs[0], sr, \"ex2_thai_tv_host.wav\", \"Thai TV host voice\")\n",
    "\n",
    "print(\"Uncomment the examples above or write your own code!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f13e1f8",
   "metadata": {},
   "source": [
    "---\n",
    "## üìö Resources\n",
    "\n",
    "- **GitHub Repository**: https://github.com/QwenLM/Qwen3-TTS\n",
    "- **Hugging Face Models**: https://huggingface.co/collections/Qwen/qwen3-tts\n",
    "- **Technical Paper**: https://arxiv.org/abs/2601.15621\n",
    "- **Online Demo**: https://huggingface.co/spaces/Qwen/Qwen3-TTS\n",
    "- **API Documentation**: https://help.aliyun.com/zh/model-studio/qwen-tts-realtime\n",
    "\n",
    "---\n",
    "\n",
    "**End of Lab**"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
