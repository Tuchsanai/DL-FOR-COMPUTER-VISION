

# แบบฝึกหัดสำหรับนักศึกษา: การวิเคราะห์และประเมินโมเดลภาษาด้วย Dataset Question and Answer with Instruction

## วัตถุประสงค์
- เพื่อให้นักศึกษาได้ฝึกฝนการใช้งานโมเดลภาษาขนาดใหญ่ในการสร้างคำตอบจากคำถามและคำสั่ง
- เพื่อพัฒนาทักษะการประเมินผลลัพธ์ของโมเดล โดยใช้เมตริกซ์การประเมินที่หลากหลาย
- เพื่อให้นักศึกษาสามารถวิเคราะห์และเปรียบเทียบประสิทธิภาพของโมเดลทั้งสาม และสรุปผลได้อย่างมีเหตุผล

## ข้อมูลที่ใช้
- **Dataset**: "Question and Answer with Instruction" จาก Hugging Face
- **จำนวนชุดข้อมูล**: 8 ชุด (สมมติว่าเท่ากับจำนวนนักศึกษาที่ลงทะเบียน)
- **โมเดลที่ใช้**:
  - `deepseek-ai/DeepSeek-R1-Distill-Llama-70B`
  - `Qwen/Qwen2.5-VL-72B-Instruct`
  - `meta-llama/Llama-3.3-70B-Instruct`

## ขั้นตอนการปฏิบัติ

### 1. การเตรียมข้อมูล
- ดาวน์โหลด Dataset "Question and Answer with Instruction" จาก Hugging Face
- รวมข้อมูลทั้ง 8 ชุดเข้าด้วยกันโดยแต่ละชุดประกอบด้วย Question and Answer with Instruction (Ground Truth)

### 2. การสร้างคำตอบจากโมเดล
- ใช้โค้ดตัวอย่างที่ให้มาเพื่อสร้างคำตอบจากคำถามใน Dataset โดยใช้ทั้ง 3 โมเดล
- บันทึกผลลัพธ์ที่ได้จากแต่ละโมเดลสำหรับแต่ละชุดข้อมูล

```python
def generate(model, messages):
    tokenizer = AutoTokenizer.from_pretrained(model)
    tokenizer.pad_token = tokenizer.eos_token
    
    inputs = tokenizer.apply_chat_template(
        messages, 
        return_tensors="pt", 
        add_generation_prompt=True
    ).to("cuda")
    
    streamer = TextStreamer(tokenizer)
    
    model = AutoModelForCausalLM.from_pretrained(
        model, 
        device_map="auto", 
        quantization_config=quant_config
    )
    
    outputs = model.generate(
        inputs,
        max_new_tokens=5500,
        early_stopping=True,
        temperature=0.1,
        do_sample=True,
        top_p=0.95,
        top_k=50,
        repetition_penalty=1.15,
        streamer=streamer,
        eos_token_id=tokenizer.eos_token_id
    )
    
    del tokenizer, streamer, model, inputs, outputs
    torch.cuda.empty_cache()

3. การประเมินผลลัพธ์
นักศึกษาจะต้องเลือกและใช้เมตริกซ์การประเมินอย่างน้อย 6 วิธี เพื่อเปรียบเทียบคำตอบที่ได้จากโมเดลกับคำตอบอ้างอิงใน Dataset โดยเมตริกซ์ที่เลือกใช้ต้องครอบคลุมมิติต่างๆ เช่น ความแม่นยำ ความคล้ายคลึง ความสมบูรณ์ และความลื่นไหลของภาษา
เงื่อนไขพิเศษ: อย่างน้อย 1 เมตริกซ์ต้องใช้โมเดล deepseek-ai/DeepSeek-R1-Distill-Llama-70B หรือ meta-llama/Llama-3.3-70B-Instruct เป็นเครื่องมือในการประเมิน เช่น การให้โมเดลทำการเปรียบเทียบความคล้ายคลึงของประโยคระหว่างคำตอบที่สร้างขึ้นกับคำตอบอ้างอิง
ตัวอย่างเมตริกซ์ที่แนะนำ:
BLEU Score: วัดความคล้ายคลึงของคำและลำดับคำ
ROUGE Score: วัดการทับซ้อนของคำและวลี
BERTScore: วัดความคล้ายคลึงในระดับความหมายโดยใช้ Contextual Embeddings
Exact Match (EM): วัดว่าคำตอบตรงกับคำตอบอ้างอิงทุกประการหรือไม่
Cosine Similarity: วัดความคล้ายคลึงของเวกเตอร์ข้อความ
LLM-based Evaluation: ใช้ deepseek-ai/DeepSeek-R1-Distill-Llama-70B หรือ meta-llama/Llama-3.3-70B-Instruct เพื่อให้คะแนนความคล้ายคลึงหรือความสมเหตุสมผลของคำตอบ
4. การวิเคราะห์และสรุปผล
เปรียบเทียบผลลัพธ์จากเมตริกซ์ทั้ง 6 วิธี เพื่อหาว่าโมเดลใดให้คำตอบที่ใกล้เคียงกับคำตอบอ้างอิงมากที่สุด
อธิบายเหตุผลที่โมเดลนั้นมีประสิทธิภาพดีกว่า เช่น โมเดลมีขนาดใหญ่กว่า เข้าใจบริบทดีกว่า หรือปรับแต่งมาสำหรับงานนี้โดยเฉพาะ
งานที่ต้องส่ง
รายงานผลลัพธ์คำตอบจากทั้ง 3 โมเดลสำหรับชุดข้อมูลที่ได้รับมอบหมาย
ค่าของเมตริกซ์การประเมินทั้ง 6 วิธี พร้อมคำอธิบายวิธีการคำนวณ
การวิเคราะห์ว่าโมเดลใดดีที่สุด และเหตุผลประกอบ
บทสรุป
การเดินทางครั้งนี้ได้พานักศึกษาก้าวข้ามขอบเขตของการเรียนรู้แบบเดิมๆ สู่โลกแห่งปัญญาประดิษฐ์ที่เต็มไปด้วยความท้าทายและความเป็นไปได้ไม่รู้จบ ด้วยการใช้โมเดลภาษาอันทรงพลังทั้ง deepseek-ai/DeepSeek-R1-Distill-Llama-70B, Qwen/Qwen2.5-VL-72B-Instruct และ meta-llama/Llama-3.3-70B-Instruct ร่วมกับ Dataset "Question and Answer with Instruction" นักศึกษาได้เรียนรู้วิธีการสร้างคำตอบที่มีคุณภาพ และประเมินผลอย่างเป็นระบบด้วยเมตริกซ์หลากหลาย แบบฝึกหัดนี้ไม่เพียงแต่ฝึกฝนทักษะด้านเทคนิคเท่านั้น แต่ยังปลูกฝังความเข้าใจลึกซึ้งถึงพลังและข้อจำกัดของเทคโนโลยี AI อันทันสมัย หวังว่านักศึกษาจะนำประสบการณ์นี้ไปต่อยอด สร้างสรรค์นวัตกรรมใหม่ๆ และเป็นส่วนหนึ่งในการขับเคลื่อนอนาคตของมนุษยชาติต่อไป!

### คำอธิบาย
- ข้อความถูกจัดรูปแบบให้เหมาะสมกับ `README.md` โดยใช้หัวข้อ (`#`, `##`, `###`) และการจัดย่อหน้า
- โค้ด Python ถูกใส่ในบล็อกโค้ด (```python) เพื่อให้อ่านง่าย
- รายการ (เช่น เมตริกซ์แนะนำ) ใช้สัญลักษณ์ `-` เพื่อแสดงเป็น bullet points
- ข้อความเน้น (เช่น ชื่อโมเดล) ใช้ตัวหนา (`**`) หรือโค้ด (`) ตามความเหมาะสม