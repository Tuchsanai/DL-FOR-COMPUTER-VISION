{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook cleaned.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import IPython\n",
    "import sys\n",
    "\n",
    "def clean_notebook():\n",
    "    IPython.display.clear_output(wait=True)\n",
    "    print(\"Notebook cleaned.\")\n",
    "!pip install facenet-pytorch --no-deps\n",
    "\n",
    "!pip install pytubefix\n",
    "\n",
    "\n",
    "# Clean up the notebook\n",
    "clean_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached the specified end time.\n",
      "Video stream ended.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from IPython.display import display, Image, clear_output\n",
    "import numpy as np\n",
    "from pytubefix import YouTube\n",
    "from facenet_pytorch import MTCNN\n",
    "import torch\n",
    "import time  # For adding delay\n",
    "\n",
    "# Initialize MTCNN model\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "mtcnn = MTCNN(keep_all=True, device=device)\n",
    "\n",
    "# YouTube video URL\n",
    "video_url = \"https://youtu.be/EsHQB9gT96k?si=bdi3dDrVnYVIgVYi\"\n",
    "video_url = \"https://youtu.be/cmdMopdk6lo?si=vK7azxlZu4PKgiHW\"\n",
    "\n",
    "# Target width for resizing\n",
    "target_width = 800\n",
    "# Start and stop times in seconds\n",
    "start_time = 75  # Start at 10 seconds\n",
    "end_time = 120   # Stop at 120 seconds\n",
    "\n",
    "# Download the video stream (use pytubefix to fetch the stream URL)\n",
    "yt = YouTube(video_url)\n",
    "video_stream = yt.streams.filter(file_extension='mp4', progressive=True).first()\n",
    "\n",
    "if not video_stream:\n",
    "    print(\"No compatible video stream found.\")\n",
    "    exit()\n",
    "\n",
    "# Get the stream URL\n",
    "stream_url = video_stream.url\n",
    "\n",
    "# Open the YouTube stream in OpenCV\n",
    "cap = cv2.VideoCapture(stream_url)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open YouTube video stream\")\n",
    "    exit()\n",
    "\n",
    "# Set start time in the video (in milliseconds)\n",
    "cap.set(cv2.CAP_PROP_POS_MSEC, start_time * 1000)\n",
    "\n",
    "while cap.isOpened():\n",
    "    clear_output(wait=True)  # Clear previous frame for smoother playback\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        print(\"Stream stopped.\")\n",
    "        break\n",
    "\n",
    "    # Get the current playback time in milliseconds\n",
    "    current_time = cap.get(cv2.CAP_PROP_POS_MSEC) / 1000  # Convert to seconds\n",
    "    \n",
    "    # Stop playback if the end time is reached\n",
    "    if current_time >= end_time:\n",
    "        print(\"Reached the specified end time.\")\n",
    "        break\n",
    "\n",
    "    # Convert frame to RGB format\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Detect faces\n",
    "    boxes, _ = mtcnn.detect(rgb_frame)\n",
    "\n",
    "    # Draw bounding boxes on the original frame\n",
    "    if boxes is not None:\n",
    "        for box in boxes:\n",
    "            # Extract coordinates\n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "            # Draw rectangle around face\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "    # Get original dimensions\n",
    "    original_height, original_width = frame.shape[:2]\n",
    "\n",
    "    # Calculate aspect ratio and new dimensions\n",
    "    aspect_ratio = original_height / original_width\n",
    "    new_height = int(target_width * aspect_ratio)\n",
    "\n",
    "    # Resize the frame while maintaining the aspect ratio\n",
    "    resized_frame = cv2.resize(frame, (target_width, new_height))\n",
    "\n",
    "    # Convert the resized frame to JPEG format for display in Jupyter\n",
    "    _, buffer = cv2.imencode('.jpg', resized_frame)\n",
    "    img_bytes = buffer.tobytes()\n",
    "\n",
    "    # Display the resized frame in Jupyter Notebook\n",
    "    display(Image(data=img_bytes))\n",
    "  \n",
    "    # Add a delay for smoother playback\n",
    "    time.sleep(0.015)  # Delay in seconds\n",
    "\n",
    "cap.release()\n",
    "print(\"Video stream ended.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached the specified end time.\n",
      "Video stream ended.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from IPython.display import display, Image, clear_output\n",
    "import numpy as np\n",
    "from pytubefix import YouTube\n",
    "from facenet_pytorch import MTCNN\n",
    "import torch\n",
    "import time\n",
    "\n",
    "# Initialize MTCNN model\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "mtcnn = MTCNN(keep_all=True, device=device)\n",
    "\n",
    "# YouTube video URL\n",
    "video_url = \"https://youtu.be/EsHQB9gT96k?si=bdi3dDrVnYVIgVYi\"\n",
    "video_url = \"https://youtu.be/cmdMopdk6lo?si=vK7azxlZu4PKgiHW\"\n",
    "\n",
    "# Target width for resizing (main video area)\n",
    "target_width = 800\n",
    "\n",
    "# Face panel settings\n",
    "face_panel_width = 150  # Width of the face panel on the right\n",
    "face_thumbnail_size = 120  # Size of each face thumbnail\n",
    "max_faces_display = 4  # Number of faces to display vertically\n",
    "\n",
    "# Start and stop times in seconds\n",
    "start_time = 75\n",
    "end_time = 120\n",
    "\n",
    "# Store recent detected faces\n",
    "recent_faces = []\n",
    "\n",
    "# Download the video stream\n",
    "yt = YouTube(video_url)\n",
    "video_stream = yt.streams.filter(file_extension='mp4', progressive=True).first()\n",
    "\n",
    "if not video_stream:\n",
    "    print(\"No compatible video stream found.\")\n",
    "    exit()\n",
    "\n",
    "stream_url = video_stream.url\n",
    "\n",
    "# Open the YouTube stream in OpenCV\n",
    "cap = cv2.VideoCapture(stream_url)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open YouTube video stream\")\n",
    "    exit()\n",
    "\n",
    "# Set start time in the video\n",
    "cap.set(cv2.CAP_PROP_POS_MSEC, start_time * 1000)\n",
    "\n",
    "def extract_face(frame, box, margin=20):\n",
    "    \"\"\"Extract face region from frame with some margin\"\"\"\n",
    "    h, w = frame.shape[:2]\n",
    "    x1, y1, x2, y2 = map(int, box)\n",
    "    \n",
    "    # Add margin\n",
    "    x1 = max(0, x1 - margin)\n",
    "    y1 = max(0, y1 - margin)\n",
    "    x2 = min(w, x2 + margin)\n",
    "    y2 = min(h, y2 + margin)\n",
    "    \n",
    "    face = frame[y1:y2, x1:x2]\n",
    "    \n",
    "    if face.size == 0:\n",
    "        return None\n",
    "    \n",
    "    # Resize to square thumbnail\n",
    "    face_resized = cv2.resize(face, (face_thumbnail_size, face_thumbnail_size))\n",
    "    return face_resized\n",
    "\n",
    "def create_face_panel(faces, panel_height):\n",
    "    \"\"\"Create a vertical panel with detected faces\"\"\"\n",
    "    # Create dark gray panel\n",
    "    panel = np.ones((panel_height, face_panel_width, 3), dtype=np.uint8) * 40\n",
    "    \n",
    "    # Calculate vertical spacing\n",
    "    total_face_height = max_faces_display * face_thumbnail_size\n",
    "    spacing = (panel_height - total_face_height) // (max_faces_display + 1)\n",
    "    spacing = max(10, spacing)  # Minimum spacing of 10 pixels\n",
    "    \n",
    "    # Add title\n",
    "    cv2.putText(panel, \"Detected\", (10, 25), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                0.5, (255, 255, 255), 1)\n",
    "    cv2.putText(panel, \"Faces\", (10, 45), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                0.5, (255, 255, 255), 1)\n",
    "    \n",
    "    # Starting y position (after title)\n",
    "    start_y = 60\n",
    "    \n",
    "    # Draw each face\n",
    "    for i, face in enumerate(faces[:max_faces_display]):\n",
    "        if face is not None:\n",
    "            y_pos = start_y + i * (face_thumbnail_size + spacing)\n",
    "            x_pos = (face_panel_width - face_thumbnail_size) // 2\n",
    "            \n",
    "            # Make sure we don't exceed panel bounds\n",
    "            if y_pos + face_thumbnail_size <= panel_height:\n",
    "                # Add border around face\n",
    "                cv2.rectangle(panel, \n",
    "                            (x_pos - 2, y_pos - 2), \n",
    "                            (x_pos + face_thumbnail_size + 2, y_pos + face_thumbnail_size + 2),\n",
    "                            (0, 255, 0), 2)\n",
    "                \n",
    "                # Place face in panel\n",
    "                panel[y_pos:y_pos + face_thumbnail_size, \n",
    "                      x_pos:x_pos + face_thumbnail_size] = face\n",
    "                \n",
    "                # Add face number\n",
    "                cv2.putText(panel, f\"#{i+1}\", (x_pos, y_pos - 5), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 0), 1)\n",
    "    \n",
    "    return panel\n",
    "\n",
    "while cap.isOpened():\n",
    "    clear_output(wait=True)\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        print(\"Stream stopped.\")\n",
    "        break\n",
    "    \n",
    "    current_time = cap.get(cv2.CAP_PROP_POS_MSEC) / 1000\n",
    "    \n",
    "    if current_time >= end_time:\n",
    "        print(\"Reached the specified end time.\")\n",
    "        break\n",
    "    \n",
    "    # Convert frame to RGB for face detection\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Detect faces\n",
    "    boxes, probs = mtcnn.detect(rgb_frame)\n",
    "    \n",
    "    # Process detected faces\n",
    "    if boxes is not None:\n",
    "        # Sort by confidence if available, otherwise by size\n",
    "        if probs is not None:\n",
    "            # Sort by probability (highest first)\n",
    "            sorted_indices = np.argsort(probs)[::-1]\n",
    "            boxes = boxes[sorted_indices]\n",
    "        \n",
    "        # Clear recent faces and add new ones\n",
    "        recent_faces = []\n",
    "        \n",
    "        for i, box in enumerate(boxes):\n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "            \n",
    "            # Draw rectangle on main frame\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            \n",
    "            # Add face number label\n",
    "            cv2.putText(frame, f\"#{i+1}\", (x1, y1 - 10), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "            \n",
    "            # Extract face for panel\n",
    "            face = extract_face(frame, box)\n",
    "            if face is not None:\n",
    "                recent_faces.append(face)\n",
    "    \n",
    "    # Get original dimensions\n",
    "    original_height, original_width = frame.shape[:2]\n",
    "    \n",
    "    # Calculate new dimensions for main video\n",
    "    aspect_ratio = original_height / original_width\n",
    "    new_height = int(target_width * aspect_ratio)\n",
    "    \n",
    "    # Resize the main frame\n",
    "    resized_frame = cv2.resize(frame, (target_width, new_height))\n",
    "    \n",
    "    # Create face panel with matching height\n",
    "    face_panel = create_face_panel(recent_faces, new_height)\n",
    "    \n",
    "    # Combine main frame and face panel horizontally\n",
    "    combined_frame = np.hstack([resized_frame, face_panel])\n",
    "    \n",
    "    # Add timestamp overlay\n",
    "    cv2.putText(combined_frame, f\"Time: {current_time:.1f}s\", (10, 30),\n",
    "               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "    \n",
    "    # Add face count\n",
    "    face_count = len(recent_faces) if recent_faces else 0\n",
    "    cv2.putText(combined_frame, f\"Faces: {face_count}\", (10, 60),\n",
    "               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "    \n",
    "    # Convert to JPEG for display\n",
    "    _, buffer = cv2.imencode('.jpg', combined_frame)\n",
    "    img_bytes = buffer.tobytes()\n",
    "    \n",
    "    # Display in Jupyter Notebook\n",
    "    display(Image(data=img_bytes))\n",
    "    \n",
    "    # Delay for smoother playback\n",
    "    time.sleep(0.015)\n",
    "\n",
    "cap.release()\n",
    "print(\"Video stream ended.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
