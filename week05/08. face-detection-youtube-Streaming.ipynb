{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook cleaned.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import IPython\n",
    "import sys\n",
    "\n",
    "def clean_notebook():\n",
    "    IPython.display.clear_output(wait=True)\n",
    "    print(\"Notebook cleaned.\")\n",
    "!pip install facenet-pytorch --no-deps\n",
    "\n",
    "!pip install pytubefix\n",
    "\n",
    "\n",
    "# Clean up the notebook\n",
    "clean_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached the specified end time.\n",
      "Video stream ended.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from IPython.display import display, Image, clear_output\n",
    "import numpy as np\n",
    "from pytubefix import YouTube\n",
    "from facenet_pytorch import MTCNN\n",
    "import torch\n",
    "import time  # For adding delay\n",
    "\n",
    "# Initialize MTCNN model\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "mtcnn = MTCNN(keep_all=True, device=device)\n",
    "\n",
    "# YouTube video URL\n",
    "video_url = \"https://youtu.be/EsHQB9gT96k?si=bdi3dDrVnYVIgVYi\"\n",
    "video_url = \"https://youtu.be/cmdMopdk6lo?si=vK7azxlZu4PKgiHW\"\n",
    "\n",
    "# Target width for resizing\n",
    "target_width = 800\n",
    "# Start and stop times in seconds\n",
    "start_time = 75  # Start at 10 seconds\n",
    "end_time = 120   # Stop at 120 seconds\n",
    "\n",
    "# Download the video stream (use pytubefix to fetch the stream URL)\n",
    "yt = YouTube(video_url)\n",
    "video_stream = yt.streams.filter(file_extension='mp4', progressive=True).first()\n",
    "\n",
    "if not video_stream:\n",
    "    print(\"No compatible video stream found.\")\n",
    "    exit()\n",
    "\n",
    "# Get the stream URL\n",
    "stream_url = video_stream.url\n",
    "\n",
    "# Open the YouTube stream in OpenCV\n",
    "cap = cv2.VideoCapture(stream_url)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open YouTube video stream\")\n",
    "    exit()\n",
    "\n",
    "# Set start time in the video (in milliseconds)\n",
    "cap.set(cv2.CAP_PROP_POS_MSEC, start_time * 1000)\n",
    "\n",
    "while cap.isOpened():\n",
    "    clear_output(wait=True)  # Clear previous frame for smoother playback\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        print(\"Stream stopped.\")\n",
    "        break\n",
    "\n",
    "    # Get the current playback time in milliseconds\n",
    "    current_time = cap.get(cv2.CAP_PROP_POS_MSEC) / 1000  # Convert to seconds\n",
    "    \n",
    "    # Stop playback if the end time is reached\n",
    "    if current_time >= end_time:\n",
    "        print(\"Reached the specified end time.\")\n",
    "        break\n",
    "\n",
    "    # Convert frame to RGB format\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Detect faces\n",
    "    boxes, _ = mtcnn.detect(rgb_frame)\n",
    "\n",
    "    # Draw bounding boxes on the original frame\n",
    "    if boxes is not None:\n",
    "        for box in boxes:\n",
    "            # Extract coordinates\n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "            # Draw rectangle around face\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "    # Get original dimensions\n",
    "    original_height, original_width = frame.shape[:2]\n",
    "\n",
    "    # Calculate aspect ratio and new dimensions\n",
    "    aspect_ratio = original_height / original_width\n",
    "    new_height = int(target_width * aspect_ratio)\n",
    "\n",
    "    # Resize the frame while maintaining the aspect ratio\n",
    "    resized_frame = cv2.resize(frame, (target_width, new_height))\n",
    "\n",
    "    # Convert the resized frame to JPEG format for display in Jupyter\n",
    "    _, buffer = cv2.imencode('.jpg', resized_frame)\n",
    "    img_bytes = buffer.tobytes()\n",
    "\n",
    "    # Display the resized frame in Jupyter Notebook\n",
    "    display(Image(data=img_bytes))\n",
    "  \n",
    "    # Add a delay for smoother playback\n",
    "    time.sleep(0.015)  # Delay in seconds\n",
    "\n",
    "cap.release()\n",
    "print(\"Video stream ended.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached the specified end time.\n",
      "Video stream ended.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from IPython.display import display, Image, clear_output\n",
    "import numpy as np\n",
    "from pytubefix import YouTube\n",
    "from facenet_pytorch import MTCNN\n",
    "import torch\n",
    "import time\n",
    "\n",
    "# Initialize MTCNN model\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "mtcnn = MTCNN(keep_all=True, device=device)\n",
    "\n",
    "# YouTube video URL\n",
    "video_url = \"https://youtu.be/EsHQB9gT96k?si=bdi3dDrVnYVIgVYi\"\n",
    "video_url = \"https://youtu.be/cmdMopdk6lo?si=vK7azxlZu4PKgiHW\"\n",
    "\n",
    "# Target width for resizing (main video area)\n",
    "target_width = 800\n",
    "\n",
    "# Face panel settings\n",
    "face_panel_width = 150  # Width of the face panel on the right\n",
    "face_thumbnail_size = 120  # Size of each face thumbnail\n",
    "max_faces_display = 4  # Number of faces to display vertically\n",
    "\n",
    "# Start and stop times in seconds\n",
    "start_time = 75\n",
    "end_time = 120\n",
    "\n",
    "# Store recent detected faces\n",
    "recent_faces = []\n",
    "\n",
    "# Download the video stream\n",
    "yt = YouTube(video_url)\n",
    "video_stream = yt.streams.filter(file_extension='mp4', progressive=True).first()\n",
    "\n",
    "if not video_stream:\n",
    "    print(\"No compatible video stream found.\")\n",
    "    exit()\n",
    "\n",
    "stream_url = video_stream.url\n",
    "\n",
    "# Open the YouTube stream in OpenCV\n",
    "cap = cv2.VideoCapture(stream_url)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open YouTube video stream\")\n",
    "    exit()\n",
    "\n",
    "# Set start time in the video\n",
    "cap.set(cv2.CAP_PROP_POS_MSEC, start_time * 1000)\n",
    "\n",
    "def extract_face(frame, box, margin=20):\n",
    "    \"\"\"Extract face region from frame with some margin\"\"\"\n",
    "    h, w = frame.shape[:2]\n",
    "    x1, y1, x2, y2 = map(int, box)\n",
    "    \n",
    "    # Add margin\n",
    "    x1 = max(0, x1 - margin)\n",
    "    y1 = max(0, y1 - margin)\n",
    "    x2 = min(w, x2 + margin)\n",
    "    y2 = min(h, y2 + margin)\n",
    "    \n",
    "    face = frame[y1:y2, x1:x2]\n",
    "    \n",
    "    if face.size == 0:\n",
    "        return None\n",
    "    \n",
    "    # Resize to square thumbnail\n",
    "    face_resized = cv2.resize(face, (face_thumbnail_size, face_thumbnail_size))\n",
    "    return face_resized\n",
    "\n",
    "def create_face_panel(faces, panel_height):\n",
    "    \"\"\"Create a vertical panel with detected faces\"\"\"\n",
    "    # Create dark gray panel\n",
    "    panel = np.ones((panel_height, face_panel_width, 3), dtype=np.uint8) * 40\n",
    "    \n",
    "    # Calculate vertical spacing\n",
    "    total_face_height = max_faces_display * face_thumbnail_size\n",
    "    spacing = (panel_height - total_face_height) // (max_faces_display + 1)\n",
    "    spacing = max(10, spacing)  # Minimum spacing of 10 pixels\n",
    "    \n",
    "    # Add title\n",
    "    cv2.putText(panel, \"Detected\", (10, 25), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                0.5, (255, 255, 255), 1)\n",
    "    cv2.putText(panel, \"Faces\", (10, 45), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                0.5, (255, 255, 255), 1)\n",
    "    \n",
    "    # Starting y position (after title)\n",
    "    start_y = 60\n",
    "    \n",
    "    # Draw each face\n",
    "    for i, face in enumerate(faces[:max_faces_display]):\n",
    "        if face is not None:\n",
    "            y_pos = start_y + i * (face_thumbnail_size + spacing)\n",
    "            x_pos = (face_panel_width - face_thumbnail_size) // 2\n",
    "            \n",
    "            # Make sure we don't exceed panel bounds\n",
    "            if y_pos + face_thumbnail_size <= panel_height:\n",
    "                # Add border around face\n",
    "                cv2.rectangle(panel, \n",
    "                            (x_pos - 2, y_pos - 2), \n",
    "                            (x_pos + face_thumbnail_size + 2, y_pos + face_thumbnail_size + 2),\n",
    "                            (0, 255, 0), 2)\n",
    "                \n",
    "                # Place face in panel\n",
    "                panel[y_pos:y_pos + face_thumbnail_size, \n",
    "                      x_pos:x_pos + face_thumbnail_size] = face\n",
    "                \n",
    "                # Add face number\n",
    "                cv2.putText(panel, f\"#{i+1}\", (x_pos, y_pos - 5), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 0), 1)\n",
    "    \n",
    "    return panel\n",
    "\n",
    "while cap.isOpened():\n",
    "    clear_output(wait=True)\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        print(\"Stream stopped.\")\n",
    "        break\n",
    "    \n",
    "    current_time = cap.get(cv2.CAP_PROP_POS_MSEC) / 1000\n",
    "    \n",
    "    if current_time >= end_time:\n",
    "        print(\"Reached the specified end time.\")\n",
    "        break\n",
    "    \n",
    "    # Convert frame to RGB for face detection\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Detect faces\n",
    "    boxes, probs = mtcnn.detect(rgb_frame)\n",
    "    \n",
    "    # Process detected faces\n",
    "    if boxes is not None:\n",
    "        # Sort by confidence if available, otherwise by size\n",
    "        if probs is not None:\n",
    "            # Sort by probability (highest first)\n",
    "            sorted_indices = np.argsort(probs)[::-1]\n",
    "            boxes = boxes[sorted_indices]\n",
    "        \n",
    "        # Clear recent faces and add new ones\n",
    "        recent_faces = []\n",
    "        \n",
    "        for i, box in enumerate(boxes):\n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "            \n",
    "            # Draw rectangle on main frame\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            \n",
    "            # Add face number label\n",
    "            cv2.putText(frame, f\"#{i+1}\", (x1, y1 - 10), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "            \n",
    "            # Extract face for panel\n",
    "            face = extract_face(frame, box)\n",
    "            if face is not None:\n",
    "                recent_faces.append(face)\n",
    "    \n",
    "    # Get original dimensions\n",
    "    original_height, original_width = frame.shape[:2]\n",
    "    \n",
    "    # Calculate new dimensions for main video\n",
    "    aspect_ratio = original_height / original_width\n",
    "    new_height = int(target_width * aspect_ratio)\n",
    "    \n",
    "    # Resize the main frame\n",
    "    resized_frame = cv2.resize(frame, (target_width, new_height))\n",
    "    \n",
    "    # Create face panel with matching height\n",
    "    face_panel = create_face_panel(recent_faces, new_height)\n",
    "    \n",
    "    # Combine main frame and face panel horizontally\n",
    "    combined_frame = np.hstack([resized_frame, face_panel])\n",
    "    \n",
    "    # Add timestamp overlay\n",
    "    cv2.putText(combined_frame, f\"Time: {current_time:.1f}s\", (10, 30),\n",
    "               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "    \n",
    "    # Add face count\n",
    "    face_count = len(recent_faces) if recent_faces else 0\n",
    "    cv2.putText(combined_frame, f\"Faces: {face_count}\", (10, 60),\n",
    "               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "    \n",
    "    # Convert to JPEG for display\n",
    "    _, buffer = cv2.imencode('.jpg', combined_frame)\n",
    "    img_bytes = buffer.tobytes()\n",
    "    \n",
    "    # Display in Jupyter Notebook\n",
    "    display(Image(data=img_bytes))\n",
    "    \n",
    "    # Delay for smoother playback\n",
    "    time.sleep(0.015)\n",
    "\n",
    "cap.release()\n",
    "print(\"Video stream ended.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Tracking Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached the specified end time.\n",
      "Video stream ended.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from IPython.display import display, Image, clear_output\n",
    "import numpy as np\n",
    "from pytubefix import YouTube\n",
    "from facenet_pytorch import MTCNN\n",
    "import torch\n",
    "import time\n",
    "from collections import deque\n",
    "\n",
    "# Initialize MTCNN model\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "mtcnn = MTCNN(keep_all=True, device=device)\n",
    "\n",
    "# YouTube video URL\n",
    "video_url = \"https://youtu.be/EsHQB9gT96k?si=bdi3dDrVnYVIgVYi\"\n",
    "video_url = \"https://youtu.be/cmdMopdk6lo?si=vK7azxlZu4PKgiHW\"\n",
    "\n",
    "# Target width for resizing (main video area)\n",
    "target_width = 800\n",
    "\n",
    "# Face panel settings\n",
    "face_panel_width = 150\n",
    "face_thumbnail_size = 120\n",
    "max_faces_display = 4\n",
    "\n",
    "# Start and stop times in seconds\n",
    "start_time = 75\n",
    "end_time = 120\n",
    "\n",
    "\n",
    "class FaceTracker:\n",
    "    \"\"\"Simple IoU-based face tracker with trajectory visualization\"\"\"\n",
    "    \n",
    "    def __init__(self, iou_threshold=0.3, max_disappeared=15, trajectory_length=30):\n",
    "        self.next_id = 1\n",
    "        self.tracked_faces = {}  # id -> {'box': box, 'disappeared': count, 'face_img': img, 'trajectory': deque}\n",
    "        self.iou_threshold = iou_threshold\n",
    "        self.max_disappeared = max_disappeared\n",
    "        self.trajectory_length = trajectory_length\n",
    "        self.colors = {}  # id -> color\n",
    "    \n",
    "    def _compute_iou(self, box1, box2):\n",
    "        \"\"\"Compute Intersection over Union between two boxes\"\"\"\n",
    "        x1 = max(box1[0], box2[0])\n",
    "        y1 = max(box1[1], box2[1])\n",
    "        x2 = min(box1[2], box2[2])\n",
    "        y2 = min(box1[3], box2[3])\n",
    "        \n",
    "        intersection = max(0, x2 - x1) * max(0, y2 - y1)\n",
    "        \n",
    "        area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "        area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "        \n",
    "        union = area1 + area2 - intersection\n",
    "        \n",
    "        return intersection / union if union > 0 else 0\n",
    "    \n",
    "    def _get_center(self, box):\n",
    "        \"\"\"Get center point of a bounding box\"\"\"\n",
    "        return ((box[0] + box[2]) / 2, (box[1] + box[3]) / 2)\n",
    "    \n",
    "    def _get_color(self, track_id):\n",
    "        \"\"\"Get or generate a unique color for each track ID\"\"\"\n",
    "        if track_id not in self.colors:\n",
    "            # Generate distinct colors using golden ratio\n",
    "            hue = (track_id * 0.618033988749895) % 1.0\n",
    "            # Convert HSV to BGR\n",
    "            color = cv2.cvtColor(np.uint8([[[hue * 180, 255, 255]]]), cv2.COLOR_HSV2BGR)[0][0]\n",
    "            self.colors[track_id] = tuple(map(int, color))\n",
    "        return self.colors[track_id]\n",
    "    \n",
    "    def update(self, boxes, face_images):\n",
    "        \"\"\"Update tracker with new detections\"\"\"\n",
    "        if boxes is None or len(boxes) == 0:\n",
    "            # Mark all existing tracks as disappeared\n",
    "            for track_id in list(self.tracked_faces.keys()):\n",
    "                self.tracked_faces[track_id]['disappeared'] += 1\n",
    "                if self.tracked_faces[track_id]['disappeared'] > self.max_disappeared:\n",
    "                    del self.tracked_faces[track_id]\n",
    "            return {}\n",
    "        \n",
    "        # If no existing tracks, register all detections\n",
    "        if len(self.tracked_faces) == 0:\n",
    "            for i, box in enumerate(boxes):\n",
    "                face_img = face_images[i] if i < len(face_images) else None\n",
    "                self._register(box, face_img)\n",
    "        else:\n",
    "            # Match detections to existing tracks using IoU\n",
    "            track_ids = list(self.tracked_faces.keys())\n",
    "            track_boxes = [self.tracked_faces[tid]['box'] for tid in track_ids]\n",
    "            \n",
    "            # Compute IoU matrix\n",
    "            iou_matrix = np.zeros((len(boxes), len(track_boxes)))\n",
    "            for i, det_box in enumerate(boxes):\n",
    "                for j, track_box in enumerate(track_boxes):\n",
    "                    iou_matrix[i, j] = self._compute_iou(det_box, track_box)\n",
    "            \n",
    "            # Greedy matching\n",
    "            matched_detections = set()\n",
    "            matched_tracks = set()\n",
    "            \n",
    "            # Sort by IoU and match greedily\n",
    "            while True:\n",
    "                if iou_matrix.size == 0:\n",
    "                    break\n",
    "                max_iou = np.max(iou_matrix)\n",
    "                if max_iou < self.iou_threshold:\n",
    "                    break\n",
    "                \n",
    "                det_idx, track_idx = np.unravel_index(np.argmax(iou_matrix), iou_matrix.shape)\n",
    "                \n",
    "                # Update matched track\n",
    "                track_id = track_ids[track_idx]\n",
    "                self.tracked_faces[track_id]['box'] = boxes[det_idx]\n",
    "                self.tracked_faces[track_id]['disappeared'] = 0\n",
    "                if det_idx < len(face_images) and face_images[det_idx] is not None:\n",
    "                    self.tracked_faces[track_id]['face_img'] = face_images[det_idx]\n",
    "                \n",
    "                # Update trajectory\n",
    "                center = self._get_center(boxes[det_idx])\n",
    "                self.tracked_faces[track_id]['trajectory'].append(center)\n",
    "                \n",
    "                matched_detections.add(det_idx)\n",
    "                matched_tracks.add(track_idx)\n",
    "                \n",
    "                # Remove matched row and column from consideration\n",
    "                iou_matrix[det_idx, :] = -1\n",
    "                iou_matrix[:, track_idx] = -1\n",
    "            \n",
    "            # Register unmatched detections as new tracks\n",
    "            for i, box in enumerate(boxes):\n",
    "                if i not in matched_detections:\n",
    "                    face_img = face_images[i] if i < len(face_images) else None\n",
    "                    self._register(box, face_img)\n",
    "            \n",
    "            # Increment disappeared count for unmatched tracks\n",
    "            for j, track_id in enumerate(track_ids):\n",
    "                if j not in matched_tracks:\n",
    "                    self.tracked_faces[track_id]['disappeared'] += 1\n",
    "                    if self.tracked_faces[track_id]['disappeared'] > self.max_disappeared:\n",
    "                        del self.tracked_faces[track_id]\n",
    "        \n",
    "        return self.tracked_faces\n",
    "    \n",
    "    def _register(self, box, face_img):\n",
    "        \"\"\"Register a new track\"\"\"\n",
    "        trajectory = deque(maxlen=self.trajectory_length)\n",
    "        trajectory.append(self._get_center(box))\n",
    "        \n",
    "        self.tracked_faces[self.next_id] = {\n",
    "            'box': box,\n",
    "            'disappeared': 0,\n",
    "            'face_img': face_img,\n",
    "            'trajectory': trajectory\n",
    "        }\n",
    "        self.next_id += 1\n",
    "    \n",
    "    def draw_trajectories(self, frame):\n",
    "        \"\"\"Draw trajectories on frame\"\"\"\n",
    "        for track_id, data in self.tracked_faces.items():\n",
    "            if data['disappeared'] == 0:  # Only draw active tracks\n",
    "                trajectory = data['trajectory']\n",
    "                color = self._get_color(track_id)\n",
    "                \n",
    "                # Draw trajectory line\n",
    "                points = list(trajectory)\n",
    "                for i in range(1, len(points)):\n",
    "                    # Fade older points\n",
    "                    alpha = i / len(points)\n",
    "                    thickness = max(1, int(3 * alpha))\n",
    "                    pt1 = tuple(map(int, points[i-1]))\n",
    "                    pt2 = tuple(map(int, points[i]))\n",
    "                    cv2.line(frame, pt1, pt2, color, thickness)\n",
    "                \n",
    "                # Draw current position marker\n",
    "                if points:\n",
    "                    center = tuple(map(int, points[-1]))\n",
    "                    cv2.circle(frame, center, 5, color, -1)\n",
    "        \n",
    "        return frame\n",
    "\n",
    "\n",
    "def extract_face(frame, box, margin=20):\n",
    "    \"\"\"Extract face region from frame with some margin\"\"\"\n",
    "    h, w = frame.shape[:2]\n",
    "    x1, y1, x2, y2 = map(int, box)\n",
    "    \n",
    "    x1 = max(0, x1 - margin)\n",
    "    y1 = max(0, y1 - margin)\n",
    "    x2 = min(w, x2 + margin)\n",
    "    y2 = min(h, y2 + margin)\n",
    "    \n",
    "    face = frame[y1:y2, x1:x2]\n",
    "    \n",
    "    if face.size == 0:\n",
    "        return None\n",
    "    \n",
    "    face_resized = cv2.resize(face, (face_thumbnail_size, face_thumbnail_size))\n",
    "    return face_resized\n",
    "\n",
    "\n",
    "def create_face_panel(tracker, panel_height):\n",
    "    \"\"\"Create a vertical panel with tracked faces\"\"\"\n",
    "    panel = np.ones((panel_height, face_panel_width, 3), dtype=np.uint8) * 40\n",
    "    \n",
    "    cv2.putText(panel, \"Tracked\", (10, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "    cv2.putText(panel, \"Faces\", (10, 45), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "    \n",
    "    # Get active faces sorted by ID\n",
    "    active_faces = [(tid, data) for tid, data in tracker.tracked_faces.items() \n",
    "                    if data['disappeared'] == 0 and data['face_img'] is not None]\n",
    "    active_faces.sort(key=lambda x: x[0])\n",
    "    \n",
    "    spacing = 10\n",
    "    start_y = 60\n",
    "    \n",
    "    for i, (track_id, data) in enumerate(active_faces[:max_faces_display]):\n",
    "        face = data['face_img']\n",
    "        color = tracker._get_color(track_id)\n",
    "        \n",
    "        y_pos = start_y + i * (face_thumbnail_size + spacing)\n",
    "        x_pos = (face_panel_width - face_thumbnail_size) // 2\n",
    "        \n",
    "        if y_pos + face_thumbnail_size <= panel_height:\n",
    "            # Draw border with track color\n",
    "            cv2.rectangle(panel, \n",
    "                         (x_pos - 2, y_pos - 2), \n",
    "                         (x_pos + face_thumbnail_size + 2, y_pos + face_thumbnail_size + 2),\n",
    "                         color, 2)\n",
    "            \n",
    "            panel[y_pos:y_pos + face_thumbnail_size, \n",
    "                  x_pos:x_pos + face_thumbnail_size] = face\n",
    "            \n",
    "            # Add track ID\n",
    "            cv2.putText(panel, f\"ID:{track_id}\", (x_pos, y_pos - 5), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 1)\n",
    "    \n",
    "    return panel\n",
    "\n",
    "\n",
    "# Initialize tracker\n",
    "tracker = FaceTracker(iou_threshold=0.3, max_disappeared=15, trajectory_length=30)\n",
    "\n",
    "# Download the video stream\n",
    "yt = YouTube(video_url)\n",
    "video_stream = yt.streams.filter(file_extension='mp4', progressive=True).first()\n",
    "\n",
    "if not video_stream:\n",
    "    print(\"No compatible video stream found.\")\n",
    "    exit()\n",
    "\n",
    "stream_url = video_stream.url\n",
    "cap = cv2.VideoCapture(stream_url)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open YouTube video stream\")\n",
    "    exit()\n",
    "\n",
    "cap.set(cv2.CAP_PROP_POS_MSEC, start_time * 1000)\n",
    "\n",
    "while cap.isOpened():\n",
    "    clear_output(wait=True)\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        print(\"Stream stopped.\")\n",
    "        break\n",
    "    \n",
    "    current_time = cap.get(cv2.CAP_PROP_POS_MSEC) / 1000\n",
    "    \n",
    "    if current_time >= end_time:\n",
    "        print(\"Reached the specified end time.\")\n",
    "        break\n",
    "    \n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Detect faces\n",
    "    boxes, probs = mtcnn.detect(rgb_frame)\n",
    "    \n",
    "    # Extract face images for detected boxes\n",
    "    face_images = []\n",
    "    if boxes is not None:\n",
    "        for box in boxes:\n",
    "            face_img = extract_face(frame, box)\n",
    "            face_images.append(face_img)\n",
    "    \n",
    "    # Update tracker\n",
    "    tracked = tracker.update(boxes, face_images)\n",
    "    \n",
    "    # Draw tracked faces on frame\n",
    "    for track_id, data in tracked.items():\n",
    "        if data['disappeared'] == 0:\n",
    "            box = data['box']\n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "            color = tracker._get_color(track_id)\n",
    "            \n",
    "            # Draw bounding box\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "            \n",
    "            # Draw ID label with background\n",
    "            label = f\"ID:{track_id}\"\n",
    "            (label_w, label_h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)\n",
    "            cv2.rectangle(frame, (x1, y1 - label_h - 10), (x1 + label_w + 5, y1), color, -1)\n",
    "            cv2.putText(frame, label, (x1 + 2, y1 - 5), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "    \n",
    "    # Draw trajectories\n",
    "    frame = tracker.draw_trajectories(frame)\n",
    "    \n",
    "    # Resize frame\n",
    "    original_height, original_width = frame.shape[:2]\n",
    "    aspect_ratio = original_height / original_width\n",
    "    new_height = int(target_width * aspect_ratio)\n",
    "    resized_frame = cv2.resize(frame, (target_width, new_height))\n",
    "    \n",
    "    # Create face panel\n",
    "    face_panel = create_face_panel(tracker, new_height)\n",
    "    \n",
    "    # Combine frames\n",
    "    combined_frame = np.hstack([resized_frame, face_panel])\n",
    "    \n",
    "    # Add overlays\n",
    "    cv2.putText(combined_frame, f\"Time: {current_time:.1f}s\", (10, 30),\n",
    "               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "    \n",
    "    active_count = sum(1 for d in tracked.values() if d['disappeared'] == 0)\n",
    "    cv2.putText(combined_frame, f\"Tracking: {active_count} faces\", (10, 60),\n",
    "               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "    \n",
    "    cv2.putText(combined_frame, f\"Total IDs: {tracker.next_id - 1}\", (10, 90),\n",
    "               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)\n",
    "    \n",
    "    # Display\n",
    "    _, buffer = cv2.imencode('.jpg', combined_frame)\n",
    "    img_bytes = buffer.tobytes()\n",
    "    display(Image(data=img_bytes))\n",
    "    \n",
    "    time.sleep(0.015)\n",
    "\n",
    "cap.release()\n",
    "print(\"Video stream ended.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
