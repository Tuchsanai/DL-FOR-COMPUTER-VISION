# ---
# jupyter:
#   jupytext:
#     cell_metadata_filter: -all
#     formats: ipynb,py:percent
#     text_representation:
#       extension: .py
#       format_name: percent
#       format_version: '1.3'
#       jupytext_version: 1.18.1
#   kernelspec:
#     display_name: Python (MLOps VEnv)
#     language: python
#     name: mlops-env
# ---

# %% [markdown]
# # üî• PyTorch Fundamentals Lab - Day 2 (‡∏â‡∏ö‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢)
# **Datasets, DataLoaders, CNNs, RNNs ‡πÅ‡∏•‡∏∞ Best Practices**
#
# ## üìö ‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏à‡∏∞‡πÑ‡∏î‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ:
# - **Datasets & DataLoaders** - ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û
# - **Image Folder DataLoader** - ‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏à‡∏≤‡∏Å‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå
# - **Transforms & Augmentation** - ‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡πÅ‡∏•‡∏∞‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
# - **CNN** - Convolutional Neural Networks ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û
# - **RNN/LSTM** - Recurrent Networks ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Sequential Data
# - **Training Best Practices** - ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏Å‡∏≤‡∏£ train ‡∏ó‡∏µ‡πà‡∏î‡∏µ
# - **GPU Optimization** - ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ GPU ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û
#
# ## üìù Prerequisites:
# ‡∏Ñ‡∏ß‡∏£‡∏ú‡πà‡∏≤‡∏ô Day 1 ‡∏°‡∏≤‡∏Å‡πà‡∏≠‡∏ô (Tensors, Autograd, Basic Neural Networks)

# %% [markdown]
# ---
# # üì¶ Module 1: Setup
# ---

# %%
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader, random_split, WeightedRandomSampler
import torchvision
import torchvision.transforms as transforms
from torchvision.datasets import ImageFolder
from collections import Counter
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm
import time
import os

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤
print(f"üì¶ PyTorch version: {torch.__version__}")
print(f"üì¶ Torchvision version: {torchvision.__version__}")

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"üéÆ Using device: {device}")

if torch.cuda.is_available():
    print(f"   GPU: {torch.cuda.get_device_name(0)}")

# %%
def set_seed(seed=42):
    """‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ seed ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö reproducibility"""
    torch.manual_seed(seed)
    np.random.seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
        torch.backends.cudnn.deterministic = True
        torch.backends.cudnn.benchmark = False

set_seed(42)
print("üå± Seed set to 42")

# %% [markdown]
# ---
# # üìä Module 2: Datasets ‡πÅ‡∏•‡∏∞ DataLoaders
# ---
#
# ## ‡∏ó‡∏≥‡πÑ‡∏°‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ Dataset ‡πÅ‡∏•‡∏∞ DataLoader?
#
# **‡∏õ‡∏±‡∏ç‡∏´‡∏≤:** ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£ train ‡∏à‡∏£‡∏¥‡∏á ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏°‡∏±‡∏Å‡∏à‡∏∞:
# - ‡πÉ‡∏´‡∏ç‡πà‡∏°‡∏≤‡∏Å ‚Üí ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏Ç‡πâ‡∏≤ RAM ‡∏ó‡∏µ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ
# - ‡∏ï‡πâ‡∏≠‡∏á shuffle ‚Üí ‡πÑ‡∏°‡πà‡∏á‡∏±‡πâ‡∏ô model ‡∏à‡∏∞‡∏à‡∏≥‡∏•‡∏≥‡∏î‡∏±‡∏ö‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ pattern
# - ‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏ö‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô batch ‚Üí GPU ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏´‡∏•‡∏≤‡∏¢‡πÜ ‡∏ï‡∏±‡∏ß‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô
#
# **‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ:**
# - **Dataset** = "‡∏™‡∏π‡∏ï‡∏£‡∏≠‡∏≤‡∏´‡∏≤‡∏£" ‡∏ö‡∏≠‡∏Å‡∏ß‡πà‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏¢‡∏π‡πà‡∏ó‡∏µ‡πà‡πÑ‡∏´‡∏ô ‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á‡∏¢‡∏±‡∏á‡πÑ‡∏á
# - **DataLoader** = "‡∏û‡πà‡∏≠‡∏Ñ‡∏£‡∏±‡∏ß" ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏ó‡∏∏‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÉ‡∏´‡πâ (shuffle, ‡πÅ‡∏ö‡πà‡∏á batch, ‡πÇ‡∏´‡∏•‡∏î‡∏•‡πà‡∏ß‡∏á‡∏´‡∏ô‡πâ‡∏≤)

# %% [markdown]
# ## 2.1 ‡∏™‡∏£‡πâ‡∏≤‡∏á Custom Dataset
#
# **‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏≤‡∏£‡∏á‡πà‡∏≤‡∏¢‡πÜ:** Dataset ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ 3 methods:
# 1. `__init__()` ‚Üí ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏ï‡∏≠‡∏ô‡∏™‡∏£‡πâ‡∏≤‡∏á)
# 2. `__len__()` ‚Üí ‡∏ö‡∏≠‡∏Å‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏µ‡πà‡∏ï‡∏±‡∏ß
# 3. `__getitem__(idx)` ‚Üí ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡∏ß‡∏ó‡∏µ‡πà idx ‡∏≠‡∏≠‡∏Å‡∏°‡∏≤
#
# **‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö:** ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠
# - `__init__` = ‡∏û‡∏¥‡∏°‡∏û‡πå‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠
# - `__len__` = ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏´‡∏ô‡πâ‡∏≤
# - `__getitem__` = ‡πÄ‡∏õ‡∏¥‡∏î‡πÑ‡∏õ‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£

# %%
class SimpleDataset(Dataset):
    """
    Custom Dataset ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö XOR problem
    
    XOR ‡∏Ñ‡∏∑‡∏≠:
    - (0,0) ‚Üí 0  (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ô = 0)
    - (0,1) ‚Üí 1  (‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô = 1)
    - (1,0) ‚Üí 1  (‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô = 1)
    - (1,1) ‚Üí 0  (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ô = 0)
    
    ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ô‡∏µ‡πâ‡∏¢‡∏≤‡∏Å‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏ö‡πà‡∏á‡∏î‡πâ‡∏ß‡∏¢‡πÄ‡∏™‡πâ‡∏ô‡∏ï‡∏£‡∏á‡πÄ‡∏™‡πâ‡∏ô‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡πÑ‡∏î‡πâ!
    """
    
    def __init__(self, n_samples=1000, noise=0.1):
        """
        Args:
            n_samples: ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
            noise: ‡∏£‡∏∞‡∏î‡∏±‡∏ö noise (‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∏‡πà‡∏°) ‡∏ó‡∏µ‡πà‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ
        """
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏à‡∏∏‡∏î‡∏™‡∏∏‡πà‡∏°‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á [0, 1]
        self.X = torch.rand(n_samples, 2)
        
        # XOR logic: ‡∏ñ‡πâ‡∏≤‡∏≠‡∏¢‡∏π‡πà‡∏Ñ‡∏ô‡∏•‡∏∞‡∏ù‡∏±‡πà‡∏á‡∏Ç‡∏≠‡∏á 0.5 = class 1
        # ^ ‡∏Ñ‡∏∑‡∏≠ XOR operator ‡πÉ‡∏ô Python
        xor_values = (self.X[:, 0] > 0.5) ^ (self.X[:, 1] > 0.5)
        self.y = xor_values.long()
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏° noise ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ realistic ‡∏Ç‡∏∂‡πâ‡∏ô
        self.X = self.X + noise * torch.randn_like(self.X)
    
    def __len__(self):
        """‡∏ö‡∏≠‡∏Å‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"""
        return len(self.y)
    
    def __getitem__(self, idx):
        """‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• 1 ‡∏ï‡∏±‡∏ß‡∏ó‡∏µ‡πà index idx"""
        return self.X[idx], self.y[idx]

# ‡∏™‡∏£‡πâ‡∏≤‡∏á dataset
dataset = SimpleDataset(n_samples=1000)
print(f"Dataset size: {len(dataset)}")

# ‡∏î‡∏π‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
x, y = dataset[0]
print(f"Sample 0: x={x}, y={y}")

# %% [markdown]
# ## 2.2 Visualize Dataset

# %%
# Visualize XOR dataset
X_all = dataset.X.numpy()
y_all = dataset.y.numpy()

plt.figure(figsize=(8, 6))
plt.scatter(X_all[y_all == 0, 0], X_all[y_all == 0, 1], 
            c='blue', label='Class 0', alpha=0.6)
plt.scatter(X_all[y_all == 1, 0], X_all[y_all == 1, 1], 
            c='red', label='Class 1', alpha=0.6)
plt.xlabel('X1')
plt.ylabel('X2')
plt.title('XOR Dataset\n(Class 1 = opposite sides of 0.5)')
plt.legend()
plt.grid(True)
plt.axhline(y=0.5, color='gray', linestyle='--', alpha=0.5)
plt.axvline(x=0.5, color='gray', linestyle='--', alpha=0.5)

plt.show()

# %% [markdown]
# ## 2.3 DataLoader - ‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô Batches
#
# **DataLoader ‡∏ó‡∏≥‡∏≠‡∏∞‡πÑ‡∏£‡∏ö‡πâ‡∏≤‡∏á:**
# - **batch_size** ‚Üí ‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏µ‡πà‡∏ï‡∏±‡∏ß‡πÄ‡∏õ‡πá‡∏ô 1 batch (‡πÄ‡∏ä‡πà‡∏ô 32 ‡∏£‡∏π‡∏õ‡∏ï‡πà‡∏≠‡∏Ñ‡∏£‡∏±‡πâ‡∏á)
# - **shuffle** ‚Üí ‡∏™‡∏•‡∏±‡∏ö‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ï‡∏≠‡∏ô train!)
# - **num_workers** ‚Üí ‡πÉ‡∏ä‡πâ‡∏Å‡∏µ‡πà CPU cores ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ 0 = ‡πÄ‡∏£‡πá‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô)
# - **drop_last** ‚Üí ‡∏ó‡∏¥‡πâ‡∏á batch ‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏Ñ‡∏£‡∏ö (‡πÄ‡∏ä‡πà‡∏ô ‡πÄ‡∏´‡∏•‡∏∑‡∏≠ 20 ‡∏ï‡∏±‡∏ß ‡πÅ‡∏ï‡πà batch_size=32)
#
# **‡∏ó‡∏≥‡πÑ‡∏° batch_size ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç:**
# - ‡πÄ‡∏•‡πá‡∏Å‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ (1-4) ‚Üí train ‡∏ô‡∏≤‡∏ô, noisy gradients
# - ‡πÉ‡∏´‡∏ç‡πà‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ (512+) ‚Üí RAM/GPU ‡πÑ‡∏°‡πà‡∏û‡∏≠, generalize ‡πÑ‡∏î‡πâ‡πÅ‡∏¢‡πà‡∏•‡∏á
# - ‡∏û‡∏≠‡∏î‡∏µ (16-128) ‚Üí balance ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡πÅ‡∏•‡∏∞‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û

# %%
# ‡∏™‡∏£‡πâ‡∏≤‡∏á DataLoader
dataloader = DataLoader(
    dataset,
    batch_size=32,      # 32 samples ‡∏ï‡πà‡∏≠ batch
    shuffle=True,       # ‡∏™‡∏•‡∏±‡∏ö‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏ó‡∏∏‡∏Å epoch
    num_workers=0,      # ‡πÉ‡∏ä‡πâ main process (‡πÉ‡∏™‡πà >0 ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö parallel loading)
    drop_last=False     # ‡πÄ‡∏Å‡πá‡∏ö batch ‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡πÅ‡∏°‡πâ‡πÑ‡∏°‡πà‡∏Ñ‡∏£‡∏ö
)

print(f"Number of batches: {len(dataloader)}")
print(f"Batch size: {dataloader.batch_size}")

# %% [markdown]
# ## 2.4 ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô DataLoader

# %%
# Iterate ‡∏ú‡πà‡∏≤‡∏ô DataLoader
print("First 3 batches:")
for i, (X_batch, y_batch) in enumerate(dataloader):
    print(f"  Batch {i}: X shape = {X_batch.shape}, y shape = {y_batch.shape}")
    if i >= 2:
        break

# %% [markdown]
# ## 2.5 ‡πÅ‡∏ö‡πà‡∏á Train/Validation/Test Sets
#
# **‡∏ó‡∏≥‡πÑ‡∏°‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏ö‡πà‡∏á 3 ‡∏™‡πà‡∏ß‡∏ô?**
#
# | ‡∏™‡πà‡∏ß‡∏ô | ‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô | ‡πÉ‡∏ä‡πâ‡∏ó‡∏≥‡∏≠‡∏∞‡πÑ‡∏£ | ‡πÅ‡∏ï‡∏∞‡∏Å‡∏µ‡πà‡∏Ñ‡∏£‡∏±‡πâ‡∏á |
# |------|---------|-----------|-------------|
# | **Train** | 70-80% | ‡∏™‡∏≠‡∏ô model | ‡∏ó‡∏∏‡∏Å epoch |
# | **Validation** | 10-15% | tune hyperparameters, ‡∏î‡∏π overfitting | ‡∏ó‡∏∏‡∏Å epoch |
# | **Test** | 10-15% | ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢ | **‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß!** |
#
# **‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç:** ‡∏´‡πâ‡∏≤‡∏°‡πÅ‡∏ï‡∏∞ Test set ‡∏à‡∏ô‡∏Å‡∏ß‡πà‡∏≤ model ‡∏à‡∏∞‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå!

# %%
# ‡∏™‡∏£‡πâ‡∏≤‡∏á dataset
full_dataset = SimpleDataset(n_samples=1000)

# ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
train_size = int(0.7 * len(full_dataset))  # 70%
val_size = int(0.15 * len(full_dataset))   # 15%
test_size = len(full_dataset) - train_size - val_size  # 15%

train_dataset, val_dataset, test_dataset = random_split(
    full_dataset, 
    [train_size, val_size, test_size],
    generator=torch.Generator().manual_seed(42)  # reproducible split
)

print(f"Train: {len(train_dataset)} samples")
print(f"Val: {len(val_dataset)} samples")
print(f"Test: {len(test_dataset)} samples")

# %%
# ‡∏™‡∏£‡πâ‡∏≤‡∏á DataLoaders
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)  # ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á shuffle
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

print(f"Train batches: {len(train_loader)}")
print(f"Val batches: {len(val_loader)}")
print(f"Test batches: {len(test_loader)}")

# %% [markdown]
# ## 2.6 Built-in Datasets ‡∏à‡∏≤‡∏Å Torchvision
#
# **‡∏Ç‡πâ‡∏≠‡∏î‡∏µ:** ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô Dataset ‡πÄ‡∏≠‡∏á, download ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
#
# **Datasets ‡∏¢‡∏≠‡∏î‡∏ô‡∏¥‡∏¢‡∏°:**
# - **MNIST** ‚Üí ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏°‡∏∑‡∏≠ 0-9 (28√ó28 grayscale) - ‡∏á‡πà‡∏≤‡∏¢‡∏™‡∏∏‡∏î
# - **CIFAR-10** ‚Üí ‡∏£‡∏π‡∏õ‡∏™‡∏µ 10 ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó (32√ó32) - ‡∏Å‡∏•‡∏≤‡∏á‡πÜ
# - **CIFAR-100** ‚Üí ‡∏£‡∏π‡∏õ‡∏™‡∏µ 100 ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó - ‡∏¢‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô
# - **ImageNet** ‚Üí ‡∏£‡∏π‡∏õ‡∏à‡∏£‡∏¥‡∏á 1000 ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó - ‡∏¢‡∏≤‡∏Å‡∏°‡∏≤‡∏Å

# %%
# ‡πÇ‡∏´‡∏•‡∏î MNIST dataset
mnist_train = torchvision.datasets.MNIST(
    root='./data',           # ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    train=True,              # training set
    download=True,           # download ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ
    transform=transforms.ToTensor()  # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô tensor
)

mnist_test = torchvision.datasets.MNIST(
    root='./data',
    train=False,
    download=True,
    transform=transforms.ToTensor()
)

print(f"MNIST Training: {len(mnist_train)} images")
print(f"MNIST Test: {len(mnist_test)} images")

# %% [markdown]
# ## 2.7 ‡∏™‡∏≥‡∏£‡∏ß‡∏à MNIST Dataset

# %%
# ‡∏î‡∏π‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û
image, label = mnist_train[0]
print(f"Image shape: {image.shape}")  # (1, 28, 28) = (Channels, Height, Width)
print(f"Label: {label}")
print(f"Pixel range: [{image.min():.2f}, {image.max():.2f}]")

# %%
# ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û
fig, axes = plt.subplots(2, 5, figsize=(12, 5))
for i, ax in enumerate(axes.flat):
    image, label = mnist_train[i]
    ax.imshow(image.squeeze(), cmap='gray')
    ax.set_title(f'Label: {label}')
    ax.axis('off')
plt.suptitle('MNIST Dataset Samples', fontsize=14)
plt.tight_layout()

plt.show()

# %% [markdown]
# ---
# # üì∑ Module 2.5: DataLoader ‡∏à‡∏≤‡∏Å Image Folder (Real-World Images)
# ---
#
# ## ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå
#
# **‡πÉ‡∏ô‡πÇ‡∏•‡∏Å‡∏à‡∏£‡∏¥‡∏á ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏°‡∏±‡∏Å‡∏à‡∏∞:**
# - ‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå (jpg, png)
# - ‡∏à‡∏±‡∏î‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏° class (‡πÅ‡∏ï‡πà‡∏•‡∏∞ class = 1 ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå)
# - ‡∏Ç‡∏ô‡∏≤‡∏î‡πÑ‡∏°‡πà‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ô ‚Üí ‡∏ï‡πâ‡∏≠‡∏á resize
#
# **‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏û‡∏ö‡∏ö‡πà‡∏≠‡∏¢:**
# ```
# dataset/
# ‚îú‚îÄ‚îÄ train/
# ‚îÇ   ‚îú‚îÄ‚îÄ class_1/
# ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ img001.jpg
# ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ img002.jpg
# ‚îÇ   ‚îî‚îÄ‚îÄ class_2/
# ‚îÇ       ‚îî‚îÄ‚îÄ img003.jpg
# ‚îî‚îÄ‚îÄ val/
#     ‚îú‚îÄ‚îÄ class_1/
#     ‚îî‚îÄ‚îÄ class_2/
# ```
#
# ## üìÅ ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á: Animal Faces Dataset (AFHQ)
# ```
# afhq/
# ‚îú‚îÄ‚îÄ train/
# ‚îÇ   ‚îú‚îÄ‚îÄ cat/      (~5000 images)
# ‚îÇ   ‚îú‚îÄ‚îÄ dog/      (~5000 images)
# ‚îÇ   ‚îî‚îÄ‚îÄ wild/     (~5000 images)
# ‚îî‚îÄ‚îÄ val/
#     ‚îú‚îÄ‚îÄ cat/      (~500 images)
#     ‚îú‚îÄ‚îÄ dog/      (~500 images)
#     ‚îî‚îÄ‚îÄ wild/     (~500 images)
# ```

# %% [markdown]
# ## 2.8 Download Dataset ‡∏à‡∏≤‡∏Å Kaggle

# %%
import kagglehub

# ‚úÖ ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Kaggle API credentials (‡∏à‡∏≤‡∏Å kaggle.json)
os.environ["KAGGLE_USERNAME"] = "your_username"  # ‚Üê ‡πÅ‡∏Å‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì
os.environ["KAGGLE_KEY"] = "your_api_key"        # ‚Üê ‡πÅ‡∏Å‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì

# ‚úÖ ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πá‡∏ö cache ‡∏Ç‡∏≠‡∏á kagglehub (optional)
os.environ["KAGGLEHUB_CACHE"] = os.path.abspath("./kaggle_cache")

# Download dataset
dataset_dir = kagglehub.dataset_download("andrewmvd/animal-faces")

print(f"‚úÖ Dataset downloaded to: {dataset_dir}")

# %% [markdown]
# ## 2.9 ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á Dataset ‡πÅ‡∏•‡∏∞‡∏´‡∏≤ Path ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á

# %%
def find_dataset_paths(base_dir):
    """
    ‡∏´‡∏≤ train ‡πÅ‡∏•‡∏∞ val directories ‡∏à‡∏≤‡∏Å base_dir
    
    Args:
        base_dir: path ‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å kagglehub.dataset_download()
    
    Returns:
        tuple: (train_dir, val_dir) ‡∏´‡∏£‡∏∑‡∏≠ (None, None) ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠
    """
    train_dir = None
    val_dir = None
    
    # ‡πÅ‡∏™‡∏î‡∏á‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á folder
    print(f"üìÅ Searching in: {base_dir}")
    print(f"üìÅ Contents:")
    
    for item in os.listdir(base_dir):
        item_path = os.path.join(base_dir, item)
        if os.path.isdir(item_path):
            print(f"   üìÇ {item}/")
            # ‡∏î‡∏π sub-folders
            for sub_item in os.listdir(item_path):
                sub_path = os.path.join(item_path, sub_item)
                if os.path.isdir(sub_path):
                    print(f"      ‚îî‚îÄ‚îÄ {sub_item}/")
    
    # ‡∏´‡∏≤ train folder
    print(f"\nüîç Searching for 'train' folder...")
    
    for root, dirs, files in os.walk(base_dir):
        if 'train' in dirs:
            train_dir = os.path.join(root, 'train')
            val_dir = os.path.join(root, 'val')
            print(f"   ‚úÖ Found train at: {train_dir}")
            print(f"   ‚úÖ Found val at: {val_dir}")
            
            # ‡πÅ‡∏™‡∏î‡∏á classes
            if os.path.exists(train_dir):
                classes = [d for d in os.listdir(train_dir) 
                          if os.path.isdir(os.path.join(train_dir, d))]
                print(f"   üìã Classes: {classes}")
            break
    
    if train_dir is None:
        print("   ‚ùå Could not find 'train' folder!")
    
    return train_dir, val_dir


# ‡∏´‡∏≤ paths
TRAIN_DIR, VAL_DIR = find_dataset_paths(dataset_dir)

# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ paths ‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡∏à‡∏£‡∏¥‡∏á
if TRAIN_DIR and os.path.exists(TRAIN_DIR):
    print(f"\n‚úÖ TRAIN_DIR is valid: {TRAIN_DIR}")
    print(f"‚úÖ VAL_DIR is valid: {VAL_DIR}")
else:
    print("\n‚ùå Paths not found! Please check dataset structure manually.")

# %% [markdown]
# ## 2.10 ‡∏™‡∏£‡πâ‡∏≤‡∏á Transforms

# %%
# === Transform ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Training ===
# ‡∏£‡∏ß‡∏° augmentation + preprocessing
train_transform = transforms.Compose([
    transforms.Resize((224, 224)),          # ‡∏õ‡∏£‡∏±‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡πâ‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ô
    transforms.RandomHorizontalFlip(p=0.5), # ‡∏û‡∏•‡∏¥‡∏Å‡∏ã‡πâ‡∏≤‡∏¢-‡∏Ç‡∏ß‡∏≤ 50%
    transforms.RandomRotation(15),          # ‡∏´‡∏°‡∏∏‡∏ô ¬±15 ‡∏≠‡∏á‡∏®‡∏≤
    transforms.ColorJitter(
        brightness=0.2,
        contrast=0.2,
        saturation=0.2,
        hue=0.1
    ),
    transforms.ToTensor(),                  # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô tensor [0, 1]
    transforms.Normalize(                   # Normalize ‡∏î‡πâ‡∏ß‡∏¢ ImageNet stats
        mean=[0.485, 0.456, 0.406],
        std=[0.229, 0.224, 0.225]
    )
])

# === Transform ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Validation/Test ===
# ‡πÑ‡∏°‡πà‡∏°‡∏µ augmentation ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ú‡∏•‡∏ó‡∏µ‡πà‡∏Ñ‡∏á‡∏ó‡∏µ‡πà
val_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(
        mean=[0.485, 0.456, 0.406],
        std=[0.229, 0.224, 0.225]
    )
])

print("‚úÖ Transforms ready!")
print("   Train: Resize ‚Üí Flip ‚Üí Rotate ‚Üí ColorJitter ‚Üí Normalize")
print("   Val:   Resize ‚Üí Normalize (‡πÑ‡∏°‡πà‡∏°‡∏µ augmentation)")

# %% [markdown]
# ## 2.11 ‡∏™‡∏£‡πâ‡∏≤‡∏á Dataset ‡∏î‡πâ‡∏ß‡∏¢ ImageFolder

# %%
# === ‡∏™‡∏£‡πâ‡∏≤‡∏á Dataset ‡∏î‡πâ‡∏ß‡∏¢ ImageFolder ===
# ‡πÉ‡∏ä‡πâ TRAIN_DIR ‡πÅ‡∏•‡∏∞ VAL_DIR ‡∏ó‡∏µ‡πà‡∏´‡∏≤‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤

train_dataset_img = ImageFolder(root=TRAIN_DIR, transform=train_transform)
val_dataset_img = ImageFolder(root=VAL_DIR, transform=val_transform)

print(f"‚úÖ Training samples: {len(train_dataset_img)}")
print(f"‚úÖ Validation samples: {len(val_dataset_img)}")
print(f"‚úÖ Classes: {train_dataset_img.classes}")
print(f"‚úÖ Class to index: {train_dataset_img.class_to_idx}")

# %% [markdown]
# ## 2.12 ‡∏™‡∏£‡πâ‡∏≤‡∏á DataLoader

# %%
# === ‡∏™‡∏£‡πâ‡∏≤‡∏á DataLoader ===
train_loader_img = DataLoader(
    train_dataset_img,
    batch_size=32,
    shuffle=True,           # ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç! ‡∏™‡∏•‡∏±‡∏ö‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏ï‡∏≠‡∏ô train
    num_workers=4,          # ‡πÉ‡∏ä‡πâ 4 CPU cores ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    pin_memory=True         # ‡πÄ‡∏£‡πá‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô‡∏ñ‡πâ‡∏≤‡πÉ‡∏ä‡πâ GPU
)

val_loader_img = DataLoader(
    val_dataset_img,
    batch_size=32,
    shuffle=False,          # ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á shuffle ‡∏ï‡∏≠‡∏ô validate
    num_workers=4,
    pin_memory=True
)

print(f"üì¶ Train batches: {len(train_loader_img)}")
print(f"üì¶ Val batches: {len(val_loader_img)}")

# %% [markdown]
# ## 2.13 ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• 1 batch

# %%
# === ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• 1 batch ===
images, labels = next(iter(train_loader_img))

print(f"üñºÔ∏è Batch images shape: {images.shape}")  # (32, 3, 224, 224)
print(f"üè∑Ô∏è Batch labels shape: {labels.shape}")  # (32,)
print(f"üè∑Ô∏è Labels sample: {labels[:5].tolist()}")
print(f"üè∑Ô∏è Class names: {[train_dataset_img.classes[l] for l in labels[:5].tolist()]}")

# %% [markdown]
# ## 2.14 ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏£‡∏π‡∏õ‡∏à‡∏≤‡∏Å Dataset

# %%
def show_batch(images, labels, class_names, n_images=8):
    """
    ‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏π‡∏õ‡∏à‡∏≤‡∏Å batch
    
    Args:
        images: tensor shape (B, C, H, W)
        labels: tensor shape (B,)
        class_names: list ‡∏Ç‡∏≠‡∏á‡∏ä‡∏∑‡πà‡∏≠ class
        n_images: ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡∏π‡∏õ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÅ‡∏™‡∏î‡∏á
    """
    # Denormalize ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏• (ImageNet stats)
    mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)
    std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)
    
    fig, axes = plt.subplots(2, 4, figsize=(14, 7))
    
    for i, ax in enumerate(axes.flat):
        if i >= n_images or i >= len(images):
            ax.axis('off')
            continue
        
        # Denormalize
        img = images[i] * std + mean
        img = img.permute(1, 2, 0).numpy()  # (C, H, W) ‚Üí (H, W, C)
        img = img.clip(0, 1)  # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ñ‡πà‡∏≤‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô [0, 1]
        
        ax.imshow(img)
        ax.set_title(f'{class_names[labels[i]]}', fontsize=12)
        ax.axis('off')
    
    plt.suptitle('Animal Faces Dataset Samples', fontsize=14)
    plt.tight_layout()
    plt.show()

# ‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏π‡∏õ
show_batch(images, labels, train_dataset_img.classes)

# %% [markdown]
# ## 2.15 Custom Dataset ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Images (Alternative Method)
#
# **‡πÉ‡∏ä‡πâ‡πÄ‡∏°‡∏∑‡πà‡∏≠:**
# - ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÑ‡∏°‡πà‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô
# - ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ preprocess ‡∏û‡∏¥‡πÄ‡∏®‡∏©
# - ‡∏°‡∏µ metadata ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏° (‡πÄ‡∏ä‡πà‡∏ô bounding box, segmentation mask)
# - ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ filter ‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢

# %%
class CustomImageDataset(Dataset):
    """
    Custom Dataset ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û
    
    ‡∏Ç‡πâ‡∏≠‡∏î‡∏µ:
    - ‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏î‡πâ‡πÄ‡∏ï‡πá‡∏°‡∏ó‡∏µ‡πà
    - ‡πÄ‡∏û‡∏¥‡πà‡∏° logic ‡∏û‡∏¥‡πÄ‡∏®‡∏©‡πÑ‡∏î‡πâ (‡πÄ‡∏ä‡πà‡∏ô filter ‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢)
    - ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö metadata ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°
    """
    
    def __init__(self, root_dir, transform=None):
        """
        Args:
            root_dir: path ‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ class folders
            transform: transforms ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ö‡∏£‡∏π‡∏õ
        """
        self.root_dir = root_dir
        self.transform = transform
        
        # ‡∏´‡∏≤ class folders
        self.classes = sorted([d for d in os.listdir(root_dir) 
                               if os.path.isdir(os.path.join(root_dir, d))])
        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}
        
        # ‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡∏£‡∏π‡∏õ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
        self.samples = []
        self.valid_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.webp', '.gif'}
        
        for class_name in self.classes:
            class_dir = os.path.join(root_dir, class_name)
            class_idx = self.class_to_idx[class_name]
            
            for filename in os.listdir(class_dir):
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö extension
                ext = os.path.splitext(filename)[1].lower()
                if ext in self.valid_extensions:
                    filepath = os.path.join(class_dir, filename)
                    self.samples.append((filepath, class_idx))
        
        print(f"Found {len(self.samples)} images in {len(self.classes)} classes")
    
    def __len__(self):
        """‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡∏π‡∏õ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"""
        return len(self.samples)
    
    def __getitem__(self, idx):
        """‡∏î‡∏∂‡∏á‡∏£‡∏π‡∏õ‡∏ó‡∏µ‡πà index idx"""
        img_path, label = self.samples[idx]
        
        # ‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏π‡∏õ
        image = Image.open(img_path).convert('RGB')  # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô RGB ‡πÄ‡∏™‡∏°‡∏≠
        
        # Apply transform
        if self.transform:
            image = self.transform(image)
        
        return image, label
    
    def get_class_name(self, idx):
        """‡πÅ‡∏õ‡∏•‡∏á index ‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡∏∑‡πà‡∏≠ class"""
        return self.classes[idx]


# ‡∏ó‡∏î‡∏™‡∏≠‡∏ö Custom Dataset
print("\nüìù Testing CustomImageDataset...")
custom_train = CustomImageDataset(root_dir=TRAIN_DIR, transform=train_transform)
print(f"   Classes: {custom_train.classes}")
print(f"   Total samples: {len(custom_train)}")

# ‡∏î‡∏∂‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á 1 ‡∏£‡∏π‡∏õ
img, label = custom_train[0]
print(f"   Image shape: {img.shape}")
print(f"   Label: {label} ({custom_train.get_class_name(label)})")

# %% [markdown]
# ## 2.16 ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏£‡∏π‡∏õ‡∏ó‡∏µ‡πà‡∏Ç‡∏ô‡∏≤‡∏î‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô
#
# **‡∏õ‡∏±‡∏ç‡∏´‡∏≤:** ‡∏£‡∏π‡∏õ‡∏à‡∏≤‡∏Å real-world ‡∏°‡∏±‡∏Å‡∏°‡∏µ‡∏Ç‡∏ô‡∏≤‡∏î‡πÑ‡∏°‡πà‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ô
#
# **‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ:**
#
# | ‡∏ß‡∏¥‡∏ò‡∏µ | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ | ‡∏Ç‡πâ‡∏≠‡∏î‡∏µ | ‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏µ‡∏¢ |
# |------|----------|-------|---------|
# | **Resize** | ‡∏õ‡∏£‡∏±‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î‡∏ï‡∏£‡∏á‡πÜ | ‡∏á‡πà‡∏≤‡∏¢ | ‡∏≠‡∏≤‡∏à‡πÄ‡∏™‡∏µ‡∏¢ aspect ratio |
# | **CenterCrop** | crop ‡∏ï‡∏£‡∏á‡∏Å‡∏•‡∏≤‡∏á | ‡∏£‡∏±‡∏Å‡∏©‡∏≤ aspect ratio | ‡πÄ‡∏™‡∏µ‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏≠‡∏ö |
# | **RandomResizedCrop** | crop + resize ‡πÅ‡∏ö‡∏ö‡∏™‡∏∏‡πà‡∏° | data augmentation | ‡∏™‡∏∏‡πà‡∏°‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á |

# %%
# === ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á transforms ‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ç‡∏ô‡∏≤‡∏î ===

# ‡∏ß‡∏¥‡∏ò‡∏µ 1: Resize ‡∏ï‡∏£‡∏á‡πÜ (‡∏≠‡∏≤‡∏à‡πÄ‡∏™‡∏µ‡∏¢ aspect ratio)
transform_resize = transforms.Compose([
    transforms.Resize((224, 224)),  # ‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î 224x224
    transforms.ToTensor()
])

# ‡∏ß‡∏¥‡∏ò‡∏µ 2: Resize ‡πÉ‡∏´‡πâ‡∏î‡πâ‡∏≤‡∏ô‡∏™‡∏±‡πâ‡∏ô‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ö target ‡πÅ‡∏•‡πâ‡∏ß CenterCrop
transform_center = transforms.Compose([
    transforms.Resize(256),          # ‡∏î‡πâ‡∏≤‡∏ô‡∏™‡∏±‡πâ‡∏ô = 256
    transforms.CenterCrop(224),      # crop ‡∏ï‡∏£‡∏á‡∏Å‡∏•‡∏≤‡∏á 224x224
    transforms.ToTensor()
])

# ‡∏ß‡∏¥‡∏ò‡∏µ 3: RandomResizedCrop (‡∏î‡∏µ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö training - data augmentation)
transform_random = transforms.Compose([
    transforms.RandomResizedCrop(
        224,
        scale=(0.8, 1.0),    # crop 80-100% ‡∏Ç‡∏≠‡∏á‡∏£‡∏π‡∏õ
        ratio=(0.9, 1.1)     # aspect ratio 0.9-1.1
    ),
    transforms.ToTensor()
])

print("üîÑ Resize Strategies:")
print("  1. Resize(224, 224)           ‚Üí ‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î (‡∏≠‡∏≤‡∏à‡πÄ‡∏™‡∏µ‡∏¢ aspect ratio)")
print("  2. Resize(256) + CenterCrop   ‚Üí ‡∏£‡∏±‡∏Å‡∏©‡∏≤ aspect ratio")
print("  3. RandomResizedCrop(224)     ‚Üí augmentation + resize")

# %% [markdown]
# ## 2.17 Weighted Sampling ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Imbalanced Data
#
# **‡∏õ‡∏±‡∏ç‡∏´‡∏≤:** ‡∏ö‡∏≤‡∏á‡∏Ñ‡∏£‡∏±‡πâ‡∏á class ‡∏°‡∏µ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÑ‡∏°‡πà‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ô
# - ‡πÄ‡∏ä‡πà‡∏ô cat=1000, dog=5000 ‡∏£‡∏π‡∏õ
# - Model ‡∏à‡∏∞ bias ‡πÑ‡∏õ‡∏ó‡∏≤‡∏á class ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏°‡∏≤‡∏Å
#
# **‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ:** ‡πÉ‡∏ä‡πâ WeightedRandomSampler
# - class ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ô‡πâ‡∏≠‡∏¢ ‚Üí weight ‡∏™‡∏π‡∏á ‚Üí ‡∏ñ‡∏π‡∏Å sample ‡∏ö‡πà‡∏≠‡∏¢‡∏Ç‡∏∂‡πâ‡∏ô

# %%
def create_weighted_sampler(dataset):
    """
    ‡∏™‡∏£‡πâ‡∏≤‡∏á WeightedRandomSampler ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö imbalanced dataset
    
    ‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏≤‡∏£: class ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ô‡πâ‡∏≠‡∏¢ ‚Üí weight ‡∏™‡∏π‡∏á ‚Üí ‡∏ñ‡∏π‡∏Å sample ‡∏ö‡πà‡∏≠‡∏¢‡∏Ç‡∏∂‡πâ‡∏ô
    
    Args:
        dataset: Dataset ‡∏ó‡∏µ‡πà‡∏°‡∏µ attribute targets ‡∏´‡∏£‡∏∑‡∏≠ samples
    
    Returns:
        WeightedRandomSampler
    """
    # ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞ class
    if hasattr(dataset, 'targets'):
        # ImageFolder ‡∏°‡∏µ attribute targets
        targets = dataset.targets
    elif hasattr(dataset, 'samples'):
        # Custom dataset ‡∏ó‡∏µ‡πà‡∏°‡∏µ samples = [(path, label), ...]
        targets = [label for _, label in dataset.samples]
    else:
        raise ValueError("Dataset must have 'targets' or 'samples' attribute")
    
    class_counts = Counter(targets)
    print(f"üìä Class distribution: {dict(class_counts)}")
    
    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì weight (inverse of frequency)
    # class ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ô‡πâ‡∏≠‡∏¢ ‚Üí weight ‡∏™‡∏π‡∏á
    total = len(targets)
    class_weights = {cls: total / count for cls, count in class_counts.items()}
    print(f"üìä Class weights: {class_weights}")
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á weight ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞ sample
    sample_weights = [class_weights[label] for label in targets]
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á sampler
    sampler = WeightedRandomSampler(
        weights=sample_weights,
        num_samples=len(targets),
        replacement=True  # ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô True ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö oversampling
    )
    
    return sampler


# ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
print("\nüìù Creating WeightedRandomSampler...")
sampler = create_weighted_sampler(train_dataset_img)

# ‡πÉ‡∏ä‡πâ sampler ‡πÅ‡∏ó‡∏ô shuffle
train_loader_balanced = DataLoader(
    train_dataset_img,
    batch_size=32,
    sampler=sampler,    # ‚Üê ‡πÉ‡∏ä‡πâ sampler ‡πÅ‡∏ó‡∏ô shuffle=True
    num_workers=4,
    pin_memory=True
)

print(f"‚úÖ Balanced DataLoader created with {len(train_loader_balanced)} batches")

# %% [markdown]
# ## 2.18 ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö ImageFolder vs Custom Dataset
#
# | Feature | ImageFolder | Custom Dataset |
# |---------|-------------|----------------|
# | **‡∏Ñ‡∏ß‡∏≤‡∏°‡∏á‡πà‡∏≤‡∏¢** | ‚úÖ ‡∏á‡πà‡∏≤‡∏¢‡∏°‡∏≤‡∏Å | ‚ùå ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÄ‡∏≠‡∏á |
# | **Flexibility** | ‚ùå ‡∏à‡∏≥‡∏Å‡∏±‡∏î | ‚úÖ ‡∏ó‡∏≥‡∏≠‡∏∞‡πÑ‡∏£‡∏Å‡πá‡πÑ‡∏î‡πâ |
# | **‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô** | ‚úÖ ‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏≤‡∏°‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô | ‚úÖ ‡∏≠‡∏∞‡πÑ‡∏£‡∏Å‡πá‡πÑ‡∏î‡πâ |
# | **Metadata** | ‚ùå ‡πÅ‡∏Ñ‡πà path + label | ‚úÖ ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÑ‡∏î‡πâ‡∏ï‡∏≤‡∏°‡πÉ‡∏à |
# | **Filter/Validate** | ‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ | ‚úÖ ‡∏ó‡∏≥‡πÑ‡∏î‡πâ |
#
# **‡∏™‡∏£‡∏∏‡∏õ:**
# - ‡πÉ‡∏ä‡πâ **ImageFolder** ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏±‡∏î‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏°‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô (‡πÄ‡∏£‡πá‡∏ß‡πÅ‡∏•‡∏∞‡∏á‡πà‡∏≤‡∏¢)
# - ‡πÉ‡∏ä‡πâ **Custom Dataset** ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ control ‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô

# %% [markdown]
# ## 2.19 Best Practices ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Image Data
#
# **üéØ ‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡∏ó‡∏≥:**
#
# 1. **Normalize ‡∏î‡πâ‡∏ß‡∏¢ ImageNet stats** (‡∏ñ‡πâ‡∏≤‡πÉ‡∏ä‡πâ pretrained model)
#    ```python
#    mean=[0.485, 0.456, 0.406]
#    std=[0.229, 0.224, 0.225]
#    ```
#
# 2. **‡πÉ‡∏ä‡πâ augmentation ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ï‡∏≠‡∏ô train**
#    - Train: RandomHorizontalFlip, RandomRotation, ColorJitter
#    - Val/Test: ‡πÅ‡∏Ñ‡πà Resize + Normalize
#
# 3. **‡πÄ‡∏•‡∏∑‡∏≠‡∏Å image size ‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°**
#    - 224√ó224: ‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô (ResNet, VGG)
#    - 299√ó299: Inception
#    - 384√ó384, 512√ó512: ViT, high-resolution tasks
#
# 4. **‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö channel order**
#    - PIL Image: (H, W, C) RGB
#    - OpenCV: (H, W, C) BGR ‚Üê ‡∏£‡∏∞‡∏ß‡∏±‡∏á! ‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏õ‡∏•‡∏á‡∏Å‡πà‡∏≠‡∏ô
#    - PyTorch Tensor: (C, H, W)
#
# 5. **num_workers ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°**
#    - Windows: 0 (‡∏°‡∏µ bug ‡∏Å‡∏±‡∏ö multiprocessing)
#    - Linux/Mac: 2-8 (‡∏Ç‡∏∂‡πâ‡∏ô‡∏Å‡∏±‡∏ö CPU cores)

# %%
print("üéØ Image Data Best Practices Summary:")
print("-" * 50)
print("1. ‡πÉ‡∏ä‡πâ ImageNet normalization ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö pretrained models")
print("2. Train transform ‡∏°‡∏µ augmentation, Val/Test ‡πÑ‡∏°‡πà‡∏°‡∏µ")
print("3. ‡∏Ç‡∏ô‡∏≤‡∏î‡∏£‡∏π‡∏õ: 224x224 (standard), 299x299 (Inception)")
print("4. ‡∏£‡∏∞‡∏ß‡∏±‡∏á channel order: PIL=RGB, OpenCV=BGR")
print("5. num_workers: 0 (Windows), 2-8 (Linux/Mac)")
print("-" * 50)

# %% [markdown]
# ## ‚úèÔ∏è ‡πÅ‡∏ö‡∏ö‡∏ù‡∏∂‡∏Å‡∏´‡∏±‡∏î 2.1: ‡∏™‡∏£‡πâ‡∏≤‡∏á Custom Dataset
#
# **‡πÇ‡∏à‡∏ó‡∏¢‡πå:** ‡∏™‡∏£‡πâ‡∏≤‡∏á Dataset ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Spiral Classification
# - 2 classes ‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏π‡∏õ spiral (‡πÄ‡∏Å‡∏•‡∏µ‡∏¢‡∏ß) ‡∏û‡∏±‡∏ô‡∏Å‡∏±‡∏ô
# - ‡∏£‡∏±‡∏ö parameters: n_samples, noise

# %%
class SpiralDataset(Dataset):
    """
    Dataset ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Spiral Classification
    
    ‡∏™‡∏£‡πâ‡∏≤‡∏á 2 spirals ‡∏ó‡∏µ‡πà‡∏û‡∏±‡∏ô‡∏Å‡∏±‡∏ô - ‡∏¢‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ XOR!
    
    Hint:
    - ‡πÉ‡∏ä‡πâ parametric equation: x = r*cos(Œ∏), y = r*sin(Œ∏)
    - r ‡πÅ‡∏•‡∏∞ Œ∏ ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏∂‡πâ‡∏ô‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô
    - Class 1 ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ó‡∏µ‡πà Œ∏ + œÄ (‡∏´‡∏°‡∏∏‡∏ô 180 ‡∏≠‡∏á‡∏®‡∏≤)
    """
    
    def __init__(self, n_samples=500, noise=0.2):
        # ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà (YOUR CODE HERE)
        pass
    
    def __len__(self):
        pass
    
    def __getitem__(self, idx):
        pass

# ‡∏ó‡∏î‡∏™‡∏≠‡∏ö:
# spiral_dataset = SpiralDataset(n_samples=500)
# print(f"Spiral dataset size: {len(spiral_dataset)}")

# %% [markdown]
# ---
# # üîÑ Module 3: Transforms ‡πÅ‡∏•‡∏∞ Data Augmentation
# ---
#
# ## ‡∏ó‡∏≥‡πÑ‡∏°‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ Transforms?
#
# **1. Preprocessing - ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ:**
# - Normalize ‚Üí ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏Ñ‡πà‡∏≤‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏° (‡πÄ‡∏ä‡πà‡∏ô mean=0, std=1)
# - Resize ‚Üí ‡∏õ‡∏£‡∏±‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î‡∏£‡∏π‡∏õ‡πÉ‡∏´‡πâ‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ô
#
# **2. Data Augmentation - "‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà" ‡∏à‡∏≤‡∏Å‡∏Ç‡∏≠‡∏á‡πÄ‡∏î‡∏¥‡∏°:**
# - ‡∏´‡∏°‡∏∏‡∏ô, ‡∏û‡∏•‡∏¥‡∏Å, crop ‚Üí ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°
# - **‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå:** ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô overfitting, model robust ‡∏Ç‡∏∂‡πâ‡∏ô
#
# **‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö:** ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏Ñ‡∏≥‡∏®‡∏±‡∏û‡∏ó‡πå
# - ‡∏î‡∏π‡∏Ñ‡∏≥‡πÄ‡∏î‡∏¥‡∏°‡∏ã‡πâ‡∏≥‡πÜ ‚Üí ‡∏à‡∏≥‡πÑ‡∏î‡πâ‡πÅ‡∏Ñ‡πà‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
# - ‡∏î‡∏π‡∏Ñ‡∏≥‡πÉ‡∏ô‡∏´‡∏•‡∏≤‡∏¢‡πÜ font/‡∏™‡∏µ ‚Üí ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢‡∏à‡∏£‡∏¥‡∏á‡πÜ

# %% [markdown]
# ## 3.1 Basic Transforms
#
# **Transforms ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏π‡πâ:**
# - `ToTensor()` ‚Üí ‡πÅ‡∏õ‡∏•‡∏á PIL Image ‡πÄ‡∏õ‡πá‡∏ô tensor ‡πÅ‡∏•‡∏∞ scale ‡πÄ‡∏õ‡πá‡∏ô [0, 1]
# - `Normalize(mean, std)` ‚Üí ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‚âà0, std‚âà1
# - `Resize(size)` ‚Üí ‡∏õ‡∏£‡∏±‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î‡∏£‡∏π‡∏õ
# - `CenterCrop(size)` ‚Üí crop ‡∏ï‡∏£‡∏á‡∏Å‡∏•‡∏≤‡∏á

# %%
# ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á basic transform
basic_transform = transforms.Compose([
    transforms.ToTensor(),  # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô tensor [0, 1]
    transforms.Normalize(
        mean=[0.1307],      # MNIST mean (‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏à‡∏≤‡∏Å training set)
        std=[0.3081]        # MNIST std
    )
])

# ‡πÇ‡∏´‡∏•‡∏î MNIST ‡∏î‡πâ‡∏ß‡∏¢ transform
mnist_normalized = torchvision.datasets.MNIST(
    root='./data',
    train=True,
    transform=basic_transform
)

# ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡πà‡∏≠‡∏ô-‡∏´‡∏•‡∏±‡∏á normalize
image_raw, _ = mnist_train[0]
image_norm, _ = mnist_normalized[0]

print(f"Before Normalize - Mean: {image_raw.mean():.4f}, Std: {image_raw.std():.4f}")
print(f"After Normalize - Mean: {image_norm.mean():.4f}, Std: {image_norm.std():.4f}")

# %% [markdown]
# ## 3.2 Data Augmentation Transforms
#
# **Augmentation ‡∏¢‡∏≠‡∏î‡∏ô‡∏¥‡∏¢‡∏°:**
# - `RandomHorizontalFlip()` ‚Üí ‡∏û‡∏•‡∏¥‡∏Å‡∏ã‡πâ‡∏≤‡∏¢-‡∏Ç‡∏ß‡∏≤ (‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ö‡∏£‡∏π‡∏õ‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ)
# - `RandomRotation(degrees)` ‚Üí ‡∏´‡∏°‡∏∏‡∏ô‡∏™‡∏∏‡πà‡∏° (‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ö‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç, ‡∏£‡∏π‡∏õ‡∏ß‡∏≤‡∏î)
# - `RandomCrop(size)` ‚Üí crop ‡∏™‡∏∏‡πà‡∏°‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á
# - `ColorJitter()` ‚Üí ‡∏õ‡∏£‡∏±‡∏ö‡∏™‡∏µ/‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏ß‡πà‡∏≤‡∏á (‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ö‡∏£‡∏π‡∏õ‡∏™‡∏µ)
# - `RandomErasing()` ‚Üí ‡∏•‡∏ö‡∏™‡πà‡∏ß‡∏ô‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏Ç‡∏≠‡∏á‡∏£‡∏π‡∏õ (‡∏ä‡πà‡∏ß‡∏¢ regularization)
#
# **‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç:** ‡πÉ‡∏ä‡πâ augmentation ‡∏ó‡∏µ‡πà make sense!
# - ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç ‚Üí ‡∏´‡∏°‡∏∏‡∏ô‡πÑ‡∏î‡πâ, ‡∏û‡∏•‡∏¥‡∏Å‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ (6 ‡∏Å‡∏±‡∏ö 9 ‡∏à‡∏∞‡∏™‡∏±‡∏ö‡∏™‡∏ô)
# - ‡∏£‡∏π‡∏õ‡πÅ‡∏°‡∏ß ‚Üí ‡∏û‡∏•‡∏¥‡∏Å‡πÑ‡∏î‡πâ, ‡∏´‡∏°‡∏∏‡∏ô‡πÑ‡∏°‡πà‡∏Ñ‡∏ß‡∏£‡∏°‡∏≤‡∏Å

# %%
# ‡∏™‡∏£‡πâ‡∏≤‡∏á augmentation transform ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö MNIST
augmentation_transform = transforms.Compose([
    transforms.RandomRotation(15),           # ‡∏´‡∏°‡∏∏‡∏ô ¬±15 ‡∏≠‡∏á‡∏®‡∏≤
    transforms.RandomAffine(
        degrees=0,
        translate=(0.1, 0.1),                # ‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô ¬±10%
        scale=(0.9, 1.1)                     # ‡∏¢‡πà‡∏≠/‡∏Ç‡∏¢‡∏≤‡∏¢ 90-110%
    ),
    transforms.ToTensor(),
    transforms.Normalize([0.1307], [0.3081])
])

# ‡πÇ‡∏´‡∏•‡∏î MNIST ‡∏î‡πâ‡∏ß‡∏¢ augmentation
mnist_augmented = torchvision.datasets.MNIST(
    root='./data',
    train=True,
    transform=augmentation_transform
)

# %% [markdown]
# ## 3.3 Visualize Augmentation

# %%
# ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏• augmentation ‡∏ö‡∏ô‡∏£‡∏π‡∏õ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô
fig, axes = plt.subplots(2, 5, figsize=(12, 5))

# ‡πÅ‡∏ñ‡∏ß‡∏ö‡∏ô: ‡∏£‡∏π‡∏õ‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö (‡∏ã‡πâ‡∏≥‡∏Å‡∏±‡∏ô)
original_image, label = mnist_train[0]
for ax in axes[0]:
    ax.imshow(original_image.squeeze(), cmap='gray')
    ax.set_title('Original')
    ax.axis('off')

# ‡πÅ‡∏ñ‡∏ß‡∏•‡πà‡∏≤‡∏á: ‡∏£‡∏π‡∏õ‡∏ó‡∏µ‡πà augment ‡πÅ‡∏•‡πâ‡∏ß (‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏à‡∏∞‡πÑ‡∏î‡πâ‡∏£‡∏π‡∏õ‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô‡πÄ‡∏û‡∏£‡∏≤‡∏∞ random)
for ax in axes[1]:
    aug_image, _ = mnist_augmented[0]
    ax.imshow(aug_image.squeeze(), cmap='gray')
    ax.set_title('Augmented')
    ax.axis('off')

plt.suptitle(f'Data Augmentation Examples (Label: {label})', fontsize=14)
plt.tight_layout()

plt.show()

# %% [markdown]
# ## 3.4 Transforms ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö CIFAR-10 (Color Images)
#
# **‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏π‡∏õ‡∏™‡∏µ (RGB) ‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏∞‡∏ß‡∏±‡∏á:**
# - mean/std ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ 3 ‡∏Ñ‡πà‡∏≤ (‡πÅ‡∏¢‡∏Å‡πÅ‡∏ï‡πà‡∏•‡∏∞ channel)
# - ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ ColorJitter ‡∏õ‡∏£‡∏±‡∏ö‡∏™‡∏µ/‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏ß‡πà‡∏≤‡∏á‡πÑ‡∏î‡πâ

# %%
# Transform ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö training (‡∏°‡∏µ augmentation)
cifar_train_transform = transforms.Compose([
    transforms.RandomHorizontalFlip(p=0.5),  # ‡∏û‡∏•‡∏¥‡∏Å 50% ‡∏Ç‡∏≠‡∏á‡πÄ‡∏ß‡∏•‡∏≤
    transforms.RandomCrop(32, padding=4),     # crop ‡πÅ‡∏ö‡∏ö‡∏™‡∏∏‡πà‡∏° (‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏≠‡∏ö 4 pixel ‡∏Å‡πà‡∏≠‡∏ô)
    transforms.ColorJitter(
        brightness=0.2,   # ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏ß‡πà‡∏≤‡∏á ¬±20%
        contrast=0.2,     # contrast ¬±20%
        saturation=0.2    # ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏≠‡∏¥‡πà‡∏°‡∏ï‡∏±‡∏ß ¬±20%
    ),
    transforms.ToTensor(),
    transforms.Normalize(
        mean=[0.4914, 0.4822, 0.4465],  # CIFAR-10 RGB mean
        std=[0.2470, 0.2435, 0.2616]    # CIFAR-10 RGB std
    )
])

# Transform ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö test (‡πÑ‡∏°‡πà‡∏°‡∏µ augmentation - ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ú‡∏•‡∏ó‡∏µ‡πà‡∏Ñ‡∏á‡∏ó‡∏µ‡πà)
cifar_test_transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(
        mean=[0.4914, 0.4822, 0.4465],
        std=[0.2470, 0.2435, 0.2616]
    )
])

print("CIFAR-10 transforms ready!")

# %%
# ‡πÇ‡∏´‡∏•‡∏î CIFAR-10
cifar_train = torchvision.datasets.CIFAR10(
    root='./data',
    train=True,
    download=True,
    transform=cifar_train_transform
)

cifar_test = torchvision.datasets.CIFAR10(
    root='./data',
    train=False,
    download=True,
    transform=cifar_test_transform
)

# Class names
cifar_classes = ['airplane', 'automobile', 'bird', 'cat', 'deer',
                 'dog', 'frog', 'horse', 'ship', 'truck']

print(f"CIFAR-10 Training: {len(cifar_train)} images")
print(f"CIFAR-10 Test: {len(cifar_test)} images")
print(f"Classes: {cifar_classes}")

# %% [markdown]
# ## 3.5 ‡πÅ‡∏™‡∏î‡∏á CIFAR-10 Samples

# %%
# ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á CIFAR-10 (‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ augmentation ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÄ‡∏´‡πá‡∏ô‡∏£‡∏π‡∏õ‡∏ä‡∏±‡∏î)
cifar_raw = torchvision.datasets.CIFAR10(
    root='./data', train=True, download=True,
    transform=transforms.ToTensor()
)

fig, axes = plt.subplots(2, 5, figsize=(12, 5))
for i, ax in enumerate(axes.flat):
    image, label = cifar_raw[i]
    # Transpose ‡∏à‡∏≤‡∏Å (C, H, W) ‡πÄ‡∏õ‡πá‡∏ô (H, W, C) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö matplotlib
    ax.imshow(image.permute(1, 2, 0))
    ax.set_title(cifar_classes[label])
    ax.axis('off')
plt.suptitle('CIFAR-10 Dataset Samples', fontsize=14)
plt.tight_layout()

plt.show()

# %% [markdown]
# ---
# # üñºÔ∏è Module 4: Convolutional Neural Networks (CNNs)
# ---
#
# ## CNN ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£?
#
# **‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏Ç‡∏≠‡∏á Fully Connected Network ‡∏Å‡∏±‡∏ö‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û:**
# - ‡∏£‡∏π‡∏õ 28√ó28 = 784 pixels ‚Üí 784 inputs
# - ‡∏£‡∏π‡∏õ 224√ó224√ó3 (RGB) = 150,528 inputs ‚Üí parameters ‡πÄ‡∏¢‡∏≠‡∏∞‡∏°‡∏≤‡∏Å!
# - ‡πÑ‡∏°‡πà‡∏™‡∏ô‡πÉ‡∏à spatial structure (pixel ‡∏Ç‡πâ‡∏≤‡∏á‡πÜ ‡∏Å‡∏±‡∏ô‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå)
#
# **CNN ‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ô‡∏µ‡πâ‡∏î‡πâ‡∏ß‡∏¢:**
# 1. **Convolutional Layer** ‚Üí ‡πÉ‡∏ä‡πâ filter ‡πÄ‡∏•‡πá‡∏Å‡πÜ (3√ó3) ‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏õ‡∏ó‡∏±‡πà‡∏ß‡∏£‡∏π‡∏õ
# 2. **Pooling Layer** ‚Üí ‡∏•‡∏î‡∏Ç‡∏ô‡∏≤‡∏î, ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏ó‡∏ô‡∏ï‡πà‡∏≠‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢
# 3. **Fully Connected** ‚Üí classification ‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢
#
# **‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö:** ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠
# - FC Network = ‡∏î‡∏π‡∏ó‡∏∏‡∏Å‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô (‡∏á‡∏á!)
# - CNN = ‡∏≠‡πà‡∏≤‡∏ô‡∏ó‡∏µ‡∏•‡∏∞‡∏Ñ‡∏≥, ‡∏ó‡∏µ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ (‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à!)

# %% [markdown]
# ## 4.1 Convolutional Layer
#
# **‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏≤‡∏£:**
# - ‡πÉ‡∏ä‡πâ filter/kernel ‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏•‡πá‡∏Å (‡πÄ‡∏ä‡πà‡∏ô 3√ó3) ‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏õ‡∏ó‡∏±‡πà‡∏ß‡∏£‡∏π‡∏õ
# - ‡πÅ‡∏ï‡πà‡∏•‡∏∞ filter ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ pattern ‡πÄ‡∏â‡∏û‡∏≤‡∏∞ (‡πÄ‡∏ä‡πà‡∏ô ‡∏Ç‡∏≠‡∏ö‡πÅ‡∏ô‡∏ß‡∏ï‡∏±‡πâ‡∏á, ‡πÅ‡∏ô‡∏ß‡∏ô‡∏≠‡∏ô, ‡∏°‡∏∏‡∏°)
#
# **Parameters ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç:**
# - `in_channels` ‚Üí ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô channels ‡∏Ç‡∏≠‡∏á input (RGB=3, grayscale=1)
# - `out_channels` ‚Üí ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô filters = ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô feature maps ‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ
# - `kernel_size` ‚Üí ‡∏Ç‡∏ô‡∏≤‡∏î‡∏Ç‡∏≠‡∏á filter (‡πÄ‡∏ä‡πà‡∏ô 3 = 3√ó3)
# - `stride` ‚Üí ‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô filter ‡∏ó‡∏µ‡∏•‡∏∞‡∏Å‡∏µ‡πà pixel (‡∏õ‡∏Å‡∏ï‡∏¥=1)
# - `padding` ‚Üí ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏≠‡∏ö‡∏Å‡∏µ‡πà pixel (‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏Ç‡∏ô‡∏≤‡∏î)

# %%
# ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á Conv2d
conv_layer = nn.Conv2d(
    in_channels=3,      # RGB input
    out_channels=16,    # ‡∏™‡∏£‡πâ‡∏≤‡∏á 16 feature maps
    kernel_size=3,      # filter 3x3
    stride=1,           # ‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏ó‡∏µ‡∏•‡∏∞ 1 pixel
    padding=1           # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏≠‡∏ö 1 pixel (‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏Ç‡∏ô‡∏≤‡∏î)
)

# ‡∏ó‡∏î‡∏™‡∏≠‡∏ö
x = torch.randn(1, 3, 32, 32)  # 1 ‡∏£‡∏π‡∏õ, RGB, 32x32
y = conv_layer(x)

print(f"Input shape: {x.shape}")   # (1, 3, 32, 32)
print(f"Output shape: {y.shape}")  # (1, 16, 32, 32)

# %% [markdown]
# ## 4.2 ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Output Size ‡∏Ç‡∏≠‡∏á Convolution
#
# **‡∏™‡∏π‡∏ï‡∏£:**
# ```
# output_size = (input_size - kernel_size + 2*padding) / stride + 1
# ```
#
# **‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á:**
# - Input: 32, kernel: 3, padding: 1, stride: 1
# - Output: (32 - 3 + 2√ó1) / 1 + 1 = 32 ‚úì (‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏ó‡πà‡∏≤‡πÄ‡∏î‡∏¥‡∏°)
#
# **‡πÄ‡∏Ñ‡∏•‡πá‡∏î‡∏•‡∏±‡∏ö:** padding = kernel_size // 2 ‡∏à‡∏∞‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏Ç‡∏ô‡∏≤‡∏î‡πÑ‡∏î‡πâ (‡πÄ‡∏°‡∏∑‡πà‡∏≠ stride=1)

# %%
def calc_conv_output_size(input_size, kernel_size, padding, stride):
    """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ç‡∏ô‡∏≤‡∏î output ‡∏Ç‡∏≠‡∏á convolution"""
    return (input_size - kernel_size + 2 * padding) // stride + 1

# ‡∏ó‡∏î‡∏™‡∏≠‡∏ö
print("Output sizes:")
print(f"  32x32, k=3, p=1, s=1 -> {calc_conv_output_size(32, 3, 1, 1)} (same)")
print(f"  32x32, k=3, p=0, s=1 -> {calc_conv_output_size(32, 3, 0, 1)} (shrink)")
print(f"  32x32, k=3, p=1, s=2 -> {calc_conv_output_size(32, 3, 1, 2)} (halved)")

# %% [markdown]
# ## 4.3 Pooling Layers
#
# **‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏Ç‡∏≠‡∏á Pooling:**
# - ‡∏•‡∏î‡∏Ç‡∏ô‡∏≤‡∏î‡∏Ç‡∏≠‡∏á feature maps (‡πÄ‡∏ä‡πà‡∏ô 32√ó32 ‚Üí 16√ó16)
# - ‡∏•‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô parameters ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì
# - ‡πÄ‡∏û‡∏¥‡πà‡∏° translation invariance (‡∏£‡∏π‡∏õ‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏õ‡∏ô‡∏¥‡∏î‡∏´‡∏ô‡πà‡∏≠‡∏¢ ‡∏ú‡∏•‡∏¢‡∏±‡∏á‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°)
#
# **‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó:**
# - **MaxPool** ‚Üí ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ñ‡πà‡∏≤‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞ region (‡πÉ‡∏ä‡πâ‡∏ö‡πà‡∏≠‡∏¢‡∏™‡∏∏‡∏î)
# - **AvgPool** ‚Üí ‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏Ñ‡πà‡∏≤‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞ region

# %%
# MaxPool2d
maxpool = nn.MaxPool2d(kernel_size=2, stride=2)  # ‡∏•‡∏î‡∏Ç‡∏ô‡∏≤‡∏î‡∏Ñ‡∏£‡∏∂‡πà‡∏á‡∏´‡∏ô‡∏∂‡πà‡∏á

x = torch.randn(1, 16, 32, 32)
y = maxpool(x)

print(f"Before MaxPool: {x.shape}")  # (1, 16, 32, 32)
print(f"After MaxPool: {y.shape}")   # (1, 16, 16, 16) - ‡∏•‡∏î‡∏Ñ‡∏£‡∏∂‡πà‡∏á‡∏´‡∏ô‡∏∂‡πà‡∏á!

# %% [markdown]
# ## 4.4 ‡∏™‡∏£‡πâ‡∏≤‡∏á CNN ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö MNIST
#
# **‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á CNN ‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ:**
# ```
# Input ‚Üí [Conv ‚Üí ReLU ‚Üí Pool] √ó N ‚Üí Flatten ‚Üí FC ‚Üí Output
# ```
#
# **‡∏Ñ‡∏¥‡∏î‡∏á‡πà‡∏≤‡∏¢‡πÜ:**
# - Conv blocks = "‡∏°‡∏≠‡∏á‡∏´‡∏≤ patterns"
# - Pooling = "‡∏¢‡πà‡∏≠‡∏£‡∏π‡∏õ‡∏•‡∏á"
# - FC = "‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à classification"

# %%
class MNISTNet(nn.Module):
    """
    CNN ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö MNIST Classification
    
    ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á:
    Input (1, 28, 28)
      ‚Üì
    Conv1 (32 filters) ‚Üí ReLU ‚Üí MaxPool ‚Üí (32, 14, 14)
      ‚Üì
    Conv2 (64 filters) ‚Üí ReLU ‚Üí MaxPool ‚Üí (64, 7, 7)
      ‚Üì
    Flatten ‚Üí FC1 (128) ‚Üí ReLU ‚Üí Dropout ‚Üí FC2 (10) ‚Üí Output
    """
    
    def __init__(self):
        super().__init__()
        
        # Convolutional layers
        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)   # 28‚Üí28
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)  # 14‚Üí14
        
        # Pooling
        self.pool = nn.MaxPool2d(2, 2)  # ‡∏•‡∏î‡∏Ç‡∏ô‡∏≤‡∏î‡∏Ñ‡∏£‡∏∂‡πà‡∏á‡∏´‡∏ô‡∏∂‡πà‡∏á
        
        # Fully connected layers
        # ‡∏´‡∏•‡∏±‡∏á 2 ‡∏Ñ‡∏£‡∏±‡πâ‡∏á pool: 28‚Üí14‚Üí7, channels: 64
        self.fc1 = nn.Linear(64 * 7 * 7, 128)
        self.fc2 = nn.Linear(128, 10)  # 10 classes (0-9)
        
        # Dropout ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö regularization (‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô overfitting)
        self.dropout = nn.Dropout(0.25)
    
    def forward(self, x):
        # Conv block 1: 28‚Üí14
        x = self.pool(F.relu(self.conv1(x)))
        
        # Conv block 2: 14‚Üí7
        x = self.pool(F.relu(self.conv2(x)))
        
        # Flatten: (batch, 64, 7, 7) ‚Üí (batch, 64*7*7)
        x = x.view(x.size(0), -1)
        
        # FC layers
        x = self.dropout(F.relu(self.fc1(x)))
        x = self.fc2(x)  # ‡πÑ‡∏°‡πà‡πÉ‡∏™‡πà activation (CrossEntropyLoss ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÉ‡∏´‡πâ)
        
        return x

# ‡∏™‡∏£‡πâ‡∏≤‡∏á model
mnist_cnn = MNISTNet()
print(mnist_cnn)

# ‡∏ô‡∏±‡∏ö parameters
total_params = sum(p.numel() for p in mnist_cnn.parameters())
print(f"\nTotal parameters: {total_params:,}")

# %% [markdown]
# ## 4.5 ‡∏ó‡∏î‡∏™‡∏≠‡∏ö Forward Pass

# %%
# ‡∏ó‡∏î‡∏™‡∏≠‡∏ö forward pass
x_test = torch.randn(4, 1, 28, 28)  # batch=4, MNIST size
output = mnist_cnn(x_test)

print(f"Input shape: {x_test.shape}")
print(f"Output shape: {output.shape}")  # (4, 10) - 10 classes
print(f"Output (logits):\n{output[0]}")  # ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏ú‡πà‡∏≤‡∏ô softmax

# %% [markdown]
# ## 4.6 Train CNN ‡∏ö‡∏ô MNIST
#
# **‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£ train:**
# 1. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Dataset, DataLoader)
# 2. ‡∏™‡∏£‡πâ‡∏≤‡∏á Model, Loss, Optimizer
# 3. Training loop: Forward ‚Üí Loss ‚Üí Backward ‚Üí Update
# 4. Validation: ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö overfitting
# 5. Test: ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢

# %%
# ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
mnist_transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize([0.1307], [0.3081])
])

train_mnist = torchvision.datasets.MNIST(
    './data', train=True, download=True, transform=mnist_transform
)
test_mnist = torchvision.datasets.MNIST(
    './data', train=False, transform=mnist_transform
)

# ‡πÅ‡∏ö‡πà‡∏á train/val
train_size = int(0.9 * len(train_mnist))
val_size = len(train_mnist) - train_size
train_data, val_data = random_split(train_mnist, [train_size, val_size])

# DataLoaders
train_loader = DataLoader(train_data, batch_size=64, shuffle=True)
val_loader = DataLoader(val_data, batch_size=64, shuffle=False)
test_loader = DataLoader(test_mnist, batch_size=64, shuffle=False)

print(f"Train: {len(train_data)}, Val: {len(val_data)}, Test: {len(test_mnist)}")

# %% [markdown]
# ## 4.7 Training Function

# %%
def train_epoch(model, loader, criterion, optimizer, device):
    """
    Train 1 epoch
    
    Returns:
        average loss, accuracy
    """
    model.train()  # ‡πÄ‡∏õ‡∏¥‡∏î training mode (Dropout ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô)
    total_loss = 0
    correct = 0
    total = 0
    
    for X_batch, y_batch in loader:
        X_batch, y_batch = X_batch.to(device), y_batch.to(device)
        
        # Forward pass
        outputs = model(X_batch)
        loss = criterion(outputs, y_batch)
        
        # Backward pass
        optimizer.zero_grad()  # ‡∏•‡πâ‡∏≤‡∏á gradients ‡πÄ‡∏Å‡πà‡∏≤
        loss.backward()        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì gradients
        optimizer.step()       # update weights
        
        # Statistics
        total_loss += loss.item() * X_batch.size(0)
        _, predicted = outputs.max(1)  # argmax
        correct += predicted.eq(y_batch).sum().item()
        total += y_batch.size(0)
    
    return total_loss / total, correct / total

def evaluate(model, loader, criterion, device):
    """
    Evaluate model (‡πÑ‡∏°‡πà update weights)
    
    Returns:
        average loss, accuracy
    """
    model.eval()  # ‡∏õ‡∏¥‡∏î training mode (Dropout ‡πÑ‡∏°‡πà‡∏ó‡∏≥‡∏á‡∏≤‡∏ô)
    total_loss = 0
    correct = 0
    total = 0
    
    with torch.no_grad():  # ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏Å‡πá‡∏ö gradients (‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î memory)
        for X_batch, y_batch in loader:
            X_batch, y_batch = X_batch.to(device), y_batch.to(device)
            
            outputs = model(X_batch)
            loss = criterion(outputs, y_batch)
            
            total_loss += loss.item() * X_batch.size(0)
            _, predicted = outputs.max(1)
            correct += predicted.eq(y_batch).sum().item()
            total += y_batch.size(0)
    
    return total_loss / total, correct / total

# %% [markdown]
# ## 4.8 Training Loop with Progress

# %%
# ‡∏™‡∏£‡πâ‡∏≤‡∏á model, criterion, optimizer
model = MNISTNet().to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# Training
n_epochs = 5
history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}

print("Starting training...")
print("-" * 60)

for epoch in range(n_epochs):
    start_time = time.time()
    
    # Train
    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)
    
    # Validate
    val_loss, val_acc = evaluate(model, val_loader, criterion, device)
    
    # Save history
    history['train_loss'].append(train_loss)
    history['train_acc'].append(train_acc)
    history['val_loss'].append(val_loss)
    history['val_acc'].append(val_acc)
    
    elapsed = time.time() - start_time
    print(f"Epoch {epoch+1}/{n_epochs} ({elapsed:.1f}s) | "
          f"Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f} | "
          f"Val Loss: {val_loss:.4f}, Acc: {val_acc:.4f}")

print("-" * 60)
print("Training complete!")

# Test
test_loss, test_acc = evaluate(model, test_loader, criterion, device)
print(f"Test Accuracy: {test_acc:.4f}")

# %% [markdown]
# ## 4.9 Visualize Training History

# %%
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# Loss
axes[0].plot(history['train_loss'], label='Train')
axes[0].plot(history['val_loss'], label='Validation')
axes[0].set_xlabel('Epoch')
axes[0].set_ylabel('Loss')
axes[0].set_title('Training & Validation Loss')
axes[0].legend()
axes[0].grid(True)

# Accuracy
axes[1].plot(history['train_acc'], label='Train')
axes[1].plot(history['val_acc'], label='Validation')
axes[1].set_xlabel('Epoch')
axes[1].set_ylabel('Accuracy')
axes[1].set_title('Training & Validation Accuracy')
axes[1].legend()
axes[1].grid(True)

plt.tight_layout()

plt.show()

# %% [markdown]
# ## 4.10 CNN ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö CIFAR-10 (‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡∏Ç‡∏∂‡πâ‡∏ô)
#
# **CIFAR-10 ‡∏¢‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ MNIST ‡πÄ‡∏û‡∏£‡∏≤‡∏∞:**
# - ‡∏£‡∏π‡∏õ‡∏™‡∏µ (3 channels) vs grayscale (1 channel)
# - Object ‡∏°‡∏µ‡∏´‡∏•‡∏≤‡∏¢‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö vs ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏Ñ‡πà‡∏≠‡∏ô‡∏Ç‡πâ‡∏≤‡∏á‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô
# - Background ‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô vs ‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ö
#
# **‡∏î‡∏±‡∏á‡∏ô‡∏±‡πâ‡∏ô‡∏ï‡πâ‡∏≠‡∏á:**
# - ‡πÉ‡∏ä‡πâ layers ‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô
# - ‡πÉ‡∏ä‡πâ Batch Normalization (‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ train ‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£)
# - ‡πÉ‡∏ä‡πâ Dropout ‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô

# %%
class CIFAR10Net(nn.Module):
    """
    CNN ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö CIFAR-10
    
    ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á: VGG-style blocks
    Block = [Conv ‚Üí BN ‚Üí ReLU ‚Üí Conv ‚Üí BN ‚Üí ReLU ‚Üí MaxPool ‚Üí Dropout]
    """
    
    def __init__(self, num_classes=10):
        super().__init__()
        
        # Block 1: 32x32 ‚Üí 16x16
        self.block1 = nn.Sequential(
            nn.Conv2d(3, 32, 3, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(inplace=True),
            nn.Conv2d(32, 32, 3, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2, 2),
            nn.Dropout(0.25)
        )
        
        # Block 2: 16x16 ‚Üí 8x8
        self.block2 = nn.Sequential(
            nn.Conv2d(32, 64, 3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 64, 3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2, 2),
            nn.Dropout(0.25)
        )
        
        # Block 3: 8x8 ‚Üí 4x4
        self.block3 = nn.Sequential(
            nn.Conv2d(64, 128, 3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.Conv2d(128, 128, 3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2, 2),
            nn.Dropout(0.25)
        )
        
        # Classifier
        self.classifier = nn.Sequential(
            nn.Flatten(),
            nn.Linear(128 * 4 * 4, 512),
            nn.ReLU(inplace=True),
            nn.Dropout(0.5),
            nn.Linear(512, num_classes)
        )
    
    def forward(self, x):
        x = self.block1(x)
        x = self.block2(x)
        x = self.block3(x)
        x = self.classifier(x)
        return x

# ‡∏™‡∏£‡πâ‡∏≤‡∏á model
cifar_model = CIFAR10Net()
print(cifar_model)

# ‡∏ô‡∏±‡∏ö parameters
total_params = sum(p.numel() for p in cifar_model.parameters())
print(f"\nTotal parameters: {total_params:,}")

# %% [markdown]
# ---
# # ‚ö° Module 6: Training Best Practices
# ---
#
# **‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏Å‡∏≤‡∏£ train ‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô:**
# 1. Learning Rate Scheduling
# 2. Early Stopping
# 3. Gradient Clipping
# 4. Weight Initialization
# 5. Batch Normalization

# %% [markdown]
# ## 6.1 Learning Rate Scheduling
#
# **‡∏õ‡∏±‡∏ç‡∏´‡∏≤:** Learning rate ‡∏Ñ‡∏á‡∏ó‡∏µ‡πà‡∏≠‡∏≤‡∏à‡πÑ‡∏°‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
# - ‡∏ï‡∏≠‡∏ô‡πÅ‡∏£‡∏Å: ‡∏≠‡∏¢‡∏≤‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡πÄ‡∏£‡πá‡∏ß‡πÜ ‚Üí lr ‡∏™‡∏π‡∏á
# - ‡∏ï‡∏≠‡∏ô‡∏ó‡πâ‡∏≤‡∏¢: ‡∏≠‡∏¢‡∏≤‡∏Å fine-tune ‚Üí lr ‡∏ï‡πà‡∏≥
#
# **Schedulers ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏ö‡πà‡∏≠‡∏¢:**
# - `StepLR` ‚Üí ‡∏•‡∏î lr ‡∏ó‡∏∏‡∏Å‡πÜ N epochs (‡πÄ‡∏ä‡πà‡∏ô ‡∏ó‡∏∏‡∏Å 10 epochs ‡∏•‡∏î 10 ‡πÄ‡∏ó‡πà‡∏≤)
# - `ReduceLROnPlateau` ‚Üí ‡∏•‡∏î lr ‡πÄ‡∏°‡∏∑‡πà‡∏≠ metric ‡πÑ‡∏°‡πà‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô
# - `CosineAnnealingLR` ‚Üí ‡∏•‡∏î‡πÅ‡∏ö‡∏ö cosine curve (‡∏Ñ‡πà‡∏≠‡∏¢‡πÜ ‡∏•‡∏î, ‡πÅ‡∏•‡πâ‡∏ß reset)

# %%
# ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á StepLR
model = nn.Linear(10, 1)
optimizer = optim.Adam(model.parameters(), lr=0.1)
scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)

lrs = []
for epoch in range(50):
    lrs.append(optimizer.param_groups[0]['lr'])
    scheduler.step()

plt.figure(figsize=(10, 4))
plt.plot(lrs)
plt.xlabel('Epoch')
plt.ylabel('Learning Rate')
plt.title('StepLR Schedule (step_size=10, gamma=0.1)')
plt.grid(True)

plt.show()

# %% [markdown]
# ## 6.2 ReduceLROnPlateau
#
# **‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏≤‡∏£:** ‡∏•‡∏î learning rate ‡πÄ‡∏°‡∏∑‡πà‡∏≠ metric ‡∏´‡∏¢‡∏∏‡∏î‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô
# - `mode='min'` ‚Üí ‡∏•‡∏î‡πÄ‡∏°‡∏∑‡πà‡∏≠ loss ‡πÑ‡∏°‡πà‡∏•‡∏î‡∏•‡∏á
# - `patience=5` ‚Üí ‡∏£‡∏≠ 5 epochs ‡∏Å‡πà‡∏≠‡∏ô‡∏•‡∏î
# - `factor=0.5` ‚Üí ‡∏•‡∏î‡∏•‡∏á‡∏Ñ‡∏£‡∏∂‡πà‡∏á‡∏´‡∏ô‡∏∂‡πà‡∏á
#
# **‡∏Ç‡πâ‡∏≠‡∏î‡∏µ:** ‡∏õ‡∏£‡∏±‡∏ö‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡∏ï‡∏≤‡∏°‡∏™‡∏ñ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ì‡πå

# %%
# ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á ReduceLROnPlateau
model = nn.Linear(10, 1)
optimizer = optim.Adam(model.parameters(), lr=0.1)
scheduler = optim.lr_scheduler.ReduceLROnPlateau(
    optimizer, 
    mode='min',      # ‡∏•‡∏î‡πÄ‡∏°‡∏∑‡πà‡∏≠ loss ‡πÑ‡∏°‡πà‡∏•‡∏î
    patience=5,      # ‡∏£‡∏≠ 5 epochs
    factor=0.5       # ‡∏•‡∏î‡∏•‡∏á‡∏Ñ‡∏£‡∏∂‡πà‡∏á‡∏´‡∏ô‡∏∂‡πà‡∏á
)

# ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô:
# scheduler.step(val_loss)  # ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏´‡∏•‡∏±‡∏á‡∏ó‡∏∏‡∏Å epoch

print("ReduceLROnPlateau: reduce lr when validation loss doesn't decrease for 5 epochs")

# %% [markdown]
# ## 6.3 Early Stopping
#
# **‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏≤‡∏£:** ‡∏´‡∏¢‡∏∏‡∏î train ‡πÄ‡∏°‡∏∑‡πà‡∏≠ validation loss ‡πÑ‡∏°‡πà‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô‡πÅ‡∏•‡πâ‡∏ß
#
# **‡∏ó‡∏≥‡πÑ‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏´‡∏¢‡∏∏‡∏î?**
# - ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô overfitting
# - ‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î‡πÄ‡∏ß‡∏•‡∏≤
# - ‡πÄ‡∏Å‡πá‡∏ö model ‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡πÑ‡∏ß‡πâ

# %%
class EarlyStopping:
    """
    Early Stopping ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô overfitting
    
    ‡∏´‡∏¢‡∏∏‡∏î train ‡πÄ‡∏°‡∏∑‡πà‡∏≠ validation loss ‡πÑ‡∏°‡πà‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ß‡∏•‡∏≤ patience epochs
    """
    
    def __init__(self, patience=7, min_delta=0, restore_best_weights=True):
        """
        Args:
            patience: ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô epochs ‡∏ó‡∏µ‡πà‡∏£‡∏≠
            min_delta: ‡∏Ñ‡πà‡∏≤‡∏ï‡πà‡∏≥‡∏™‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô
            restore_best_weights: ‡∏Ñ‡∏∑‡∏ô weights ‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        """
        self.patience = patience
        self.min_delta = min_delta
        self.restore_best_weights = restore_best_weights
        self.best_loss = None
        self.counter = 0
        self.best_weights = None
        self.early_stop = False
    
    def __call__(self, val_loss, model):
        if self.best_loss is None:
            self.best_loss = val_loss
            self.best_weights = model.state_dict().copy()
        elif val_loss > self.best_loss - self.min_delta:
            self.counter += 1
            if self.counter >= self.patience:
                self.early_stop = True
                if self.restore_best_weights:
                    model.load_state_dict(self.best_weights)
        else:
            self.best_loss = val_loss
            self.best_weights = model.state_dict().copy()
            self.counter = 0
        
        return self.early_stop

# ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
print("Early Stopping Example:")
print("""
early_stopping = EarlyStopping(patience=7)

for epoch in range(max_epochs):
    train_loss = train_epoch(...)
    val_loss = evaluate(...)
    
    if early_stopping(val_loss, model):
        print(f"Early stopping at epoch {epoch}")
        break
""")

# %% [markdown]
# ## 6.4 Gradient Clipping
#
# **‡∏õ‡∏±‡∏ç‡∏´‡∏≤:** Exploding Gradients
# - Gradient ‡πÉ‡∏´‡∏ç‡πà‡∏°‡∏≤‡∏Å‡∏à‡∏ô weights ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á
# - ‡∏û‡∏ö‡∏ö‡πà‡∏≠‡∏¢‡πÉ‡∏ô RNN
#
# **‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ:** ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ç‡∏ô‡∏≤‡∏î‡∏Ç‡∏≠‡∏á gradient
# - ‡∏ñ‡πâ‡∏≤ ||gradient|| > max_norm ‚Üí scale ‡∏•‡∏á

# %%
# Gradient Clipping
model = nn.Linear(10, 1)
optimizer = optim.SGD(model.parameters(), lr=0.1)

# ‡∏™‡∏£‡πâ‡∏≤‡∏á gradient
x = torch.randn(4, 10, requires_grad=True)
y = torch.randn(4, 1)

output = model(x)
loss = ((output - y) ** 2).mean()
loss.backward()

# ‡∏Å‡πà‡∏≠‡∏ô clip
print(f"Gradient norm before clip: {model.weight.grad.norm():.4f}")

# Clip gradient (‡∏ó‡∏≥‡∏´‡∏•‡∏±‡∏á backward, ‡∏Å‡πà‡∏≠‡∏ô optimizer.step)
torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)

# ‡∏´‡∏•‡∏±‡∏á clip
print(f"Gradient norm after clip: {model.weight.grad.norm():.4f}")

# %% [markdown]
# ## 6.5 Weight Initialization
#
# **‡∏ó‡∏≥‡πÑ‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç:**
# - Weights ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏î‡∏µ ‚Üí train ‡πÄ‡∏£‡πá‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô, converge ‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô
# - Weights ‡πÅ‡∏¢‡πà ‚Üí vanishing/exploding gradients
#
# **‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏ö‡πà‡∏≠‡∏¢:**
# - **Xavier/Glorot** ‚Üí ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö tanh, sigmoid
# - **Kaiming/He** ‚Üí ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö ReLU (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥!)
# - **Orthogonal** ‚Üí ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö RNN

# %%
def init_weights(module):
    """
    Initialize weights ‡∏ï‡∏≤‡∏° best practices
    """
    if isinstance(module, nn.Linear):
        # Kaiming init ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö ReLU
        nn.init.kaiming_normal_(module.weight, nonlinearity='relu')
        if module.bias is not None:
            nn.init.zeros_(module.bias)
    
    elif isinstance(module, nn.Conv2d):
        # Kaiming init ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Conv
        nn.init.kaiming_normal_(module.weight, nonlinearity='relu')
        if module.bias is not None:
            nn.init.zeros_(module.bias)
    
    elif isinstance(module, nn.LSTM):
        # Orthogonal init ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö RNN
        for name, param in module.named_parameters():
            if 'weight_ih' in name:
                nn.init.xavier_uniform_(param.data)
            elif 'weight_hh' in name:
                nn.init.orthogonal_(param.data)
            elif 'bias' in name:
                nn.init.zeros_(param.data)

# ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
model = MNISTNet()
model.apply(init_weights)  # apply ‡πÑ‡∏õ‡∏ó‡∏∏‡∏Å module
print("Weights initialized!")

# %% [markdown]
# ## 6.6 Batch Normalization
#
# **‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏≤‡∏£:** Normalize activations ‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞ layer
# - ‡∏ó‡∏≥‡πÉ‡∏´‡πâ mean‚âà0, std‚âà1 ‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞ batch
#
# **‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå:**
# - Train ‡πÄ‡∏£‡πá‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô (‡πÉ‡∏ä‡πâ lr ‡∏™‡∏π‡∏á‡πÑ‡∏î‡πâ)
# - Regularization effect ‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢
# - Gradient flow ‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô
#
# **‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á:** ‡∏´‡∏•‡∏±‡∏á Linear/Conv, ‡∏Å‡πà‡∏≠‡∏ô activation

# %%
class NetWithBN(nn.Module):
    """Network with Batch Normalization"""
    
    def __init__(self):
        super().__init__()
        self.fc1 = nn.Linear(784, 256)
        self.bn1 = nn.BatchNorm1d(256)  # BN ‡∏´‡∏•‡∏±‡∏á linear
        self.fc2 = nn.Linear(256, 128)
        self.bn2 = nn.BatchNorm1d(128)
        self.fc3 = nn.Linear(128, 10)
    
    def forward(self, x):
        x = x.view(x.size(0), -1)
        x = F.relu(self.bn1(self.fc1(x)))  # Linear ‚Üí BN ‚Üí ReLU
        x = F.relu(self.bn2(self.fc2(x)))
        x = self.fc3(x)
        return x

model_bn = NetWithBN()
print(model_bn)

# %% [markdown]
# ## 6.7 Complete Training Loop with Best Practices

# %%
def train_with_best_practices(model, train_loader, val_loader, 
                               criterion, optimizer, scheduler,
                               n_epochs, device, patience=10):
    """
    Training loop ‡∏û‡∏£‡πâ‡∏≠‡∏° best practices ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î:
    - Learning rate scheduling
    - Early stopping
    - Gradient clipping
    """
    early_stopping = EarlyStopping(patience=patience)
    history = {'train_loss': [], 'val_loss': [], 'val_acc': [], 'lr': []}
    
    for epoch in range(n_epochs):
        # === Training ===
        model.train()
        train_loss = 0
        
        for X_batch, y_batch in train_loader:
            X_batch, y_batch = X_batch.to(device), y_batch.to(device)
            
            optimizer.zero_grad()
            output = model(X_batch)
            loss = criterion(output, y_batch)
            loss.backward()
            
            # Gradient clipping
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            
            optimizer.step()
            train_loss += loss.item()
        
        train_loss /= len(train_loader)
        
        # === Validation ===
        model.eval()
        val_loss = 0
        correct = 0
        total = 0
        
        with torch.no_grad():
            for X_batch, y_batch in val_loader:
                X_batch, y_batch = X_batch.to(device), y_batch.to(device)
                output = model(X_batch)
                val_loss += criterion(output, y_batch).item()
                
                _, predicted = output.max(1)
                correct += predicted.eq(y_batch).sum().item()
                total += y_batch.size(0)
        
        val_loss /= len(val_loader)
        val_acc = correct / total
        
        # Learning rate scheduling
        if isinstance(scheduler, optim.lr_scheduler.ReduceLROnPlateau):
            scheduler.step(val_loss)
        else:
            scheduler.step()
        
        current_lr = optimizer.param_groups[0]['lr']
        
        # Save history
        history['train_loss'].append(train_loss)
        history['val_loss'].append(val_loss)
        history['val_acc'].append(val_acc)
        history['lr'].append(current_lr)
        
        print(f"Epoch {epoch+1}/{n_epochs} | "
              f"Train Loss: {train_loss:.4f} | "
              f"Val Loss: {val_loss:.4f} | "
              f"Val Acc: {val_acc:.4f} | "
              f"LR: {current_lr:.6f}")
        
        # Early stopping
        if early_stopping(val_loss, model):
            print(f"Early stopping at epoch {epoch+1}")
            break
    
    return history

print("Training function with best practices ready!")

# %% [markdown]
# ---
# # üöÄ Module 7: GPU Optimization
# ---
#
# **‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ GPU ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û:**
# 1. Memory Management
# 2. Mixed Precision Training (FP16)
# 3. DataLoader Optimization

# %% [markdown]
# ## 7.1 Memory Management
#
# **GPU memory ‡∏°‡∏µ‡∏à‡∏≥‡∏Å‡∏±‡∏î ‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏∞‡∏ß‡∏±‡∏á:**
# - ‡∏•‡∏ö tensor ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ
# - ‡πÉ‡∏ä‡πâ `torch.no_grad()` ‡∏ï‡∏≠‡∏ô inference
# - Batch size ‡πÉ‡∏´‡∏ç‡πà‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ ‚Üí Out of Memory

# %%
if torch.cuda.is_available():
    print("GPU Memory Info:")
    print(f"   Total: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB")
    print(f"   Allocated: {torch.cuda.memory_allocated() / 1e9:.4f} GB")
    print(f"   Cached: {torch.cuda.memory_reserved() / 1e9:.4f} GB")
    
    # ‡∏•‡πâ‡∏≤‡∏á cache
    torch.cuda.empty_cache()
    print("   Cache cleared!")
else:
    print("GPU not available")

# %% [markdown]
# ## 7.2 Mixed Precision Training (FP16)
#
# **‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏≤‡∏£:** ‡πÉ‡∏ä‡πâ float16 ‡πÅ‡∏ó‡∏ô float32
# - ‡∏•‡∏î memory usage ~50%
# - ‡πÄ‡∏£‡πá‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô 2-3 ‡πÄ‡∏ó‡πà‡∏≤ (‡∏ö‡∏ô GPU ‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö)
# - ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á float32
#
# **‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡∏Å‡∏±‡∏ö:** NVIDIA GPU ‡∏ó‡∏µ‡πà‡∏°‡∏µ Tensor Cores (RTX, V100, A100)

# %%
# Mixed Precision Training with AMP (Automatic Mixed Precision)
from torch.cuda.amp import autocast, GradScaler

def train_with_amp(model, train_loader, criterion, optimizer, device):
    """Training with Automatic Mixed Precision"""
    scaler = GradScaler()  # ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ gradient scaling
    model.train()
    
    for X_batch, y_batch in train_loader:
        X_batch, y_batch = X_batch.to(device), y_batch.to(device)
        
        optimizer.zero_grad()
        
        # Forward pass with autocasting (auto ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å FP16 ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°)
        with autocast():
            output = model(X_batch)
            loss = criterion(output, y_batch)
        
        # Backward pass with scaling
        scaler.scale(loss).backward()
        scaler.step(optimizer)
        scaler.update()

print("""
Mixed Precision Training Pattern:

scaler = GradScaler()

for X, y in dataloader:
    optimizer.zero_grad()
    
    with autocast():
        output = model(X)
        loss = criterion(output, y)
    
    scaler.scale(loss).backward()
    scaler.step(optimizer)
    scaler.update()
""")

# %% [markdown]
# ## 7.3 DataLoader Optimization
#
# **‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ DataLoader ‡∏ó‡∏µ‡πà‡∏î‡∏µ:**
# - `num_workers` ‚Üí ‡πÉ‡∏ä‡πâ‡∏´‡∏•‡∏≤‡∏¢ CPU cores ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ 2-8)
# - `pin_memory=True` ‚Üí ‡πÄ‡∏£‡πá‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö GPU transfer
# - `persistent_workers=True` ‚Üí ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á workers ‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏∏‡∏Å epoch
# - `prefetch_factor` ‚Üí ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡πà‡∏ß‡∏á‡∏´‡∏ô‡πâ‡∏≤

# %%
# Optimized DataLoader
def create_optimized_dataloader(dataset, batch_size, is_train=True):
    """
    ‡∏™‡∏£‡πâ‡∏≤‡∏á DataLoader ‡∏ó‡∏µ‡πà optimize ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö GPU
    """
    return DataLoader(
        dataset,
        batch_size=batch_size,
        shuffle=is_train,
        num_workers=4,          # ‡πÉ‡∏ä‡πâ 4 processes
        pin_memory=True,        # ‡πÄ‡∏£‡πá‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö GPU
        persistent_workers=True, # ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á workers ‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏∏‡∏Å epoch
        prefetch_factor=2       # ‡πÇ‡∏´‡∏•‡∏î 2 batches ‡∏•‡πà‡∏ß‡∏á‡∏´‡∏ô‡πâ‡∏≤
    )

print("Optimized DataLoader settings:")
print("  - num_workers=4 (parallel data loading)")
print("  - pin_memory=True (faster GPU transfer)")
print("  - persistent_workers=True (reuse workers)")
print("  - prefetch_factor=2 (preload batches)")

# %% [markdown]
# ## 7.4 Model Optimization: torch.compile (PyTorch 2.0+)
#
# **‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏≤‡∏£:** PyTorch 2.0 ‡∏°‡∏µ JIT compiler ‡πÉ‡∏´‡∏°‡πà
# - ‡πÄ‡∏£‡πá‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô 20-50% ‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î
# - ‡πÅ‡∏Ñ‡πà wrap model ‡∏î‡πâ‡∏ß‡∏¢ `torch.compile()`

# %%
# torch.compile (PyTorch 2.0+)
if hasattr(torch, 'compile'):
    print("torch.compile available!")
    print("""
Usage:
    
# Before training
model = MyModel()
model = torch.compile(model)  # Just add this line!

# Then use normally
output = model(x)
    """)
else:
    print("torch.compile not available (need PyTorch 2.0+)")

# %% [markdown]
# ## 7.5 Profiling: ‡∏´‡∏≤‡∏à‡∏∏‡∏î‡∏Ñ‡∏≠‡∏Ç‡∏ß‡∏î
#
# **‡πÉ‡∏ä‡πâ profiler ‡∏´‡∏≤‡∏ß‡πà‡∏≤‡∏™‡πà‡∏ß‡∏ô‡πÑ‡∏´‡∏ô‡∏ä‡πâ‡∏≤:**
# - GPU utilization ‡∏ï‡πà‡∏≥ ‚Üí DataLoader ‡∏ä‡πâ‡∏≤
# - Memory ‡∏™‡∏π‡∏á‡∏°‡∏≤‡∏Å ‚Üí Batch size ‡πÉ‡∏´‡∏ç‡πà‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ

# %%
# Simple timing
def benchmark_model(model, input_shape, n_iterations=100, device='cpu'):
    """‡∏ß‡∏±‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡∏Ç‡∏≠‡∏á model"""
    model = model.to(device)
    model.eval()
    
    x = torch.randn(input_shape).to(device)
    
    # Warm up (‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÅ‡∏£‡∏Å‡∏à‡∏∞‡∏ä‡πâ‡∏≤)
    with torch.no_grad():
        for _ in range(10):
            _ = model(x)
    
    # Benchmark
    if device == 'cuda':
        torch.cuda.synchronize()  # ‡∏£‡∏≠‡πÉ‡∏´‡πâ GPU ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÄ‡∏™‡∏£‡πá‡∏à
    
    start = time.time()
    with torch.no_grad():
        for _ in range(n_iterations):
            _ = model(x)
    
    if device == 'cuda':
        torch.cuda.synchronize()
    
    elapsed = time.time() - start
    avg_time = elapsed / n_iterations * 1000  # ms
    
    return avg_time

# ‡∏ó‡∏î‡∏™‡∏≠‡∏ö
model = MNISTNet()
cpu_time = benchmark_model(model, (32, 1, 28, 28), device='cpu')
print(f"CPU inference time: {cpu_time:.2f} ms per batch")

if torch.cuda.is_available():
    gpu_time = benchmark_model(model, (32, 1, 28, 28), device='cuda')
    print(f"GPU inference time: {gpu_time:.2f} ms per batch")
    print(f"Speedup: {cpu_time/gpu_time:.1f}x")

# %% [markdown]
# ---
# # üß™ Lab: Complete Training Pipeline
# ---
#
# **‡∏£‡∏ß‡∏°‡∏ó‡∏∏‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏°‡∏≤!**

# %%
# === Complete Training Pipeline ===

# 1. Data Preparation
print("Preparing data...")
transform_train = transforms.Compose([
    transforms.RandomRotation(10),
    transforms.ToTensor(),
    transforms.Normalize([0.1307], [0.3081])
])

transform_test = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize([0.1307], [0.3081])
])

train_dataset = torchvision.datasets.MNIST('./data', train=True, 
                                            transform=transform_train, download=True)
test_dataset = torchvision.datasets.MNIST('./data', train=False, 
                                           transform=transform_test)

# Split train/val
train_size = int(0.9 * len(train_dataset))
val_size = len(train_dataset) - train_size
train_data, val_data = random_split(train_dataset, [train_size, val_size])

# DataLoaders
batch_size = 64
train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True,
                         num_workers=0, pin_memory=torch.cuda.is_available())
val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False,
                        num_workers=0, pin_memory=torch.cuda.is_available())
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False,
                         num_workers=0, pin_memory=torch.cuda.is_available())

print(f"   Train: {len(train_data)}, Val: {len(val_data)}, Test: {len(test_dataset)}")

# %%
# 2. Model
print("\nCreating model...")
model = MNISTNet().to(device)
model.apply(init_weights)
print(f"   Device: {device}")
print(f"   Parameters: {sum(p.numel() for p in model.parameters()):,}")

# 3. Loss, Optimizer, Scheduler
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)
scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, factor=0.5)

# 4. Training
print("\nTraining...")
history = train_with_best_practices(
    model, train_loader, val_loader,
    criterion, optimizer, scheduler,
    n_epochs=10, device=device, patience=5
)

# %%
# 5. Final Evaluation
print("\nFinal Evaluation...")
model.eval()
test_loss = 0
correct = 0
total = 0

with torch.no_grad():
    for X_batch, y_batch in test_loader:
        X_batch, y_batch = X_batch.to(device), y_batch.to(device)
        output = model(X_batch)
        test_loss += criterion(output, y_batch).item()
        _, predicted = output.max(1)
        correct += predicted.eq(y_batch).sum().item()
        total += y_batch.size(0)

test_loss /= len(test_loader)
test_acc = correct / total
print(f"   Test Loss: {test_loss:.4f}")
print(f"   Test Accuracy: {test_acc:.4f}")

# %%
# 6. Save Model
model_path = './best_model.pt'
torch.save({
    'model_state_dict': model.state_dict(),
    'optimizer_state_dict': optimizer.state_dict(),
    'test_accuracy': test_acc,
    'history': history
}, model_path)
print(f"\nModel saved to {model_path}")

# %%
# 7. Visualize Results
fig, axes = plt.subplots(2, 2, figsize=(14, 10))

# Loss
axes[0, 0].plot(history['train_loss'], label='Train')
axes[0, 0].plot(history['val_loss'], label='Validation')
axes[0, 0].set_xlabel('Epoch')
axes[0, 0].set_ylabel('Loss')
axes[0, 0].set_title('Training & Validation Loss')
axes[0, 0].legend()
axes[0, 0].grid(True)

# Accuracy
axes[0, 1].plot(history['val_acc'])
axes[0, 1].set_xlabel('Epoch')
axes[0, 1].set_ylabel('Accuracy')
axes[0, 1].set_title(f'Validation Accuracy (Final Test: {test_acc:.4f})')
axes[0, 1].grid(True)

# Learning Rate
axes[1, 0].plot(history['lr'])
axes[1, 0].set_xlabel('Epoch')
axes[1, 0].set_ylabel('Learning Rate')
axes[1, 0].set_title('Learning Rate Schedule')
axes[1, 0].grid(True)

# Sample Predictions
model.eval()
images, labels = next(iter(test_loader))
images = images[:8].to(device)
labels = labels[:8].to(device)

with torch.no_grad():
    outputs = model(images)
    preds = outputs.argmax(dim=1)

# Put 8 small plots INSIDE axes[1, 1]
ax_panel = axes[1, 1]
ax_panel.axis('off')
ax_panel.set_title('Sample Predictions')

nrows, ncols = 2, 4
pad = 0.02
cell_w = (1 - pad * (ncols + 1)) / ncols
cell_h = (1 - pad * (nrows + 1)) / nrows

for i in range(8):
    r, c = divmod(i, ncols)
    x0 = pad + c * (cell_w + pad)
    y0 = 1 - pad - (r + 1) * cell_h - r * pad

    ax = ax_panel.inset_axes([x0, y0, cell_w, cell_h])
    img = images[i].detach().cpu()

    if img.ndim == 3 and img.shape[0] == 1:
        ax.imshow(img[0], cmap='gray')
    elif img.ndim == 3 and img.shape[0] == 3:
        ax.imshow(img.permute(1, 2, 0))
    else:
        ax.imshow(img.squeeze(), cmap='gray')

    ok = (preds[i] == labels[i]).item()
    color = 'green' if ok else 'red'
    ax.set_title(f'Pred: {preds[i].item()}\nTrue: {labels[i].item()}',
                 color=color, fontsize=9)
    ax.axis('off')

plt.tight_layout()
plt.show()

# %% [markdown]
# ---
# # üéâ ‡∏™‡∏£‡∏∏‡∏õ Day 2
# ---
#
# ## ‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ:
#
# | Module | ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠ | ‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô |
# |--------|--------|----------------|
# | **2** | Datasets & DataLoaders | Custom Dataset, DataLoader, train/val/test split |
# | **2.5** | Image Folder DataLoader | ImageFolder, Custom Image Dataset, Weighted Sampling |
# | **3** | Transforms | Preprocessing, Data Augmentation |
# | **4** | CNN | Conv2d, Pooling, MNIST/CIFAR-10 classification |
# | **6** | Best Practices | LR Scheduling, Early Stopping, Weight Init |
# | **7** | GPU Optimization | Memory, AMP, DataLoader optimization |
#
# ## üéØ Key Takeaways:
#
# 1. **Dataset/DataLoader** ‡πÅ‡∏¢‡∏Å‡∏Å‡∏±‡∏ô: Dataset ‡∏ö‡∏≠‡∏Å‡∏ß‡∏¥‡∏ò‡∏µ‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á, DataLoader ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ batching
# 2. **ImageFolder** ‡∏á‡πà‡∏≤‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö image classification
# 3. **Augmentation** ‡πÉ‡∏ä‡πâ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ï‡∏≠‡∏ô train, ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ‡∏ï‡∏≠‡∏ô val/test
# 4. **CNN** ‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤ FC ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û (parameter ‡∏ô‡πâ‡∏≠‡∏¢‡∏Å‡∏ß‡πà‡∏≤, ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ spatial patterns)
# 5. **Best Practices** ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç: LR scheduling, early stopping, gradient clipping
# 6. **GPU Optimization**: pin_memory, num_workers, AMP
#
# ## üìö ‡πÅ‡∏´‡∏•‡πà‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°:
# - [PyTorch Tutorials](https://pytorch.org/tutorials/)
# - [PyTorch Documentation](https://pytorch.org/docs/)
# - [Papers With Code](https://paperswithcode.com/)

# %%
print("üéâ Congratulations! You've completed Day 2!")
print("üìö Next: Transfer Learning, Advanced Architectures, Model Deployment")
