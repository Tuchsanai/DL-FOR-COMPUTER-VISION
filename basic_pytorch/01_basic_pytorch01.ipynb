{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # üî• PyTorch Fundamentals Lab (‡∏â‡∏ö‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢)\n",
    "\n",
    " **‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà 1: ‡∏à‡∏≤‡∏Å Tensor ‡∏™‡∏π‡πà Training Loop**\n",
    "\n",
    "\n",
    "\n",
    " ‡∏¢‡∏¥‡∏ô‡∏î‡∏µ‡∏ï‡πâ‡∏≠‡∏ô‡∏£‡∏±‡∏ö‡∏™‡∏π‡πà PyTorch! ‡∏ö‡∏ó‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡∏û‡∏≤‡∏Ñ‡∏∏‡∏ì‡∏à‡∏≤‡∏Å‡∏®‡∏π‡∏ô‡∏¢‡πå‡πÑ‡∏õ‡∏™‡∏π‡πà‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡∏ù‡∏∂‡∏Å Neural Network\n",
    "\n",
    "\n",
    "\n",
    " ## üìö ‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏à‡∏∞‡πÑ‡∏î‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ:\n",
    "\n",
    " - **Tensor** - ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏±‡∏Å‡∏Ç‡∏≠‡∏á PyTorch (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô numpy array ‡πÅ‡∏ï‡πà‡∏ó‡∏£‡∏á‡∏û‡∏•‡∏±‡∏á‡∏Å‡∏ß‡πà‡∏≤)\n",
    "\n",
    " - **Autograd** - ‡∏£‡∏∞‡∏ö‡∏ö‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì gradient ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥ (‡∏´‡∏±‡∏ß‡πÉ‡∏à‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ)\n",
    "\n",
    " - **Neural Networks** - ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•\n",
    "\n",
    "\n",
    "\n",
    " ## üìù ‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô:\n",
    "\n",
    " - ‡∏£‡∏±‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞ cell ‡∏ï‡∏≤‡∏°‡∏•‡∏≥‡∏î‡∏±‡∏ö (Shift+Enter)\n",
    "\n",
    " - ‡∏ó‡∏≥‡πÅ‡∏ö‡∏ö‡∏ù‡∏∂‡∏Å‡∏´‡∏±‡∏î‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏´‡∏°‡∏≤‡∏¢ ‚úèÔ∏è\n",
    "\n",
    " - ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏Å‡∏±‡∏ö ‚úÖ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ---\n",
    "\n",
    " # üì¶ Module 1: ‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏•‡∏∞‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏™‡∏†‡∏≤‡∏û‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°\n",
    "\n",
    " ---\n",
    "\n",
    " ‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô ‡πÄ‡∏£‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏™‡∏†‡∏≤‡∏û‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°‡πÉ‡∏´‡πâ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡πà‡∏≠‡∏ô"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 1.1 ‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤ Libraries ‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô\n",
    "\n",
    "\n",
    "\n",
    " **‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ (‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢):**\n",
    "\n",
    " - `torch` - Library ‡∏´‡∏•‡∏±‡∏Å‡∏Ç‡∏≠‡∏á PyTorch\n",
    "\n",
    " - `torch.nn` - ‡πÄ‡∏Å‡πá‡∏ö building blocks ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á neural network\n",
    "\n",
    " - `torch.optim` - ‡πÄ‡∏Å‡πá‡∏ö optimizer ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡πà‡∏≤ weights\n",
    "\n",
    " - `numpy` - ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏ó‡∏≤‡∏á‡∏Ñ‡∏ì‡∏¥‡∏ï‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå\n",
    "\n",
    " - `matplotlib` - ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ‡πÅ‡∏™‡∏î‡∏á‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡∏Ç‡∏≠‡∏á PyTorch\n",
    "print(f\"üì¶ PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ GPU (CUDA) ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà\n",
    "print(f\"üéÆ CUDA available: {torch.cuda.is_available()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 1.2 ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Device ‡∏ó‡∏µ‡πà‡∏°‡∏µ (CPU/GPU)\n",
    "\n",
    "\n",
    "\n",
    " **‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ (‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢):**\n",
    "\n",
    "\n",
    "\n",
    " PyTorch ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏ó‡∏±‡πâ‡∏á‡∏ö‡∏ô CPU ‡πÅ‡∏•‡∏∞ GPU:\n",
    "\n",
    " - **CPU** - ‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡∏ó‡∏∏‡∏Å‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á ‡πÅ‡∏ï‡πà‡∏ä‡πâ‡∏≤‡∏Å‡∏ß‡πà‡∏≤\n",
    "\n",
    " - **GPU (CUDA)** - ‡πÄ‡∏£‡πá‡∏ß‡∏Å‡∏ß‡πà‡∏≤‡∏°‡∏≤‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Deep Learning (‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πå‡∏î‡∏à‡∏≠ NVIDIA)\n",
    "\n",
    " - **MPS** - ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Mac ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏ä‡∏¥‡∏õ Apple Silicon (M1/M2/M3)\n",
    "\n",
    "\n",
    "\n",
    " ‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å device ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏à‡∏∞‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏Å‡∏≤‡∏£ train ‡πÄ‡∏£‡πá‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô‡∏´‡∏•‡∏≤‡∏¢‡πÄ‡∏ó‡πà‡∏≤!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device_info():\n",
    "    \"\"\"\n",
    "    ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• device ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà\n",
    "    (Function to display available device information)\n",
    "    \"\"\"\n",
    "    print(\"=\" * 50)\n",
    "    print(\"üìä ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• DEVICE (DEVICE INFORMATION)\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # CPU ‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÄ‡∏™‡∏°‡∏≠\n",
    "    print(f\"\\nüìå CPU: ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÄ‡∏™‡∏°‡∏≠ (Always available)\")\n",
    "    \n",
    "    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö NVIDIA GPU\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"\\nüöÄ CUDA (NVIDIA GPU): ‚úÖ ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô\")\n",
    "        print(f\"   ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô GPU: {torch.cuda.device_count()}\")\n",
    "        \n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            gpu_name = torch.cuda.get_device_name(i)\n",
    "            total_mem = torch.cuda.get_device_properties(i).total_memory / 1e9\n",
    "            print(f\"   GPU {i}: {gpu_name}\")\n",
    "            print(f\"         ‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥: {total_mem:.2f} GB\")\n",
    "    else:\n",
    "        print(f\"\\n‚ö†Ô∏è  CUDA: ‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô (‡∏à‡∏∞‡πÉ‡∏ä‡πâ CPU ‡πÅ‡∏ó‡∏ô)\")\n",
    "    \n",
    "    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Apple Silicon\n",
    "    if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "        print(f\"\\nüçé MPS (Apple Silicon): ‚úÖ ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô\")\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "\n",
    "# ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô\n",
    "get_device_info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 1.3 ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£ device ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÉ‡∏ä‡πâ‡∏ï‡∏•‡∏≠‡∏î‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°\n",
    "\n",
    "\n",
    "\n",
    " **‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ (‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢):**\n",
    "\n",
    "\n",
    "\n",
    " ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£ `device` ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡∏ï‡∏•‡∏≠‡∏î‡∏ó‡∏±‡πâ‡∏á‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°\n",
    "\n",
    " ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ô‡∏µ‡πâ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÇ‡∏Ñ‡πâ‡∏î‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏ó‡∏∏‡∏Å‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á ‡πÑ‡∏°‡πà‡∏ß‡πà‡∏≤‡∏à‡∏∞‡∏°‡∏µ GPU ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà\n",
    "\n",
    "\n",
    "\n",
    " **‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô:**\n",
    "\n",
    " ```python\n",
    "\n",
    " device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£ device (‡πÉ‡∏ä‡πâ GPU ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ ‡πÑ‡∏°‡πà‡∏á‡∏±‡πâ‡∏ô‡πÉ‡∏ä‡πâ CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"‚úÖ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô device: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 1.4 ‡∏Å‡∏≤‡∏£‡∏¢‡πâ‡∏≤‡∏¢ Tensor ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á Devices\n",
    "\n",
    "\n",
    "\n",
    " **‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ (‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢):**\n",
    "\n",
    "\n",
    "\n",
    " ‡πÄ‡∏£‡∏≤‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏¢‡πâ‡∏≤‡∏¢ tensor ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á CPU ‡πÅ‡∏•‡∏∞ GPU ‡πÑ‡∏î‡πâ‡∏î‡πâ‡∏ß‡∏¢ `.to(device)`\n",
    "\n",
    "\n",
    "\n",
    " ‚ö†Ô∏è **‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏£‡∏à‡∏≥:** Tensor ‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡∏Ñ‡∏ô‡∏•‡∏∞ device ‡∏à‡∏∞‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ô‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ!\n",
    "\n",
    " ‡∏ï‡πâ‡∏≠‡∏á‡∏¢‡πâ‡∏≤‡∏¢‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πà device ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô‡∏Å‡πà‡∏≠‡∏ô"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á tensor ‡∏ö‡∏ô CPU\n",
    "x_cpu = torch.tensor([1, 2, 3])\n",
    "print(f\"üîµ x_cpu ‡∏≠‡∏¢‡∏π‡πà‡∏ö‡∏ô: {x_cpu.device}\")\n",
    "\n",
    "# ‡∏¢‡πâ‡∏≤‡∏¢‡πÑ‡∏õ‡∏¢‡∏±‡∏á device ‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å (GPU ‡∏´‡∏£‡∏∑‡∏≠ CPU)\n",
    "x_device = x_cpu.to(device)\n",
    "print(f\"üü¢ x_device ‡∏≠‡∏¢‡∏π‡πà‡∏ö‡∏ô: {x_device.device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 1.5 ‡∏™‡∏£‡πâ‡∏≤‡∏á Tensor ‡∏ö‡∏ô Device ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á\n",
    "\n",
    "\n",
    "\n",
    " **‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ (‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢):**\n",
    "\n",
    "\n",
    "\n",
    " ‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ö‡∏ô CPU ‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡πà‡∏≠‡∏¢‡∏¢‡πâ‡∏≤‡∏¢ ‡πÄ‡∏£‡∏≤‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ö‡∏ô device ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢\n",
    "\n",
    " ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ô‡∏µ‡πâ‡πÄ‡∏£‡πá‡∏ß‡∏Å‡∏ß‡πà‡∏≤‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥‡∏Å‡∏ß‡πà‡∏≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á tensor ‡∏ö‡∏ô device ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á\n",
    "y = torch.randn(3, 3, device=device)\n",
    "print(f\"üéØ y ‡∏ñ‡∏π‡∏Å‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ö‡∏ô: {y.device}\")\n",
    "print(f\"‡∏Ñ‡πà‡∏≤‡∏Ç‡∏≠‡∏á y:\\n{y}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 1.6 ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Seed ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Reproducibility\n",
    "\n",
    "\n",
    "\n",
    " **‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ (‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢):**\n",
    "\n",
    "\n",
    "\n",
    " ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏•‡∏≠‡∏á ‡πÄ‡∏£‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏´‡πâ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ô‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏ô\n",
    "\n",
    " ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏ß‡πà‡∏≤ **Reproducibility** (‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ã‡πâ‡∏≥)\n",
    "\n",
    "\n",
    "\n",
    " ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏Ñ‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á **seed** ‡πÉ‡∏´‡πâ‡∏ï‡∏±‡∏ß‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏•‡∏Ç‡∏™‡∏∏‡πà‡∏° (random number generator)\n",
    "\n",
    " ‡πÄ‡∏°‡∏∑‡πà‡∏≠ seed ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô ‚Üí ‡πÄ‡∏•‡∏Ç‡∏™‡∏∏‡πà‡∏°‡∏à‡∏∞‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ô"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int = 42):\n",
    "    \"\"\"\n",
    "    ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ seed ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö reproducibility\n",
    "    ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡∏ï‡∏≠‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏•‡∏≠‡∏á!\n",
    "    \n",
    "    Args:\n",
    "        seed: ‡∏Ñ‡πà‡∏≤ seed ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ (‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏Ñ‡∏∑‡∏≠ 42)\n",
    "    \"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)  # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö multi-GPU\n",
    "        \n",
    "        # ‡∏ó‡∏≥‡πÉ‡∏´‡πâ CUDA operations ‡πÄ‡∏õ‡πá‡∏ô deterministic\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "    print(f\"üå± ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ seed ‡πÄ‡∏õ‡πá‡∏ô {seed} ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢\")\n",
    "\n",
    "# ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô\n",
    "set_seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 1.7 ‡∏ó‡∏î‡∏™‡∏≠‡∏ö Reproducibility\n",
    "\n",
    "\n",
    "\n",
    " **‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ (‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢):**\n",
    "\n",
    "\n",
    "\n",
    " ‡∏°‡∏≤‡∏•‡∏≠‡∏á‡∏û‡∏¥‡∏™‡∏π‡∏à‡∏ô‡πå‡∏ß‡πà‡∏≤ seed ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏á\n",
    "\n",
    " ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ï‡∏±‡πâ‡∏á seed ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô tensor ‡∏™‡∏∏‡πà‡∏°‡∏à‡∏∞‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ô‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà 1\n",
    "set_seed(42)\n",
    "random_tensor_1 = torch.rand(3)\n",
    "print(f\"‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà 1: {random_tensor_1}\")\n",
    "\n",
    "# ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà 2 (seed ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô)\n",
    "set_seed(42)\n",
    "random_tensor_2 = torch.rand(3)\n",
    "print(f\"‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà 2: {random_tensor_2}\")\n",
    "\n",
    "# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ô\n",
    "print(f\"\\n‚úÖ ‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà: {torch.equal(random_tensor_1, random_tensor_2)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## ‚úèÔ∏è ‡πÅ‡∏ö‡∏ö‡∏ù‡∏∂‡∏Å‡∏´‡∏±‡∏î 1.1: ‡∏ù‡∏∂‡∏Å Device Management\n",
    "\n",
    "\n",
    "\n",
    " **‡πÇ‡∏à‡∏ó‡∏¢‡πå:** ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ó‡∏µ‡πà:\n",
    "\n",
    " 1. ‡∏£‡∏±‡∏ö tensor ‡πÄ‡∏õ‡πá‡∏ô input\n",
    "\n",
    " 2. ‡πÅ‡∏™‡∏î‡∏á device ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡∏Ç‡∏≠‡∏á tensor\n",
    "\n",
    " 3. ‡∏¢‡πâ‡∏≤‡∏¢ tensor ‡πÑ‡∏õ‡∏¢‡∏±‡∏á device ‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î (GPU ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)\n",
    "\n",
    " 4. ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤ tensor ‡∏ó‡∏µ‡πà‡∏¢‡πâ‡∏≤‡∏¢‡πÅ‡∏•‡πâ‡∏ß"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_to_best_device(tensor):\n",
    "    \"\"\"\n",
    "    ‡∏¢‡πâ‡∏≤‡∏¢ tensor ‡πÑ‡∏õ‡∏¢‡∏±‡∏á device ‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î\n",
    "    \n",
    "    Args:\n",
    "        tensor: tensor ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏¢‡πâ‡∏≤‡∏¢\n",
    "    \n",
    "    Returns:\n",
    "        tensor ‡∏ó‡∏µ‡πà‡∏¢‡πâ‡∏≤‡∏¢‡πÅ‡∏•‡πâ‡∏ß\n",
    "    \"\"\"\n",
    "    # ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà (YOUR CODE HERE)\n",
    "    pass\n",
    "\n",
    "# ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì:\n",
    "# test_tensor = torch.ones(5)\n",
    "# result = move_to_best_device(test_tensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ---\n",
    "\n",
    " # üßÆ Module 2: Tensors - ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏±‡∏Å‡∏Ç‡∏≠‡∏á PyTorch\n",
    "\n",
    " ---\n",
    "\n",
    "\n",
    "\n",
    " **Tensor ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£?**\n",
    "\n",
    "\n",
    "\n",
    " Tensor ‡∏Ñ‡∏∑‡∏≠ array ‡∏´‡∏•‡∏≤‡∏¢‡∏°‡∏¥‡∏ï‡∏¥ (n-dimensional array) ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏û‡∏¥‡πÄ‡∏®‡∏©:\n",
    "\n",
    " - ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏ö‡∏ô GPU ‡πÑ‡∏î‡πâ\n",
    "\n",
    " - ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì gradient ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡πÑ‡∏î‡πâ\n",
    "\n",
    " - ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö broadcasting\n",
    "\n",
    "\n",
    "\n",
    " **‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö NumPy:**\n",
    "\n",
    " | NumPy | PyTorch |\n",
    "\n",
    " |-------|---------|\n",
    "\n",
    " | ndarray | tensor |\n",
    "\n",
    " | np.array([1,2,3]) | torch.tensor([1,2,3]) |\n",
    "\n",
    " | np.zeros() | torch.zeros() |\n",
    "\n",
    " | np.dot() | torch.matmul() ‡∏´‡∏£‡∏∑‡∏≠ @ |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 2.1 ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á Tensor ‡∏à‡∏≤‡∏Å Python List\n",
    "\n",
    "\n",
    "\n",
    " **‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ (‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢):**\n",
    "\n",
    "\n",
    "\n",
    " ‡∏ß‡∏¥‡∏ò‡∏µ‡∏á‡πà‡∏≤‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á tensor ‡∏Ñ‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡∏à‡∏≤‡∏Å Python list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á tensor 1 ‡∏°‡∏¥‡∏ï‡∏¥ (vector)\n",
    "a = torch.tensor([1, 2, 3])\n",
    "print(f\"Vector: {a}\")\n",
    "print(f\"  Shape (‡∏£‡∏π‡∏õ‡∏£‡πà‡∏≤‡∏á): {a.shape}\")\n",
    "print(f\"  Dtype (‡∏ä‡∏ô‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•): {a.dtype}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 2.2 Tensor 2 ‡∏°‡∏¥‡∏ï‡∏¥ (Matrix)\n",
    "\n",
    "\n",
    "\n",
    " **‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ (‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢):**\n",
    "\n",
    "\n",
    "\n",
    " Tensor 2 ‡∏°‡∏¥‡∏ï‡∏¥ ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏ß‡πà‡∏≤ Matrix ‡∏´‡∏£‡∏∑‡∏≠ ‡∏ï‡∏≤‡∏£‡∏≤‡∏á\n",
    "\n",
    " ‡πÉ‡∏ä‡πâ nested list (list ‡∏ã‡πâ‡∏≠‡∏ô list) ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á tensor 2 ‡∏°‡∏¥‡∏ï‡∏¥ (matrix)\n",
    "b = torch.tensor([\n",
    "    [1, 2, 3],    # ‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà 1\n",
    "    [4, 5, 6]     # ‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà 2\n",
    "])\n",
    "print(f\"Matrix:\\n{b}\")\n",
    "print(f\"  Shape: {b.shape}\")  # (2, 3) = 2 ‡πÅ‡∏ñ‡∏ß, 3 ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 2.3 ‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á NumPy ‚Üî PyTorch\n",
    "\n",
    "\n",
    "\n",
    " **‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ (‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢):**\n",
    "\n",
    "\n",
    "\n",
    " PyTorch ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏õ‡∏°‡∏≤‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á NumPy ‡πÑ‡∏î‡πâ‡∏á‡πà‡∏≤‡∏¢\n",
    "\n",
    "\n",
    "\n",
    " ‚ö†Ô∏è **‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏£‡∏£‡∏∞‡∏ß‡∏±‡∏á:** `torch.from_numpy()` ‡∏à‡∏∞ **share memory** ‡∏Å‡∏±‡∏ö NumPy array\n",
    "\n",
    " ‡∏´‡∏°‡∏≤‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ß‡πà‡∏≤‡∏ñ‡πâ‡∏≤‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏≠‡∏±‡∏ô‡∏´‡∏ô‡∏∂‡πà‡∏á ‡∏≠‡∏µ‡∏Å‡∏≠‡∏±‡∏ô‡∏à‡∏∞‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ï‡∏≤‡∏°‡∏î‡πâ‡∏ß‡∏¢!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy ‚Üí PyTorch\n",
    "np_array = np.array([1.0, 2.0, 3.0])\n",
    "tensor_from_np = torch.from_numpy(np_array)\n",
    "print(f\"NumPy array: {np_array}\")\n",
    "print(f\"Tensor: {tensor_from_np}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 2.4 ‡∏ó‡∏î‡∏™‡∏≠‡∏ö Memory Sharing\n",
    "\n",
    "\n",
    "\n",
    " **‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ (‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢):**\n",
    "\n",
    "\n",
    "\n",
    " ‡∏°‡∏≤‡∏û‡∏¥‡∏™‡∏π‡∏à‡∏ô‡πå‡∏ß‡πà‡∏≤ memory ‡∏ñ‡∏π‡∏Å share ‡∏à‡∏£‡∏¥‡∏á"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç NumPy array\n",
    "np_array[0] = 999\n",
    "print(f\"‡∏´‡∏•‡∏±‡∏á‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç NumPy: {np_array}\")\n",
    "print(f\"Tensor ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ï‡∏≤‡∏°: {tensor_from_np}\")\n",
    "\n",
    "# ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤‡∏Å‡∏•‡∏±‡∏ö\n",
    "np_array[0] = 1.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 2.5 ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏£‡πâ‡∏≤‡∏á Tensor ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏ö‡πà‡∏≠‡∏¢\n",
    "\n",
    "\n",
    "\n",
    " **‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ (‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢):**\n",
    "\n",
    "\n",
    "\n",
    " PyTorch ‡∏°‡∏µ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡∏£‡∏π‡∏õ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á tensor ‡πÅ‡∏ö‡∏ö‡∏ï‡πà‡∏≤‡∏á‡πÜ:\n",
    "\n",
    "\n",
    "\n",
    " | ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô | ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå |\n",
    "\n",
    " |---------|--------|\n",
    "\n",
    " | `torch.zeros()` | tensor ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÅ‡∏ï‡πà 0 |\n",
    "\n",
    " | `torch.ones()` | tensor ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÅ‡∏ï‡πà 1 |\n",
    "\n",
    " | `torch.rand()` | ‡∏™‡∏∏‡πà‡∏°‡∏à‡∏≤‡∏Å 0-1 (uniform) |\n",
    "\n",
    " | `torch.randn()` | ‡∏™‡∏∏‡πà‡∏°‡πÅ‡∏ö‡∏ö normal distribution |\n",
    "\n",
    " | `torch.arange()` | ‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç |\n",
    "\n",
    " | `torch.eye()` | matrix ‡∏´‡∏ô‡πà‡∏ß‡∏¢ (identity) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zeros - ‡∏™‡∏£‡πâ‡∏≤‡∏á tensor ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÅ‡∏ï‡πà 0\n",
    "zeros = torch.zeros(2, 3)  # 2 ‡πÅ‡∏ñ‡∏ß, 3 ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå\n",
    "print(f\"Zeros (2x3):\\n{zeros}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ones - ‡∏™‡∏£‡πâ‡∏≤‡∏á tensor ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÅ‡∏ï‡πà 1\n",
    "ones = torch.ones(2, 3)\n",
    "print(f\"Ones (2x3):\\n{ones}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rand - ‡∏™‡∏∏‡πà‡∏°‡∏à‡∏≤‡∏Å 0 ‡∏ñ‡∏∂‡∏á 1 (uniform distribution)\n",
    "random_uniform = torch.rand(2, 3)\n",
    "print(f\"Random Uniform (2x3):\\n{random_uniform}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randn - ‡∏™‡∏∏‡πà‡∏°‡πÅ‡∏ö‡∏ö Normal Distribution (mean=0, std=1)\n",
    "random_normal = torch.randn(2, 3)\n",
    "print(f\"Random Normal (2x3):\\n{random_normal}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arange - ‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô range ‡∏Ç‡∏≠‡∏á Python)\n",
    "sequence = torch.arange(0, 10, 2)  # ‡πÄ‡∏£‡∏¥‡πà‡∏°=0, ‡∏à‡∏ö=10, step=2\n",
    "print(f\"Arange (0 ‡∏ñ‡∏∂‡∏á 10, step=2): {sequence}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linspace - ‡πÅ‡∏ö‡πà‡∏á‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ó‡πà‡∏≤‡πÜ ‡∏Å‡∏±‡∏ô\n",
    "linspace = torch.linspace(0, 1, 5)  # ‡πÅ‡∏ö‡πà‡∏á 0-1 ‡πÄ‡∏õ‡πá‡∏ô 5 ‡∏à‡∏∏‡∏î\n",
    "print(f\"Linspace (0 ‡∏ñ‡∏∂‡∏á 1, 5 ‡∏à‡∏∏‡∏î): {linspace}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eye - Identity Matrix (matrix ‡∏´‡∏ô‡πà‡∏ß‡∏¢)\n",
    "identity = torch.eye(3)  # 3x3\n",
    "print(f\"Identity Matrix (3x3):\\n{identity}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 2.6 Data Types (dtype) - ‡∏ä‡∏ô‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
    "\n",
    "\n",
    "\n",
    " **‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ (‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢):**\n",
    "\n",
    "\n",
    "\n",
    " dtype ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ß‡πà‡∏≤ tensor ‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ö‡∏ö‡πÑ‡∏´‡∏ô ‡∏™‡πà‡∏á‡∏ú‡∏•‡∏ï‡πà‡∏≠:\n",
    "\n",
    " - **‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥** (precision) - float64 ‡πÅ‡∏°‡πà‡∏ô‡∏Å‡∏ß‡πà‡∏≤ float32\n",
    "\n",
    " - **‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥** - float32 ‡πÉ‡∏ä‡πâ‡∏ô‡πâ‡∏≠‡∏¢‡∏Å‡∏ß‡πà‡∏≤ float64\n",
    "\n",
    " - **‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß** - float32 ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÄ‡∏£‡πá‡∏ß‡∏Å‡∏ß‡πà‡∏≤\n",
    "\n",
    "\n",
    "\n",
    " **dtype ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏ö‡πà‡∏≠‡∏¢:**\n",
    "\n",
    " | dtype | ‡∏Ç‡∏ô‡∏≤‡∏î | ‡πÉ‡∏ä‡πâ‡πÄ‡∏°‡∏∑‡πà‡∏≠ |\n",
    "\n",
    " |-------|------|---------|\n",
    "\n",
    " | float32 | 4 bytes | ‡πÉ‡∏ä‡πâ‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ (‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô) |\n",
    "\n",
    " | float64 | 8 bytes | ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏™‡∏π‡∏á |\n",
    "\n",
    " | int64 | 8 bytes | ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏ï‡πá‡∏° |\n",
    "\n",
    " | bool | 1 bit | True/False |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏Ç‡∏≠‡∏á float ‡∏Ñ‡∏∑‡∏≠ float32\n",
    "x_default = torch.tensor([1.0])\n",
    "print(f\"Default float: {x_default.dtype}\")  # torch.float32\n",
    "\n",
    "# ‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏Ç‡∏≠‡∏á integer ‡∏Ñ‡∏∑‡∏≠ int64\n",
    "x_int = torch.tensor([1])\n",
    "print(f\"Default int: {x_int.dtype}\")  # torch.int64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î dtype ‡πÄ‡∏≠‡∏á\n",
    "x_float32 = torch.tensor([1, 2, 3], dtype=torch.float32)\n",
    "x_float64 = torch.tensor([1, 2, 3], dtype=torch.float64)\n",
    "\n",
    "print(f\"Float32: {x_float32.dtype}, ‡∏Ç‡∏ô‡∏≤‡∏î: {x_float32.element_size()} bytes ‡∏ï‡πà‡∏≠‡∏ï‡∏±‡∏ß\")\n",
    "print(f\"Float64: {x_float64.dtype}, ‡∏Ç‡∏ô‡∏≤‡∏î: {x_float64.element_size()} bytes ‡∏ï‡πà‡∏≠‡∏ï‡∏±‡∏ß\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 2.7 ‡∏™‡∏£‡πâ‡∏≤‡∏á Tensor ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏∏‡∏ì‡∏™‡∏°‡∏ö‡∏±‡∏ï‡∏¥‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô Tensor ‡∏≠‡∏∑‡πà‡∏ô\n",
    "\n",
    "\n",
    "\n",
    " **‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ (‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢):**\n",
    "\n",
    "\n",
    "\n",
    " ‡∏ö‡∏≤‡∏á‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏£‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á tensor ‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ‡πà‡∏°‡∏µ dtype ‡πÅ‡∏•‡∏∞ device ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô tensor ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà\n",
    "\n",
    " ‡πÉ‡∏ä‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô `*_like()`:\n",
    "\n",
    " - `torch.zeros_like(x)` - ‡∏™‡∏£‡πâ‡∏≤‡∏á zeros ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏∏‡∏ì‡∏™‡∏°‡∏ö‡∏±‡∏ï‡∏¥‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô x\n",
    "\n",
    " - `torch.ones_like(x)` - ‡∏™‡∏£‡πâ‡∏≤‡∏á ones ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏∏‡∏ì‡∏™‡∏°‡∏ö‡∏±‡∏ï‡∏¥‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô x\n",
    "\n",
    " - `torch.rand_like(x)` - ‡∏™‡∏£‡πâ‡∏≤‡∏á random ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏∏‡∏ì‡∏™‡∏°‡∏ö‡∏±‡∏ï‡∏¥‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á tensor ‡∏ï‡πâ‡∏ô‡πÅ‡∏ö‡∏ö\n",
    "original = torch.randn(2, 3, dtype=torch.float64, device=device)\n",
    "print(f\"Original - device: {original.device}, dtype: {original.dtype}\")\n",
    "print(f\"Original:\\n{original}\")\n",
    "\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á tensor ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏∏‡∏ì‡∏™‡∏°‡∏ö‡∏±‡∏ï‡∏¥‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ô\n",
    "zeros_like_original = torch.zeros_like(original)\n",
    "print(f\"\\nZeros like - device: {zeros_like_original.device}, dtype: {zeros_like_original.dtype}\")\n",
    "print(f\"Zeros like:\\n{zeros_like_original}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ---\n",
    "\n",
    " ## 2.8 ‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô Shape: reshape, view\n",
    "\n",
    " ---\n",
    "\n",
    "\n",
    "\n",
    " **‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ (‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢):**\n",
    "\n",
    "\n",
    "\n",
    " Shape ‡∏Ñ‡∏∑‡∏≠ \"‡∏£‡∏π‡∏õ‡∏£‡πà‡∏≤‡∏á\" ‡∏Ç‡∏≠‡∏á tensor ‡∏ö‡∏≠‡∏Å‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Å‡∏µ‡πà‡∏°‡∏¥‡∏ï‡∏¥ ‡πÅ‡∏•‡∏∞‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏°‡∏¥‡∏ï‡∏¥‡∏°‡∏µ‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏´‡∏£‡πà\n",
    "\n",
    "\n",
    "\n",
    " **‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á:**\n",
    "\n",
    " - `(6,)` = 1 ‡∏°‡∏¥‡∏ï‡∏¥, 6 ‡∏ï‡∏±‡∏ß\n",
    "\n",
    " - `(2, 3)` = 2 ‡∏°‡∏¥‡∏ï‡∏¥, 2 ‡πÅ‡∏ñ‡∏ß √ó 3 ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå\n",
    "\n",
    " - `(2, 2, 3)` = 3 ‡∏°‡∏¥‡∏ï‡∏¥, 2 √ó 2 √ó 3\n",
    "\n",
    "\n",
    "\n",
    " **‡∏Å‡∏é‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç:** ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ô‡∏´‡∏•‡∏±‡∏á reshape\n",
    "\n",
    " - `(6,)` ‚Üí `(2, 3)` ‡πÑ‡∏î‡πâ ‡πÄ‡∏û‡∏£‡∏≤‡∏∞ 6 = 2√ó3\n",
    "\n",
    " - `(6,)` ‚Üí `(2, 4)` ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ ‡πÄ‡∏û‡∏£‡∏≤‡∏∞ 6 ‚â† 2√ó4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á tensor 1 ‡∏°‡∏¥‡∏ï‡∏¥\n",
    "x = torch.arange(12)  # [0, 1, 2, ..., 11]\n",
    "print(f\"Original shape: {x.shape}\")\n",
    "print(f\"Original: {x}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### reshape ‡πÄ‡∏õ‡πá‡∏ô 2 ‡∏°‡∏¥‡∏ï‡∏¥ (Matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape ‡πÄ‡∏õ‡πá‡∏ô 2D: 3 ‡πÅ‡∏ñ‡∏ß √ó 4 ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå\n",
    "x_2d = x.reshape(3, 4)\n",
    "print(f\"Shape ‡∏´‡∏•‡∏±‡∏á reshape(3, 4): {x_2d.shape}\")\n",
    "print(f\"Matrix:\\n{x_2d}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### reshape ‡πÄ‡∏õ‡πá‡∏ô 3 ‡∏°‡∏¥‡∏ï‡∏¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape ‡πÄ‡∏õ‡πá‡∏ô 3D: 2 \"‡∏Å‡πâ‡∏≠‡∏ô\" √ó 2 ‡πÅ‡∏ñ‡∏ß √ó 3 ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå\n",
    "x_3d = x.reshape(2, 2, 3)\n",
    "print(f\"Shape ‡∏´‡∏•‡∏±‡∏á reshape(2, 2, 3): {x_3d.shape}\")\n",
    "print(f\"3D Tensor:\\n{x_3d}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### ‡πÉ‡∏ä‡πâ -1 ‡πÉ‡∏´‡πâ PyTorch ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏°‡∏¥‡∏ï‡∏¥‡πÉ‡∏´‡πâ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡πÉ‡∏ä‡πâ -1 = ‡πÉ‡∏´‡πâ PyTorch ‡∏Ñ‡∏¥‡∏î‡πÉ‡∏´‡πâ\n",
    "x_auto = x.reshape(4, -1)  # 4 ‡πÅ‡∏ñ‡∏ß, PyTorch ‡∏Ñ‡∏¥‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÉ‡∏´‡πâ\n",
    "print(f\"reshape(4, -1) ‚Üí shape: {x_auto.shape}\")  # (4, 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### ‚ö†Ô∏è ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á view ‡πÅ‡∏•‡∏∞ reshape\n",
    "\n",
    "\n",
    "\n",
    " **‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ (‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢):**\n",
    "\n",
    "\n",
    "\n",
    " - `view()` - ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤ **view** ‡∏Ç‡∏≠‡∏á tensor ‡πÄ‡∏î‡∏¥‡∏° (share memory) ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô contiguous\n",
    "\n",
    " - `reshape()` - ‡∏≠‡∏≤‡∏à‡∏Ñ‡∏∑‡∏ô view ‡∏´‡∏£‡∏∑‡∏≠ copy ‡∏Å‡πá‡πÑ‡∏î‡πâ ‡∏¢‡∏∑‡∏î‡∏´‡∏¢‡∏∏‡πà‡∏ô‡∏Å‡∏ß‡πà‡∏≤\n",
    "\n",
    "\n",
    "\n",
    " ‚ö†Ô∏è **‡∏£‡∏∞‡∏ß‡∏±‡∏á:** ‡∏ñ‡πâ‡∏≤‡πÉ‡∏ä‡πâ `view()` ‡πÅ‡∏•‡πâ‡∏ß‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏Ñ‡πà‡∏≤ tensor ‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö‡∏à‡∏∞‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ï‡∏≤‡∏°!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á: view shares memory\n",
    "x = torch.arange(6).reshape(2, 3)\n",
    "print(f\"x ‡∏Å‡πà‡∏≠‡∏ô‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç:\\n{x}\")\n",
    "\n",
    "y = x.view(3, 2)  # y ‡∏Ñ‡∏∑‡∏≠ view ‡∏Ç‡∏≠‡∏á x (share memory)\n",
    "y[0, 0] = 999     # ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç y\n",
    "\n",
    "print(f\"\\nx ‡∏´‡∏•‡∏±‡∏á‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç y:\\n{x}\")  # x ‡∏Å‡πá‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏î‡πâ‡∏ß‡∏¢!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 2.9 squeeze ‡πÅ‡∏•‡∏∞ unsqueeze - ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏°‡∏¥‡∏ï‡∏¥‡∏Ç‡∏ô‡∏≤‡∏î 1\n",
    "\n",
    "\n",
    "\n",
    " **‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ (‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢):**\n",
    "\n",
    "\n",
    "\n",
    " - `squeeze()` - **‡∏•‡∏ö** ‡∏°‡∏¥‡∏ï‡∏¥‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ç‡∏ô‡∏≤‡∏î 1 ‡∏≠‡∏≠‡∏Å\n",
    "\n",
    " - `unsqueeze()` - **‡πÄ‡∏û‡∏¥‡πà‡∏°** ‡∏°‡∏¥‡∏ï‡∏¥‡∏Ç‡∏ô‡∏≤‡∏î 1 ‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ\n",
    "\n",
    "\n",
    "\n",
    " **‡∏ó‡∏≥‡πÑ‡∏°‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ?**\n",
    "\n",
    " ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏ô PyTorch ‡∏°‡∏±‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ input shape ‡πÅ‡∏ö‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞ ‡πÄ‡∏ä‡πà‡∏ô:\n",
    "\n",
    " - ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ batch dimension ‚Üí ‡πÉ‡∏ä‡πâ unsqueeze\n",
    "\n",
    " - ‡∏ï‡πâ‡∏≠‡∏á‡∏•‡∏ö‡∏°‡∏¥‡∏ï‡∏¥‡∏™‡πà‡∏ß‡∏ô‡πÄ‡∏Å‡∏¥‡∏ô ‚Üí ‡πÉ‡∏ä‡πâ squeeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á squeeze\n",
    "x = torch.randn(1, 3, 1, 4, 1)\n",
    "print(f\"Shape ‡πÄ‡∏î‡∏¥‡∏°: {x.shape}\")  # (1, 3, 1, 4, 1)\n",
    "\n",
    "# squeeze() ‡∏•‡∏ö‡∏ó‡∏∏‡∏Å‡∏°‡∏¥‡∏ï‡∏¥‡∏ó‡∏µ‡πà‡∏Ç‡∏ô‡∏≤‡∏î = 1\n",
    "squeezed = x.squeeze()\n",
    "print(f\"‡∏´‡∏•‡∏±‡∏á squeeze(): {squeezed.shape}\")  # (3, 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# squeeze ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏°‡∏¥‡∏ï‡∏¥‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£\n",
    "x = torch.randn(1, 3, 1, 4, 1)\n",
    "squeezed_0 = x.squeeze(0)  # ‡∏•‡∏ö‡∏°‡∏¥‡∏ï‡∏¥‡∏ó‡∏µ‡πà 0 ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô\n",
    "print(f\"‡∏´‡∏•‡∏±‡∏á squeeze(0): {squeezed_0.shape}\")  # (3, 1, 4, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á unsqueeze\n",
    "x = torch.randn(3, 4)\n",
    "print(f\"Shape ‡πÄ‡∏î‡∏¥‡∏°: {x.shape}\")  # (3, 4)\n",
    "\n",
    "# ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏°‡∏¥‡∏ï‡∏¥‡∏ó‡∏µ‡πà‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏ï‡πà‡∏≤‡∏á‡πÜ\n",
    "print(f\"unsqueeze(0): {x.unsqueeze(0).shape}\")   # (1, 3, 4) - ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ó‡∏µ‡πà‡∏î‡πâ‡∏≤‡∏ô‡∏´‡∏ô‡πâ‡∏≤\n",
    "print(f\"unsqueeze(1): {x.unsqueeze(1).shape}\")   # (3, 1, 4) - ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ï‡∏£‡∏á‡∏Å‡∏•‡∏≤‡∏á\n",
    "print(f\"unsqueeze(-1): {x.unsqueeze(-1).shape}\") # (3, 4, 1) - ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ó‡∏µ‡πà‡∏ó‡πâ‡∏≤‡∏¢\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### üîë Pattern ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç: ‡πÄ‡∏û‡∏¥‡πà‡∏° Batch Dimension\n",
    "\n",
    "\n",
    "\n",
    " **‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ (‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢):**\n",
    "\n",
    "\n",
    "\n",
    " ‡πÇ‡∏°‡πÄ‡∏î‡∏• Deep Learning ‡∏°‡∏±‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ input ‡∏ó‡∏µ‡πà‡∏°‡∏µ batch dimension\n",
    "\n",
    " ‡πÄ‡∏ä‡πà‡∏ô ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û 1 ‡∏£‡∏π‡∏õ ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô shape `(1, C, H, W)` ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà `(C, H, W)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û 1 ‡∏£‡∏π‡∏õ: 3 channels, 224x224 pixels\n",
    "single_image = torch.randn(3, 224, 224)\n",
    "print(f\"‡∏£‡∏π‡∏õ‡πÄ‡∏î‡∏µ‡πà‡∏¢‡∏ß shape: {single_image.shape}\")  # (3, 224, 224)\n",
    "\n",
    "# ‡πÄ‡∏û‡∏¥‡πà‡∏° batch dimension\n",
    "batched_image = single_image.unsqueeze(0)\n",
    "print(f\"‡∏´‡∏•‡∏±‡∏á‡πÄ‡∏û‡∏¥‡πà‡∏° batch: {batched_image.shape}\")  # (1, 3, 224, 224)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 2.10 Indexing ‡πÅ‡∏•‡∏∞ Slicing\n",
    "\n",
    "\n",
    "\n",
    " **‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ (‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢):**\n",
    "\n",
    "\n",
    "\n",
    " ‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô tensor ‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ö NumPy:\n",
    "\n",
    " - `x[i]` - ‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà i\n",
    "\n",
    " - `x[i, j]` - ‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á element ‡∏ó‡∏µ‡πà‡πÅ‡∏ñ‡∏ß i, ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå j\n",
    "\n",
    " - `x[start:end]` - slice ‡∏à‡∏≤‡∏Å start ‡∏ñ‡∏∂‡∏á end-1\n",
    "\n",
    " - `x[:, j]` - ‡∏ó‡∏∏‡∏Å‡πÅ‡∏ñ‡∏ß, ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå j\n",
    "\n",
    " - `x[-1]` - ‡πÅ‡∏ñ‡∏ß‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á matrix ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á\n",
    "x = torch.arange(12).reshape(3, 4)\n",
    "print(f\"Matrix:\\n{x}\")\n",
    "print(f\"Shape: {x.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic indexing\n",
    "print(f\"x[1, 2] (‡πÅ‡∏ñ‡∏ß 1, ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå 2): {x[1, 2]}\")  # 6\n",
    "print(f\"x[0] (‡πÅ‡∏ñ‡∏ß‡πÅ‡∏£‡∏Å): {x[0]}\")  # [0, 1, 2, 3]\n",
    "print(f\"x[-1] (‡πÅ‡∏ñ‡∏ß‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢): {x[-1]}\")  # [8, 9, 10, 11]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column indexing\n",
    "print(f\"x[:, 0] (‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÅ‡∏£‡∏Å): {x[:, 0]}\")  # [0, 4, 8]\n",
    "print(f\"x[:, -1] (‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢): {x[:, -1]}\")  # [3, 7, 11]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slicing\n",
    "print(f\"x[0:2, 1:3] (‡πÅ‡∏ñ‡∏ß 0-1, ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå 1-2):\\n{x[0:2, 1:3]}\")\n",
    "print(f\"\\nx[::2] (‡∏ó‡∏∏‡∏Å‡πÜ 2 ‡πÅ‡∏ñ‡∏ß):\\n{x[::2]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 2.11 Boolean Masking - ‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏≠‡∏á‡∏î‡πâ‡∏ß‡∏¢‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç\n",
    "\n",
    "\n",
    "\n",
    " **‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ (‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢):**\n",
    "\n",
    "\n",
    "\n",
    " ‡πÄ‡∏£‡∏≤‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç boolean ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£\n",
    "\n",
    " ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ô‡∏µ‡πâ‡∏ó‡∏£‡∏á‡∏û‡∏•‡∏±‡∏á‡∏°‡∏≤‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏≠‡∏á‡πÅ‡∏•‡∏∞‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á tensor ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á\n",
    "x = torch.randn(3, 4)\n",
    "print(f\"Tensor:\\n{x}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á boolean mask\n",
    "mask = x > 0\n",
    "print(f\"\\nMask (‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏ó‡∏µ‡πà‡∏Ñ‡πà‡∏≤ > 0):\\n{mask}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡πÉ‡∏ä‡πâ mask ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
    "positives = x[mask]\n",
    "print(f\"\\n‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà > 0: {positives}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏î‡πâ‡∏ß‡∏¢ mask (‡∏ó‡∏≥ ReLU ‡∏î‡πâ‡∏ß‡∏¢‡∏°‡∏∑‡∏≠!)\n",
    "x[x < 0] = 0\n",
    "print(f\"\\n‡∏´‡∏•‡∏±‡∏á‡∏ó‡∏≥ x[x < 0] = 0 (ReLU):\\n{x}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 2.12 torch.where - ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ñ‡πà‡∏≤‡∏ï‡∏≤‡∏°‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç\n",
    "\n",
    "\n",
    "\n",
    " **‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ (‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢):**\n",
    "\n",
    "\n",
    "\n",
    " `torch.where(condition, x, y)` ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤:\n",
    "\n",
    " - ‡∏Ñ‡πà‡∏≤ x ‡∏ñ‡πâ‡∏≤ condition ‡πÄ‡∏õ‡πá‡∏ô True\n",
    "\n",
    " - ‡∏Ñ‡πà‡∏≤ y ‡∏ñ‡πâ‡∏≤ condition ‡πÄ‡∏õ‡πá‡∏ô False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([-2., -1., 0., 1., 2.])\n",
    "print(f\"x: {x}\")\n",
    "\n",
    "# where(condition, if_true, if_false)\n",
    "result = torch.where(x > 0, x, torch.zeros_like(x))\n",
    "print(f\"torch.where(x > 0, x, 0): {result}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## ‚úèÔ∏è ‡πÅ‡∏ö‡∏ö‡∏ù‡∏∂‡∏Å‡∏´‡∏±‡∏î 2.1: ‡∏ù‡∏∂‡∏Å Tensor Manipulation\n",
    "\n",
    "\n",
    "\n",
    " **‡πÇ‡∏à‡∏ó‡∏¢‡πå:** ‡∏à‡∏≤‡∏Å‡∏ï‡∏≤‡∏£‡∏≤‡∏á 4√ó4 ‡πÉ‡∏´‡πâ:\n",
    "\n",
    " 1. ‡∏î‡∏∂‡∏á‡∏Ñ‡πà‡∏≤‡∏ö‡∏ô‡πÄ‡∏™‡πâ‡∏ô‡∏ó‡πÅ‡∏¢‡∏á‡∏°‡∏∏‡∏° (diagonal)\n",
    "\n",
    " 2. ‡∏î‡∏∂‡∏á submatrix ‡∏°‡∏∏‡∏°‡∏ö‡∏ô‡∏Ç‡∏ß‡∏≤ 2√ó2\n",
    "\n",
    " 3. ‡∏î‡∏∂‡∏á‡∏Ñ‡πà‡∏≤‡∏ó‡∏∏‡∏Å‡∏ï‡∏±‡∏ß‡∏ó‡∏µ‡πà‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = torch.arange(16).reshape(4, 4).float()\n",
    "print(f\"Matrix:\\n{matrix}\")\n",
    "\n",
    "# ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà (YOUR CODE HERE)\n",
    "# diagonal = ...\n",
    "# upper_right = ...\n",
    "# above_mean = ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ---\n",
    "\n",
    " ## 2.13 Broadcasting - ‡∏Å‡∏≤‡∏£‡∏Ç‡∏¢‡∏≤‡∏¢‡∏°‡∏¥‡∏ï‡∏¥‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥\n",
    "\n",
    " ---\n",
    "\n",
    "\n",
    "\n",
    " **‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ (‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢):**\n",
    "\n",
    "\n",
    "\n",
    " Broadcasting ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÄ‡∏£‡∏≤‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á tensor ‡∏ó‡∏µ‡πà‡∏°‡∏µ shape ‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô‡πÑ‡∏î‡πâ\n",
    "\n",
    "\n",
    "\n",
    " **‡∏Å‡∏é Broadcasting (‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤‡∏à‡∏≤‡∏Å‡∏Ç‡∏ß‡∏≤‡πÑ‡∏õ‡∏ã‡πâ‡∏≤‡∏¢):**\n",
    "\n",
    " 1. ‡∏°‡∏¥‡∏ï‡∏¥‡∏ó‡∏µ‡πà‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ô ‚Üí ‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ\n",
    "\n",
    " 2. ‡∏°‡∏¥‡∏ï‡∏¥‡∏ó‡∏µ‡πà‡∏Ç‡∏ô‡∏≤‡∏î = 1 ‚Üí ‡∏Ç‡∏¢‡∏≤‡∏¢‡πÑ‡∏î‡πâ\n",
    "\n",
    " 3. ‡∏°‡∏¥‡∏ï‡∏¥‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ (‡∏ã‡πâ‡∏≤‡∏¢) ‚Üí ‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô 1\n",
    "\n",
    "\n",
    "\n",
    " **‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á:**\n",
    "\n",
    " - `(3, 4)` + `(4,)` ‚Üí `(3, 4)` + `(1, 4)` ‚Üí `(3, 4)` ‚úì\n",
    "\n",
    " - `(3, 4)` + `(3,)` ‚Üí ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ ‚úó"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Broadcasting ‡∏Å‡∏±‡∏ö scalar\n",
    "x = torch.tensor([1, 2, 3])\n",
    "print(f\"x + 10 = {x + 10}\")  # 10 ‡∏ñ‡∏π‡∏Å‡∏Ç‡∏¢‡∏≤‡∏¢‡πÄ‡∏õ‡πá‡∏ô [10, 10, 10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Broadcasting ‡∏Å‡∏±‡∏ö vector\n",
    "a = torch.ones(3, 4)       # shape: (3, 4)\n",
    "b = torch.tensor([1, 2, 3, 4])  # shape: (4,) ‚Üí (1, 4)\n",
    "\n",
    "result = a + b\n",
    "print(f\"a shape: {a.shape}\")\n",
    "print(f\"b shape: {b.shape}\")\n",
    "print(f\"a + b shape: {result.shape}\")\n",
    "print(f\"‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå:\\n{result}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### üîë ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ Broadcasting: Normalize ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
    "\n",
    "\n",
    "\n",
    " **‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ (‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢):**\n",
    "\n",
    "\n",
    "\n",
    " ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏á: normalize ‡πÅ‡∏ï‡πà‡∏•‡∏∞ column ‡πÉ‡∏´‡πâ‡∏°‡∏µ mean=0, std=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: 5 samples, 3 features\n",
    "data = torch.randn(5, 3)\n",
    "print(f\"‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏¥‡∏ö:\\n{data}\")\n",
    "\n",
    "# ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì mean ‡πÅ‡∏•‡∏∞ std ‡πÅ‡∏ï‡πà‡∏•‡∏∞ column\n",
    "mean = data.mean(dim=0, keepdim=True)  # shape: (1, 3)\n",
    "std = data.std(dim=0, keepdim=True)    # shape: (1, 3)\n",
    "\n",
    "# Normalize ‡∏î‡πâ‡∏ß‡∏¢ broadcasting\n",
    "normalized = (data - mean) / std\n",
    "\n",
    "print(f\"\\n‡∏´‡∏•‡∏±‡∏á normalize:\")\n",
    "print(f\"Mean ‡πÅ‡∏ï‡πà‡∏•‡∏∞ column: {normalized.mean(dim=0)}\")  # ‡∏Ñ‡∏ß‡∏£‡πÉ‡∏Å‡∏•‡πâ 0\n",
    "print(f\"Std ‡πÅ‡∏ï‡πà‡∏•‡∏∞ column: {normalized.std(dim=0)}\")    # ‡∏Ñ‡∏ß‡∏£‡πÉ‡∏Å‡∏•‡πâ 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 2.14 ‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Element-wise\n",
    "\n",
    "\n",
    "\n",
    " **‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ (‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢):**\n",
    "\n",
    "\n",
    "\n",
    " Element-wise operations ‡∏Ñ‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏ó‡∏µ‡∏•‡∏∞‡∏ï‡∏±‡∏ß (‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏ï‡πà‡∏≠‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([1., 2., 3., 4.])\n",
    "b = torch.tensor([2., 2., 2., 2.])\n",
    "\n",
    "print(\"Element-wise Operations:\")\n",
    "print(f\"  a + b = {a + b}\")  # ‡∏ö‡∏ß‡∏Å\n",
    "print(f\"  a - b = {a - b}\")  # ‡∏•‡∏ö\n",
    "print(f\"  a * b = {a * b}\")  # ‡∏Ñ‡∏π‡∏ì (‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà matrix multiply!)\n",
    "print(f\"  a / b = {a / b}\")  # ‡∏´‡∏≤‡∏£\n",
    "print(f\"  a ** b = {a ** b}\")  # ‡∏¢‡∏Å‡∏Å‡∏≥‡∏•‡∏±‡∏á\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ó‡∏≤‡∏á‡∏Ñ‡∏ì‡∏¥‡∏ï‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå\n",
    "print(f\"exp(a) = {torch.exp(a)}\")   # e^x\n",
    "print(f\"log(a) = {torch.log(a)}\")   # ln(x)\n",
    "print(f\"sqrt(a) = {torch.sqrt(a)}\") # ‡∏£‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏≠‡∏á\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 2.15 Reduction Operations - ‡∏Å‡∏≤‡∏£‡∏•‡∏î‡∏°‡∏¥‡∏ï‡∏¥\n",
    "\n",
    "\n",
    "\n",
    " **‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ (‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢):**\n",
    "\n",
    "\n",
    "\n",
    " Reduction operations ‡∏Ñ‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡∏£‡∏ß‡∏°‡∏Ñ‡πà‡∏≤‡∏´‡∏•‡∏≤‡∏¢‡πÜ ‡∏ï‡∏±‡∏ß‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏Ñ‡πà‡∏≤‡πÄ‡∏î‡∏µ‡∏¢‡∏ß ‡πÄ‡∏ä‡πà‡∏ô sum, mean, max\n",
    "\n",
    "\n",
    "\n",
    " **Parameter `dim`:** ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ß‡πà‡∏≤‡∏à‡∏∞ reduce ‡∏ï‡∏≤‡∏°‡∏°‡∏¥‡∏ï‡∏¥‡πÑ‡∏´‡∏ô\n",
    "\n",
    " - `dim=0` = reduce ‡∏ï‡∏≤‡∏°‡πÅ‡∏ñ‡∏ß (‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÄ‡∏´‡∏•‡∏∑‡∏≠ 1 ‡πÅ‡∏ñ‡∏ß)\n",
    "\n",
    " - `dim=1` = reduce ‡∏ï‡∏≤‡∏°‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå (‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÄ‡∏´‡∏•‡∏∑‡∏≠ 1 ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([\n",
    "    [1., 2., 3.],\n",
    "    [4., 5., 6.]\n",
    "])\n",
    "print(f\"Tensor:\\n{x}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î\n",
    "print(f\"sum() ‡∏£‡∏ß‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {x.sum()}\")\n",
    "\n",
    "# Sum ‡∏ï‡∏≤‡∏° dim\n",
    "print(f\"sum(dim=0) ‡∏£‡∏ß‡∏°‡∏ï‡∏≤‡∏°‡πÅ‡∏ñ‡∏ß: {x.sum(dim=0)}\")    # [1+4, 2+5, 3+6]\n",
    "print(f\"sum(dim=1) ‡∏£‡∏ß‡∏°‡∏ï‡∏≤‡∏°‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå: {x.sum(dim=1)}\")  # [1+2+3, 4+5+6]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean, Max, Argmax\n",
    "print(f\"mean() ‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢: {x.mean()}\")\n",
    "print(f\"max() ‡∏Ñ‡πà‡∏≤‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î: {x.max()}\")\n",
    "print(f\"argmax() ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏Ñ‡πà‡∏≤‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î: {x.argmax()}\")  # ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡πÉ‡∏ô flattened array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### keepdim=True - ‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏°‡∏¥‡∏ï‡∏¥‡πÑ‡∏ß‡πâ\n",
    "\n",
    "\n",
    "\n",
    " **‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ (‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢):**\n",
    "\n",
    "\n",
    "\n",
    " `keepdim=True` ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏¢‡∏±‡∏á‡∏Ñ‡∏á‡∏°‡∏¥‡∏ï‡∏¥‡πÄ‡∏î‡∏¥‡∏° (‡πÅ‡∏ï‡πà‡∏Ç‡∏ô‡∏≤‡∏î = 1)\n",
    "\n",
    " ‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö broadcasting ‡πÉ‡∏ô‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ñ‡∏±‡∏î‡πÑ‡∏õ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"‡πÑ‡∏°‡πà‡∏°‡∏µ keepdim: {x.sum(dim=1).shape}\")        # (2,)\n",
    "print(f\"‡∏°‡∏µ keepdim=True: {x.sum(dim=1, keepdim=True).shape}\")  # (2, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 2.16 ‚≠ê Matrix Multiplication - ‡∏Å‡∏≤‡∏£‡∏Ñ‡∏π‡∏ì‡πÄ‡∏°‡∏ó‡∏£‡∏¥‡∏Å‡∏ã‡πå\n",
    "\n",
    "\n",
    "\n",
    " **‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ (‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢):**\n",
    "\n",
    "\n",
    "\n",
    " Matrix multiplication ‡∏Ñ‡∏∑‡∏≠‡∏´‡∏±‡∏ß‡πÉ‡∏à‡∏Ç‡∏≠‡∏á Neural Networks!\n",
    "\n",
    "\n",
    "\n",
    " **‡∏Å‡∏é:** `(m, n) @ (n, p)` ‚Üí `(m, p)`\n",
    "\n",
    " - ‡∏°‡∏¥‡∏ï‡∏¥‡∏î‡πâ‡∏≤‡∏ô‡πÉ‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ô (n)\n",
    "\n",
    " - ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏°‡∏µ‡∏Ç‡∏ô‡∏≤‡∏î (‡∏°‡∏¥‡∏ï‡∏¥‡∏ã‡πâ‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á‡∏ï‡∏±‡∏ß‡πÅ‡∏£‡∏Å, ‡∏°‡∏¥‡∏ï‡∏¥‡∏Ç‡∏ß‡∏≤‡∏Ç‡∏≠‡∏á‡∏ï‡∏±‡∏ß‡∏´‡∏•‡∏±‡∏á)\n",
    "\n",
    "\n",
    "\n",
    " **‡∏ß‡∏¥‡∏ò‡∏µ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô (3 ‡∏ß‡∏¥‡∏ò‡∏µ ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ô‡∏´‡∏°‡∏î):**\n",
    "\n",
    " - `A @ B` - ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥! ‡∏≠‡πà‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢\n",
    "\n",
    " - `torch.matmul(A, B)` - ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô\n",
    "\n",
    " - `torch.mm(A, B)` - ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö 2D ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.randn(2, 3)  # 2 ‡πÅ‡∏ñ‡∏ß, 3 ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå\n",
    "B = torch.randn(3, 4)  # 3 ‡πÅ‡∏ñ‡∏ß, 4 ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå\n",
    "\n",
    "# Matrix multiplication\n",
    "C = A @ B  # (2, 3) @ (3, 4) ‚Üí (2, 4)\n",
    "\n",
    "print(f\"A shape: {A.shape}\")\n",
    "print(f\"B shape: {B.shape}\")\n",
    "print(f\"A @ B shape: {C.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Batch Matrix Multiplication\n",
    "\n",
    "\n",
    "\n",
    " **‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ (‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢):**\n",
    "\n",
    "\n",
    "\n",
    " ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏°‡∏µ‡∏´‡∏•‡∏≤‡∏¢ matrix ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Ñ‡∏π‡∏ì‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô (‡πÄ‡∏ä‡πà‡∏ô batch ‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 32 ‡∏Ñ‡∏π‡πà‡∏Ç‡∏≠‡∏á matrix ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Ñ‡∏π‡∏ì‡∏Å‡∏±‡∏ô\n",
    "batch_A = torch.randn(32, 4, 5)  # 32 matrices ‡∏Ç‡∏ô‡∏≤‡∏î 4√ó5\n",
    "batch_B = torch.randn(32, 5, 3)  # 32 matrices ‡∏Ç‡∏ô‡∏≤‡∏î 5√ó3\n",
    "\n",
    "batch_C = batch_A @ batch_B  # 32 matrices ‡∏Ç‡∏ô‡∏≤‡∏î 4√ó3\n",
    "print(f\"Batch matmul: {batch_A.shape} @ {batch_B.shape} = {batch_C.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 2.17 Concatenate ‡πÅ‡∏•‡∏∞ Stack\n",
    "\n",
    "\n",
    "\n",
    " **‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ (‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢):**\n",
    "\n",
    "\n",
    "\n",
    " - `torch.cat()` - ‡∏ï‡πà‡∏≠ tensor ‡∏ï‡∏≤‡∏°‡∏°‡∏¥‡∏ï‡∏¥‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î (‡πÑ‡∏°‡πà‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏°‡∏¥‡∏ï‡∏¥‡πÉ‡∏´‡∏°‡πà)\n",
    "\n",
    " - `torch.stack()` - ‡∏ã‡πâ‡∏≠‡∏ô tensor ‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏¥‡∏ï‡∏¥‡πÉ‡∏´‡∏°‡πà"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.ones(2, 3)\n",
    "b = torch.zeros(2, 3)\n",
    "\n",
    "# Concatenate ‡∏ï‡∏≤‡∏° dim=0 (‡∏ï‡πà‡∏≠‡πÅ‡∏ô‡∏ß‡∏ï‡∏±‡πâ‡∏á)\n",
    "cat_dim0 = torch.cat([a, b], dim=0)\n",
    "print(f\"cat(dim=0): {cat_dim0.shape}\")  # (4, 3)\n",
    "print(f\"‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå:\\n{cat_dim0}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate ‡∏ï‡∏≤‡∏° dim=1 (‡∏ï‡πà‡∏≠‡πÅ‡∏ô‡∏ß‡∏ô‡∏≠‡∏ô)\n",
    "cat_dim1 = torch.cat([a, b], dim=1)\n",
    "print(f\"cat(dim=1): {cat_dim1.shape}\")  # (2, 6)\n",
    "print(f\"‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå:\\n{cat_dim1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack (‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏°‡∏¥‡∏ï‡∏¥‡πÉ‡∏´‡∏°‡πà)\n",
    "stacked = torch.stack([a, b], dim=0)\n",
    "print(f\"stack(dim=0): {stacked.shape}\")  # (2, 2, 3)\n",
    "print(f\"‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå:\\n{stacked}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## ‚úèÔ∏è ‡πÅ‡∏ö‡∏ö‡∏ù‡∏∂‡∏Å‡∏´‡∏±‡∏î 2.2: Implement Functions\n",
    "\n",
    "\n",
    "\n",
    " **‡πÇ‡∏à‡∏ó‡∏¢‡πå A:** Implement Softmax\n",
    "\n",
    "\n",
    "\n",
    " ‡∏™‡∏π‡∏ï‡∏£: `softmax(x) = exp(x) / sum(exp(x))`\n",
    "\n",
    "\n",
    "\n",
    " **‡πÄ‡∏Ñ‡∏•‡πá‡∏î‡∏•‡∏±‡∏ö:** ‡∏•‡∏ö‡∏Ñ‡πà‡∏≤ max ‡∏Å‡πà‡∏≠‡∏ô exp ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô numerical overflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x, dim=-1):\n",
    "    \"\"\"\n",
    "    ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì softmax ‡∏ï‡∏≤‡∏°‡∏°‡∏¥‡∏ï‡∏¥‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î\n",
    "    \n",
    "    Args:\n",
    "        x: input tensor\n",
    "        dim: ‡∏°‡∏¥‡∏ï‡∏¥‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì softmax (default=-1 ‡∏Ñ‡∏∑‡∏≠‡∏°‡∏¥‡∏ï‡∏¥‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢)\n",
    "    \n",
    "    Returns:\n",
    "        tensor ‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô softmax ‡πÅ‡∏•‡πâ‡∏ß (‡∏ú‡∏•‡∏£‡∏ß‡∏°‡∏ï‡∏≤‡∏° dim = 1)\n",
    "    \"\"\"\n",
    "    # ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà (YOUR CODE HERE)\n",
    "    pass\n",
    "\n",
    "# ‡∏ó‡∏î‡∏™‡∏≠‡∏ö:\n",
    "# x = torch.tensor([[1., 2., 3.], [1., 1., 1.]])\n",
    "# print(softmax(x))  # ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÅ‡∏ñ‡∏ß‡∏Ñ‡∏ß‡∏£‡∏£‡∏ß‡∏°‡πÄ‡∏õ‡πá‡∏ô 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **‡πÇ‡∏à‡∏ó‡∏¢‡πå B:** Implement Batch Cosine Similarity\n",
    "\n",
    "\n",
    "\n",
    " ‡∏™‡∏π‡∏ï‡∏£: `cos_sim(a, b) = (a ¬∑ b) / (||a|| √ó ||b||)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_cosine_similarity(a, b):\n",
    "    \"\"\"\n",
    "    ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì cosine similarity ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á vector ‡∏Ñ‡∏π‡πà‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô\n",
    "    \n",
    "    Args:\n",
    "        a: tensor shape (batch, features)\n",
    "        b: tensor shape (batch, features)\n",
    "    \n",
    "    Returns:\n",
    "        tensor shape (batch,) ‡∏Ñ‡πà‡∏≤ similarity ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ñ‡∏π‡πà\n",
    "    \"\"\"\n",
    "    # ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà (YOUR CODE HERE)\n",
    "    pass\n",
    "\n",
    "# ‡∏ó‡∏î‡∏™‡∏≠‡∏ö:\n",
    "# a = torch.tensor([[1., 0., 0.], [1., 1., 0.]])\n",
    "# b = torch.tensor([[1., 0., 0.], [0., 1., 0.]])\n",
    "# print(batch_cosine_similarity(a, b))  # ‡∏Ñ‡∏ß‡∏£‡πÑ‡∏î‡πâ [1.0, 0.707...]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ---\n",
    "\n",
    " # üéØ Module 3: Autograd - ‡∏´‡∏±‡∏ß‡πÉ‡∏à‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ\n",
    "\n",
    " ---\n",
    "\n",
    "\n",
    "\n",
    " **Autograd ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£?**\n",
    "\n",
    "\n",
    "\n",
    " Autograd (Automatic Differentiation) ‡∏Ñ‡∏∑‡∏≠‡∏£‡∏∞‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì gradient ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥\n",
    "\n",
    " ‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏±‡∏ß‡πÉ‡∏à‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡πÉ‡∏´‡πâ Deep Learning ‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏õ‡πÑ‡∏î‡πâ!\n",
    "\n",
    "\n",
    "\n",
    " **‡∏ó‡∏≥‡πÑ‡∏°‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ Gradient?**\n",
    "\n",
    "\n",
    "\n",
    " ‡∏Å‡∏≤‡∏£ train neural network ‡πÉ‡∏ä‡πâ Gradient Descent:\n",
    "\n",
    " 1. ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì prediction\n",
    "\n",
    " 2. ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì loss (error)\n",
    "\n",
    " 3. ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì gradient ‡∏Ç‡∏≠‡∏á loss ‡∏ï‡πà‡∏≠ parameters\n",
    "\n",
    " 4. ‡∏õ‡∏£‡∏±‡∏ö parameters: `param = param - learning_rate √ó gradient`\n",
    "\n",
    "\n",
    "\n",
    " Autograd ‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏ô‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 3 ‡πÇ‡∏î‡∏¢‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 3.1 requires_grad - ‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô Gradient Tracking\n",
    "\n",
    "\n",
    "\n",
    " **‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ (‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢):**\n",
    "\n",
    "\n",
    "\n",
    " ‡πÇ‡∏î‡∏¢‡∏õ‡∏Å‡∏ï‡∏¥ tensor ‡∏à‡∏∞‡πÑ‡∏°‡πà‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏° gradient (‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥)\n",
    "\n",
    " ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡∏¥‡∏î‡∏î‡πâ‡∏ß‡∏¢ `requires_grad=True` ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ autograd ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏õ‡∏Å‡∏ï‡∏¥ tensor ‡πÑ‡∏°‡πà track gradient\n",
    "x = torch.tensor([1., 2., 3.])\n",
    "print(f\"requires_grad (default): {x.requires_grad}\")  # False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡πÄ‡∏õ‡∏¥‡∏î gradient tracking\n",
    "x = torch.tensor([1., 2., 3.], requires_grad=True)\n",
    "print(f\"requires_grad (enabled): {x.requires_grad}\")  # True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 3.2 Computation Graph - ‡∏Å‡∏£‡∏≤‡∏ü‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì\n",
    "\n",
    "\n",
    "\n",
    " **‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ (‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢):**\n",
    "\n",
    "\n",
    "\n",
    " ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏≤‡∏ó‡∏≥ operation ‡∏Å‡∏±‡∏ö tensor ‡∏ó‡∏µ‡πà‡∏°‡∏µ `requires_grad=True`\n",
    "\n",
    " PyTorch ‡∏à‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á \"computation graph\" ‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ß‡πâ\n",
    "\n",
    "\n",
    "\n",
    " ‡∏Å‡∏£‡∏≤‡∏ü‡∏ô‡∏µ‡πâ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ß‡πà‡∏≤:\n",
    "\n",
    " - ‡∏Ñ‡πà‡∏≤‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ï‡∏±‡∏ß‡∏°‡∏≤‡∏à‡∏≤‡∏Å operation ‡∏≠‡∏∞‡πÑ‡∏£\n",
    "\n",
    " - ‡∏ï‡πâ‡∏≠‡∏á‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì gradient ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([2.0], requires_grad=True)\n",
    "\n",
    "# Forward pass: y = x¬≤ + 3x + 1\n",
    "y = x ** 2 + 3 * x + 1\n",
    "\n",
    "print(f\"x = {x.item()}\")\n",
    "print(f\"y = x¬≤ + 3x + 1 = {y.item()}\")\n",
    "print(f\"y.grad_fn = {y.grad_fn}\")  # ‡πÅ‡∏™‡∏î‡∏á operation ‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 3.3 backward() - ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Gradient\n",
    "\n",
    "\n",
    "\n",
    " **‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ (‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢):**\n",
    "\n",
    "\n",
    "\n",
    " ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏µ‡∏¢‡∏Å `.backward()` PyTorch ‡∏à‡∏∞‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì gradient ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥\n",
    "\n",
    " ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ß‡πâ‡πÉ‡∏ô `.grad` ‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞ tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([2.0], requires_grad=True)\n",
    "y = x ** 2 + 3 * x + 1\n",
    "\n",
    "# ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì gradient\n",
    "y.backward()\n",
    "\n",
    "# ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÄ‡∏Å‡πá‡∏ö‡πÉ‡∏ô x.grad\n",
    "print(f\"x = {x.item()}\")\n",
    "print(f\"y = {y.item()}\")\n",
    "print(f\"dy/dx = {x.grad.item()}\")\n",
    "\n",
    "# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö: dy/dx = 2x + 3 = 2(2) + 3 = 7 ‚úì\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 3.4 Gradient ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Vector Output\n",
    "\n",
    "\n",
    "\n",
    " **‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ (‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢):**\n",
    "\n",
    "\n",
    "\n",
    " ‡∏ñ‡πâ‡∏≤ output ‡πÄ‡∏õ‡πá‡∏ô vector (‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà scalar) ‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏∏ \"upstream gradient\"\n",
    "\n",
    " ‡πÉ‡∏ô‡∏ó‡∏≤‡∏á‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥ ‡πÄ‡∏£‡∏≤‡∏°‡∏±‡∏Å‡∏à‡∏∞ reduce ‡πÄ‡∏õ‡πá‡∏ô scalar ‡∏Å‡πà‡∏≠‡∏ô (‡πÄ‡∏ä‡πà‡∏ô loss function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏Å‡∏£‡∏ì‡∏µ output ‡πÄ‡∏õ‡πá‡∏ô vector\n",
    "x = torch.tensor([1., 2., 3.], requires_grad=True)\n",
    "y = x ** 2  # y ‡πÄ‡∏õ‡πá‡∏ô vector [1, 4, 9]\n",
    "\n",
    "# ‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏∏ upstream gradient\n",
    "upstream = torch.tensor([1., 1., 1.])\n",
    "y.backward(upstream)\n",
    "\n",
    "print(f\"x = {x}\")\n",
    "print(f\"y = x¬≤ = {y}\")\n",
    "print(f\"dy/dx = 2x = {x.grad}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 3.5 Pattern ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏ö‡πà‡∏≠‡∏¢: Reduce ‡πÄ‡∏õ‡πá‡∏ô Scalar\n",
    "\n",
    "\n",
    "\n",
    " **‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ (‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢):**\n",
    "\n",
    "\n",
    "\n",
    " ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£ train ‡∏à‡∏£‡∏¥‡∏á loss ‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô scalar ‡πÄ‡∏™‡∏°‡∏≠\n",
    "\n",
    " ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏∏ upstream gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1., 2., 3.], requires_grad=True)\n",
    "y = (x ** 2).sum()  # Reduce ‡πÄ‡∏õ‡πá‡∏ô scalar: 1 + 4 + 9 = 14\n",
    "\n",
    "y.backward()  # ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏∏ argument\n",
    "\n",
    "print(f\"y = sum(x¬≤) = {y.item()}\")\n",
    "print(f\"dy/dx = 2x = {x.grad}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 3.6 ‚ö†Ô∏è Gradient Accumulation - ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏û‡∏ö‡∏ö‡πà‡∏≠‡∏¢\n",
    "\n",
    "\n",
    "\n",
    " **‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ (‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢):**\n",
    "\n",
    "\n",
    "\n",
    " **‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏°‡∏≤‡∏Å!** Gradient ‡∏à‡∏∞ **‡∏™‡∏∞‡∏™‡∏°** (accumulate) ‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏Å backward()\n",
    "\n",
    " ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà clear ‡∏à‡∏∞‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏Ñ‡πà‡∏≤ gradient ‡∏ú‡∏¥‡∏î!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1., 2., 3.], requires_grad=True)\n",
    "\n",
    "# backward ‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà 1\n",
    "y1 = (x ** 2).sum()\n",
    "y1.backward()\n",
    "print(f\"‡∏´‡∏•‡∏±‡∏á backward ‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà 1: {x.grad}\")  # [2, 4, 6]\n",
    "\n",
    "# backward ‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà 2 - gradient ‡∏™‡∏∞‡∏™‡∏°!\n",
    "y2 = (x ** 3).sum()\n",
    "y2.backward()\n",
    "print(f\"‡∏´‡∏•‡∏±‡∏á backward ‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà 2: {x.grad}\")  # [2+3, 4+12, 6+27] = [5, 16, 33]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 3.7 ‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ: Zero Gradients ‡∏Å‡πà‡∏≠‡∏ô backward\n",
    "\n",
    "\n",
    "\n",
    " **‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ (‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢):**\n",
    "\n",
    "\n",
    "\n",
    " ‡∏ï‡πâ‡∏≠‡∏á clear gradient ‡∏Å‡πà‡∏≠‡∏ô‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà‡∏à‡∏∞ backward ‡πÉ‡∏´‡∏°‡πà"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1., 2., 3.], requires_grad=True)\n",
    "\n",
    "# backward ‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà 1\n",
    "y1 = (x ** 2).sum()\n",
    "y1.backward()\n",
    "print(f\"Gradient 1: {x.grad}\")\n",
    "\n",
    "# üîë Clear gradient!\n",
    "x.grad.zero_()\n",
    "\n",
    "# backward ‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà 2\n",
    "y2 = (x ** 3).sum()\n",
    "y2.backward()\n",
    "print(f\"Gradient 2 (‡∏´‡∏•‡∏±‡∏á clear): {x.grad}\")  # ‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏•‡πâ‡∏ß\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 3.8 torch.no_grad() - ‡∏õ‡∏¥‡∏î Gradient Tracking\n",
    "\n",
    "\n",
    "\n",
    " **‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ (‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢):**\n",
    "\n",
    "\n",
    "\n",
    " ‡∏ï‡∏≠‡∏ô inference (‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•) ‡πÄ‡∏£‡∏≤‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ gradient\n",
    "\n",
    " ‡∏Å‡∏≤‡∏£‡∏õ‡∏¥‡∏î gradient ‡∏ó‡∏≥‡πÉ‡∏´‡πâ:\n",
    "\n",
    " - **‡πÄ‡∏£‡πá‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô** - ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á computation graph\n",
    "\n",
    " - **‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥** - ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏Å‡πá‡∏ö intermediate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1., 2., 3.], requires_grad=True)\n",
    "\n",
    "# ‡∏õ‡∏Å‡∏ï‡∏¥: ‡∏°‡∏µ gradient tracking\n",
    "y = x ** 2\n",
    "print(f\"‡∏õ‡∏Å‡∏ï‡∏¥ - requires_grad: {y.requires_grad}\")\n",
    "\n",
    "# ‡πÉ‡∏ô no_grad: ‡πÑ‡∏°‡πà‡∏°‡∏µ gradient tracking\n",
    "with torch.no_grad():\n",
    "    z = x ** 2\n",
    "    print(f\"‡πÉ‡∏ô no_grad - requires_grad: {z.requires_grad}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 3.9 Pattern: Evaluation Mode\n",
    "\n",
    "\n",
    "\n",
    " **‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ (‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢):**\n",
    "\n",
    "\n",
    "\n",
    " ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡πÉ‡∏ô‡∏Å‡∏≤‡∏£ evaluate ‡πÇ‡∏°‡πÄ‡∏î‡∏•:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data):\n",
    "    \"\"\"\n",
    "    ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á\n",
    "    \"\"\"\n",
    "    model.eval()           # ‡∏ï‡∏±‡πâ‡∏á‡πÄ‡∏õ‡πá‡∏ô evaluation mode\n",
    "    with torch.no_grad():  # ‡∏õ‡∏¥‡∏î gradient\n",
    "        outputs = model(data)\n",
    "    return outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 3.10 detach() - ‡∏ï‡∏±‡∏î Tensor ‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å Graph\n",
    "\n",
    "\n",
    "\n",
    " **‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ (‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢):**\n",
    "\n",
    "\n",
    "\n",
    " `detach()` ‡∏™‡∏£‡πâ‡∏≤‡∏á tensor ‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏Å‡∏±‡∏ö computation graph\n",
    "\n",
    " ‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ gradient ‡πÑ‡∏´‡∏•‡∏ú‡πà‡∏≤‡∏ô"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1., 2., 3.], requires_grad=True)\n",
    "y = x ** 2\n",
    "\n",
    "# detach ‡∏™‡∏£‡πâ‡∏≤‡∏á tensor ‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ grad\n",
    "z = y.detach()\n",
    "\n",
    "print(f\"y.requires_grad: {y.requires_grad}\")\n",
    "print(f\"z.requires_grad: {z.requires_grad}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 3.11 Gradient Clipping - ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô Exploding Gradients\n",
    "\n",
    "\n",
    "\n",
    " **‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ (‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢):**\n",
    "\n",
    "\n",
    "\n",
    " ‡∏ö‡∏≤‡∏á‡∏Ñ‡∏£‡∏±‡πâ‡∏á gradient ‡∏°‡∏µ‡∏Ñ‡πà‡∏≤‡∏™‡∏π‡∏á‡∏°‡∏≤‡∏Å (exploding gradients)\n",
    "\n",
    " ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏Å‡∏≤‡∏£ train ‡πÑ‡∏°‡πà‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£\n",
    "\n",
    "\n",
    "\n",
    " **‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ:** ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ç‡∏ô‡∏≤‡∏î‡∏Ç‡∏≠‡∏á gradient\n",
    "\n",
    " - `clip_grad_norm_()` - ‡∏à‡∏≥‡∏Å‡∏±‡∏î L2 norm ‡∏£‡∏ß‡∏° (‡∏ô‡∏¥‡∏¢‡∏°‡πÉ‡∏ä‡πâ)\n",
    "\n",
    " - `clip_grad_value_()` - ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ñ‡πà‡∏≤‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ï‡∏±‡∏ß"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á parameters ‡∏ó‡∏µ‡πà‡∏°‡∏µ gradient ‡∏™‡∏π‡∏á\n",
    "params = torch.tensor([1., 2., 3.], requires_grad=True)\n",
    "loss = (params ** 4).sum()  # Gradient ‡∏à‡∏∞‡∏™‡∏π‡∏á‡∏°‡∏≤‡∏Å\n",
    "loss.backward()\n",
    "\n",
    "print(f\"Gradient ‡πÄ‡∏î‡∏¥‡∏°: {params.grad}\")\n",
    "print(f\"Gradient norm: {params.grad.norm():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Clip by Norm (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = torch.tensor([1., 2., 3.], requires_grad=True)\n",
    "loss = (params ** 4).sum()\n",
    "loss.backward()\n",
    "\n",
    "max_norm = 1.0\n",
    "torch.nn.utils.clip_grad_norm_([params], max_norm)\n",
    "\n",
    "print(f\"‡∏´‡∏•‡∏±‡∏á clip by norm (max=1.0):\")\n",
    "print(f\"  Gradient: {params.grad}\")\n",
    "print(f\"  Norm: {params.grad.norm():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## ‚úèÔ∏è ‡πÅ‡∏ö‡∏ö‡∏ù‡∏∂‡∏Å‡∏´‡∏±‡∏î 3.1: ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Gradient ‡∏î‡πâ‡∏ß‡∏¢‡∏°‡∏∑‡∏≠\n",
    "\n",
    "\n",
    "\n",
    " **‡πÇ‡∏à‡∏ó‡∏¢‡πå:** ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ autograd ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì gradient ‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á\n",
    "\n",
    "\n",
    "\n",
    " ‡πÉ‡∏´‡πâ `g(x) = sin(x) √ó exp(-x)` ‡∏ó‡∏µ‡πà x = 1\n",
    "\n",
    "\n",
    "\n",
    " ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì gradient ‡∏î‡πâ‡∏ß‡∏¢ autograd ‡πÅ‡∏•‡πâ‡∏ß‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö analytical solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á: f(x) = x¬≥ - 2x¬≤ + x\n",
    "def f(x):\n",
    "    return x**3 - 2*x**2 + x\n",
    "\n",
    "def df_dx_analytical(x):\n",
    "    \"\"\"Analytical derivative: f'(x) = 3x¬≤ - 4x + 1\"\"\"\n",
    "    return 3*x**2 - 4*x + 1\n",
    "\n",
    "# ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏ó‡∏µ‡πà x = 2\n",
    "x = torch.tensor([2.0], requires_grad=True)\n",
    "y = f(x)\n",
    "y.backward()\n",
    "\n",
    "print(f\"Autograd df/dx ‡∏ó‡∏µ‡πà x=2: {x.grad.item()}\")\n",
    "print(f\"Analytical df/dx ‡∏ó‡∏µ‡πà x=2: {df_dx_analytical(2.0)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡πÇ‡∏à‡∏ó‡∏¢‡πå‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì: g(x) = sin(x) √ó exp(-x) ‡∏ó‡∏µ‡πà x = 1\n",
    "# ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà (YOUR CODE HERE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ---\n",
    "\n",
    " # üèóÔ∏è Module 4: Neural Network Building Blocks\n",
    "\n",
    " ---\n",
    "\n",
    "\n",
    "\n",
    " ‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏£‡∏≤‡∏°‡∏≤‡∏™‡∏£‡πâ‡∏≤‡∏á Neural Network ‡∏à‡∏£‡∏¥‡∏á‡πÜ ‡∏Å‡∏±‡∏ô!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 4.1 nn.Module - ‡∏Ñ‡∏•‡∏≤‡∏™‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á Neural Networks\n",
    "\n",
    "\n",
    "\n",
    " **‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ (‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢):**\n",
    "\n",
    "\n",
    "\n",
    " `nn.Module` ‡∏Ñ‡∏∑‡∏≠ base class ‡∏Ç‡∏≠‡∏á‡∏ó‡∏∏‡∏Å neural network ‡πÉ‡∏ô PyTorch\n",
    "\n",
    "\n",
    "\n",
    " **‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô:**\n",
    "\n",
    " 1. `__init__()` - ‡∏Å‡∏≥‡∏´‡∏ô‡∏î layers\n",
    "\n",
    " 2. `forward()` - ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Å‡∏≤‡∏£‡πÑ‡∏´‡∏•‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Neural Network ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏á‡πà‡∏≤‡∏¢\n",
    "    \n",
    "    ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á:\n",
    "    Input ‚Üí Linear ‚Üí ReLU ‚Üí Linear ‚Üí Output\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()  # ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç! ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏Å parent __init__\n",
    "        \n",
    "        # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î layers\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)   # Fully Connected 1\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)  # Fully Connected 2\n",
    "        self.relu = nn.ReLU()                           # Activation\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Å‡∏≤‡∏£‡πÑ‡∏´‡∏•‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\"\"\"\n",
    "        x = self.fc1(x)   # Linear: y = Wx + b\n",
    "        x = self.relu(x)  # Activation: max(0, x)\n",
    "        x = self.fc2(x)   # Linear ‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á\n",
    "        return x\n",
    "\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á model\n",
    "model = SimpleNet(input_size=10, hidden_size=32, output_size=5)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 4.2 ‡∏î‡∏π Parameters ‡∏Ç‡∏≠‡∏á Model\n",
    "\n",
    "\n",
    "\n",
    " **‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ (‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢):**\n",
    "\n",
    "\n",
    "\n",
    " Model ‡∏°‡∏µ parameters (weights ‡πÅ‡∏•‡∏∞ biases) ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìä Model Parameters:\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"  {name}: {param.shape}\")\n",
    "\n",
    "# ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô parameters ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"\\nüìà Total parameters: {total_params:,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 4.3 Forward Pass - ‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ú‡πà‡∏≤‡∏ô Model\n",
    "\n",
    "\n",
    "\n",
    " **‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ (‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢):**\n",
    "\n",
    "\n",
    "\n",
    " ‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡πÅ‡∏Ñ‡πà \"‡πÄ‡∏£‡∏µ‡∏¢‡∏Å\" model ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô\n",
    "\n",
    " PyTorch ‡∏à‡∏∞‡πÄ‡∏£‡∏µ‡∏¢‡∏Å `forward()` ‡πÉ‡∏´‡πâ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á input: batch=4, features=10\n",
    "x = torch.randn(4, 10)\n",
    "\n",
    "# Forward pass (‡πÄ‡∏£‡∏µ‡∏¢‡∏Å model ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô)\n",
    "output = model(x)\n",
    "\n",
    "print(f\"Input shape: {x.shape}\")     # (4, 10)\n",
    "print(f\"Output shape: {output.shape}\") # (4, 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 4.4 ‡∏¢‡πâ‡∏≤‡∏¢ Model ‡πÑ‡∏õ GPU\n",
    "\n",
    "\n",
    "\n",
    " **‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ (‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢):**\n",
    "\n",
    "\n",
    "\n",
    " ‡πÉ‡∏ä‡πâ `.to(device)` ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô tensor\n",
    "\n",
    " ‡∏à‡∏∞‡∏¢‡πâ‡∏≤‡∏¢ parameters ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÑ‡∏õ device ‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "print(f\"Model ‡∏≠‡∏¢‡∏π‡πà‡∏ö‡∏ô: {next(model.parameters()).device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ---\n",
    "\n",
    " ## 4.5 Common Layers - Layers ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏ö‡πà‡∏≠‡∏¢\n",
    "\n",
    " ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Linear Layer (Fully Connected)\n",
    "\n",
    "\n",
    "\n",
    " **‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ (‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢):**\n",
    "\n",
    "\n",
    "\n",
    " `nn.Linear(in_features, out_features)` ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì `y = xW^T + b`\n",
    "\n",
    " - `W` shape: (out_features, in_features)\n",
    "\n",
    " - `b` shape: (out_features,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = nn.Linear(in_features=10, out_features=5)\n",
    "\n",
    "print(f\"Linear layer: {linear}\")\n",
    "print(f\"  Weight shape: {linear.weight.shape}\")  # (5, 10)\n",
    "print(f\"  Bias shape: {linear.bias.shape}\")      # (5,)\n",
    "\n",
    "# ‡∏ó‡∏î‡∏™‡∏≠‡∏ö\n",
    "x = torch.randn(3, 10)  # batch=3\n",
    "y = linear(x)\n",
    "print(f\"\\n  Input: {x.shape} ‚Üí Output: {y.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Embedding Layer\n",
    "\n",
    "\n",
    "\n",
    " **‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ (‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢):**\n",
    "\n",
    "\n",
    "\n",
    " `nn.Embedding` ‡πÅ‡∏õ‡∏•‡∏á integer indices ‡πÄ‡∏õ‡πá‡∏ô dense vectors\n",
    "\n",
    " ‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö NLP (‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡∏≥‡πÄ‡∏õ‡πá‡∏ô vector) ‡∏´‡∏£‡∏∑‡∏≠ categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 1000       # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏≥‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î\n",
    "embedding_dim = 64      # ‡∏Ç‡∏ô‡∏≤‡∏î‡∏Ç‡∏≠‡∏á embedding vector\n",
    "\n",
    "embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "# Input: indices ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏≥ (integers)\n",
    "word_indices = torch.tensor([1, 45, 999, 0, 123])\n",
    "embedded = embedding(word_indices)\n",
    "\n",
    "print(f\"Embedding: {vocab_size} ‡∏Ñ‡∏≥ ‚Üí {embedding_dim} ‡∏°‡∏¥‡∏ï‡∏¥\")\n",
    "print(f\"Input: {word_indices.shape} ‚Üí Output: {embedded.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Conv2d (Preview)\n",
    "\n",
    "\n",
    "\n",
    " **‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ (‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢):**\n",
    "\n",
    "\n",
    "\n",
    " Convolutional layer ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö image processing\n",
    "\n",
    " ‡∏à‡∏∞‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏•‡∏∂‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô‡πÉ‡∏ô lab ‡∏ñ‡∏±‡∏î‡πÑ‡∏õ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = nn.Conv2d(\n",
    "    in_channels=3,      # RGB = 3 channels\n",
    "    out_channels=16,    # ‡∏™‡∏£‡πâ‡∏≤‡∏á 16 feature maps\n",
    "    kernel_size=3,      # ‡∏Ç‡∏ô‡∏≤‡∏î filter 3√ó3\n",
    "    padding=1           # ‡πÄ‡∏û‡∏¥‡πà‡∏° padding ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏Ç‡∏ô‡∏≤‡∏î\n",
    ")\n",
    "\n",
    "# Input: batch=1, channels=3, height=32, width=32\n",
    "image = torch.randn(1, 3, 32, 32)\n",
    "features = conv(image)\n",
    "\n",
    "print(f\"Conv2d: 3 channels ‚Üí 16 features\")\n",
    "print(f\"Input: {image.shape} ‚Üí Output: {features.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ---\n",
    "\n",
    " ## 4.6 Activation Functions - ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏Å‡∏£‡∏∞‡∏ï‡∏∏‡πâ‡∏ô\n",
    "\n",
    " ---\n",
    "\n",
    "\n",
    "\n",
    " **‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ (‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢):**\n",
    "\n",
    "\n",
    "\n",
    " Activation functions ‡∏™‡∏£‡πâ‡∏≤‡∏á non-linearity ‡πÉ‡∏´‡πâ neural network\n",
    "\n",
    " ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ activation function, network ‡∏´‡∏•‡∏≤‡∏¢‡∏ä‡∏±‡πâ‡∏ô‡∏Å‡πá‡πÑ‡∏°‡πà‡∏ï‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å‡∏ä‡∏±‡πâ‡∏ô‡πÄ‡∏î‡∏µ‡∏¢‡∏ß!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### ReLU - Rectified Linear Unit\n",
    "\n",
    "\n",
    "\n",
    " ‡∏™‡∏π‡∏ï‡∏£: `max(0, x)`\n",
    "\n",
    " - ‡∏ñ‡πâ‡∏≤ x > 0 ‚Üí ‡∏Ñ‡∏∑‡∏ô x\n",
    "\n",
    " - ‡∏ñ‡πâ‡∏≤ x ‚â§ 0 ‚Üí ‡∏Ñ‡∏∑‡∏ô 0\n",
    "\n",
    "\n",
    "\n",
    " **‡∏Ç‡πâ‡∏≠‡∏î‡∏µ:** ‡∏á‡πà‡∏≤‡∏¢, ‡πÄ‡∏£‡πá‡∏ß, ‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ô‡πÅ‡∏û‡∏£‡πà‡∏´‡∏•‡∏≤‡∏¢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relu = nn.ReLU()\n",
    "x = torch.tensor([-2., -1., 0., 1., 2.])\n",
    "print(f\"Input: {x}\")\n",
    "print(f\"ReLU: {relu(x)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Sigmoid\n",
    "\n",
    "\n",
    "\n",
    " ‡∏™‡∏π‡∏ï‡∏£: `1 / (1 + e^(-x))`\n",
    "\n",
    " - Output ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á (0, 1)\n",
    "\n",
    " - ‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö probability, binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid = nn.Sigmoid()\n",
    "x = torch.tensor([-2., -1., 0., 1., 2.])\n",
    "print(f\"Input: {x}\")\n",
    "print(f\"Sigmoid: {sigmoid(x)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Tanh\n",
    "\n",
    "\n",
    "\n",
    " ‡∏™‡∏π‡∏ï‡∏£: `(e^x - e^(-x)) / (e^x + e^(-x))`\n",
    "\n",
    " - Output ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á (-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tanh = nn.Tanh()\n",
    "x = torch.tensor([-2., -1., 0., 1., 2.])\n",
    "print(f\"Input: {x}\")\n",
    "print(f\"Tanh: {tanh(x)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Visualize Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.linspace(-5, 5, 100)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 8))\n",
    "\n",
    "# ReLU\n",
    "axes[0, 0].plot(x, nn.ReLU()(x))\n",
    "axes[0, 0].set_title(\"ReLU: max(0, x)\")\n",
    "axes[0, 0].grid(True)\n",
    "axes[0, 0].axhline(y=0, color='k', linewidth=0.5)\n",
    "axes[0, 0].axvline(x=0, color='k', linewidth=0.5)\n",
    "\n",
    "# Sigmoid\n",
    "axes[0, 1].plot(x, nn.Sigmoid()(x))\n",
    "axes[0, 1].set_title(\"Sigmoid: 1/(1+e^-x)\")\n",
    "axes[0, 1].grid(True)\n",
    "axes[0, 1].axhline(y=0.5, color='r', linestyle='--', linewidth=0.5)\n",
    "\n",
    "# Tanh\n",
    "axes[1, 0].plot(x, nn.Tanh()(x))\n",
    "axes[1, 0].set_title(\"Tanh: (e^x - e^-x)/(e^x + e^-x)\")\n",
    "axes[1, 0].grid(True)\n",
    "axes[1, 0].axhline(y=0, color='k', linewidth=0.5)\n",
    "\n",
    "# GELU (‡πÉ‡∏ä‡πâ‡πÉ‡∏ô Transformers)\n",
    "axes[1, 1].plot(x, nn.GELU()(x))\n",
    "axes[1, 1].set_title(\"GELU\")\n",
    "axes[1, 1].grid(True)\n",
    "axes[1, 1].axhline(y=0, color='k', linewidth=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Softmax - ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô Probability Distribution\n",
    "\n",
    "\n",
    "\n",
    " **‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ (‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢):**\n",
    "\n",
    "\n",
    "\n",
    " Softmax ‡πÅ‡∏õ‡∏•‡∏á logits (raw scores) ‡πÄ‡∏õ‡πá‡∏ô probabilities ‡∏ó‡∏µ‡πà‡∏£‡∏ß‡∏°‡∏Å‡∏±‡∏ô‡πÑ‡∏î‡πâ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = torch.tensor([[2.0, 1.0, 0.1]])\n",
    "\n",
    "softmax = nn.Softmax(dim=1)\n",
    "probs = softmax(logits)\n",
    "\n",
    "print(f\"Logits: {logits}\")\n",
    "print(f\"Probabilities: {probs}\")\n",
    "print(f\"‡∏ú‡∏•‡∏£‡∏ß‡∏°: {probs.sum().item()}\")  # ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ---\n",
    "\n",
    " ## 4.7 Loss Functions - ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ß‡∏±‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î\n",
    "\n",
    " ---\n",
    "\n",
    "\n",
    "\n",
    " **‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ (‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢):**\n",
    "\n",
    "\n",
    "\n",
    " Loss function ‡∏ß‡∏±‡∏î‡∏ß‡πà‡∏≤ prediction ‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤‡∏´‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å target ‡∏°‡∏≤‡∏Å‡πÅ‡∏Ñ‡πà‡πÑ‡∏´‡∏ô\n",
    "\n",
    " ‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£ train ‡∏Ñ‡∏∑‡∏≠‡∏ó‡∏≥‡πÉ‡∏´‡πâ loss ‡∏ï‡πà‡∏≥‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### MSE Loss - ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Regression\n",
    "\n",
    "\n",
    "\n",
    " ‡∏™‡∏π‡∏ï‡∏£: `mean((prediction - target)¬≤)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = torch.tensor([2.5, 0.0, 2.0])\n",
    "targets = torch.tensor([3.0, 0.0, 2.0])\n",
    "\n",
    "mse_loss = nn.MSELoss()\n",
    "loss = mse_loss(predictions, targets)\n",
    "\n",
    "print(f\"Predictions: {predictions}\")\n",
    "print(f\"Targets: {targets}\")\n",
    "print(f\"MSE Loss: {loss.item():.4f}\")\n",
    "\n",
    "# ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏î‡πâ‡∏ß‡∏¢‡∏°‡∏∑‡∏≠\n",
    "manual_mse = ((predictions - targets) ** 2).mean()\n",
    "print(f\"‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏î‡πâ‡∏ß‡∏¢‡∏°‡∏∑‡∏≠: {manual_mse.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Cross Entropy Loss - ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Multi-class Classification\n",
    "\n",
    "\n",
    "\n",
    " **‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ (‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢):**\n",
    "\n",
    "\n",
    "\n",
    " ‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö classification ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏´‡∏•‡∏≤‡∏¢ class\n",
    "\n",
    "\n",
    "\n",
    " ‚ö†Ô∏è **‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç:** ‡∏£‡∏±‡∏ö **logits** (raw scores) ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà softmax probabilities!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logits = raw scores ‡∏Å‡πà‡∏≠‡∏ô softmax\n",
    "logits = torch.tensor([\n",
    "    [2.0, 1.0, 0.1],   # Sample 1: ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏ó‡∏µ‡πà class 0\n",
    "    [0.1, 0.1, 2.0]    # Sample 2: ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏ó‡∏µ‡πà class 2\n",
    "])\n",
    "\n",
    "# Target class indices\n",
    "targets = torch.tensor([0, 2])  # Sample 1 = class 0, Sample 2 = class 2\n",
    "\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "loss = ce_loss(logits, targets)\n",
    "\n",
    "print(f\"Logits:\\n{logits}\")\n",
    "print(f\"Targets: {targets}\")\n",
    "print(f\"Cross Entropy Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### BCE Loss - ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Binary Classification\n",
    "\n",
    "\n",
    "\n",
    " **‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ (‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢):**\n",
    "\n",
    "\n",
    "\n",
    " ‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö classification 2 class ‡∏´‡∏£‡∏∑‡∏≠ multi-label classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = torch.tensor([0.5, -1.0, 2.0])   # Raw scores\n",
    "targets = torch.tensor([1.0, 0.0, 1.0])   # Binary labels\n",
    "\n",
    "bce_loss = nn.BCEWithLogitsLoss()  # ‡∏£‡∏ß‡∏° Sigmoid + BCELoss\n",
    "loss = bce_loss(logits, targets)\n",
    "\n",
    "print(f\"Logits: {logits}\")\n",
    "print(f\"Targets: {targets}\")\n",
    "print(f\"BCE with Logits Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### üîë ‡∏™‡∏£‡∏∏‡∏õ: ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Loss Function ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£\n",
    "\n",
    "\n",
    "\n",
    " | Task | Loss Function | Output ‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏ö |\n",
    "\n",
    " |------|--------------|--------------|\n",
    "\n",
    " | Regression | MSELoss | ‡∏Ñ‡πà‡∏≤‡πÉ‡∏î‡∏Å‡πá‡πÑ‡∏î‡πâ |\n",
    "\n",
    " | Multi-class (1 label) | CrossEntropyLoss | Logits |\n",
    "\n",
    " | Binary classification | BCEWithLogitsLoss | Logit |\n",
    "\n",
    " | Multi-label | BCEWithLogitsLoss | Logits |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ---\n",
    "\n",
    " ## 4.8 Optimizers - ‡∏ï‡∏±‡∏ß‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡πà‡∏≤ Parameters\n",
    "\n",
    " ---\n",
    "\n",
    "\n",
    "\n",
    " **‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ (‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢):**\n",
    "\n",
    "\n",
    "\n",
    " Optimizer ‡πÉ‡∏ä‡πâ gradient ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡πà‡∏≤ parameters ‡∏Ç‡∏≠‡∏á model\n",
    "\n",
    " ‡∏™‡∏π‡∏ï‡∏£‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô: `new_param = old_param - learning_rate √ó gradient`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á model ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏á‡πà‡∏≤‡∏¢\n",
    "model = nn.Linear(10, 2)\n",
    "\n",
    "# Optimizers ‡∏ï‡πà‡∏≤‡∏á‡πÜ\n",
    "optimizer_sgd = optim.SGD(model.parameters(), lr=0.01)\n",
    "optimizer_adam = optim.Adam(model.parameters(), lr=0.001)\n",
    "optimizer_adamw = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "\n",
    "print(\"Optimizers ‡∏ó‡∏µ‡πà‡∏ô‡∏¥‡∏¢‡∏°:\")\n",
    "print(\"‚Ä¢ SGD - Stochastic Gradient Descent (‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô)\")\n",
    "print(\"‚Ä¢ Adam - Adaptive Moment Estimation (‡∏ô‡∏¥‡∏¢‡∏°‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î)\")\n",
    "print(\"‚Ä¢ AdamW - Adam + Weight Decay (‡∏î‡∏µ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Transformers)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Learning Rate ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£?\n",
    "\n",
    "\n",
    "\n",
    " **‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ (‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢):**\n",
    "\n",
    "\n",
    "\n",
    " Learning rate (lr) ‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡∏Ç‡∏ô‡∏≤‡∏î‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£ update\n",
    "\n",
    " - lr ‡∏™‡∏π‡∏á ‚Üí update ‡πÄ‡∏¢‡∏≠‡∏∞ ‚Üí ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÄ‡∏£‡πá‡∏ß ‡πÅ‡∏ï‡πà‡∏≠‡∏≤‡∏à overshoot\n",
    "\n",
    " - lr ‡∏ï‡πà‡∏≥ ‚Üí update ‡∏ô‡πâ‡∏≠‡∏¢ ‚Üí ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏ä‡πâ‡∏≤ ‡πÅ‡∏ï‡πà‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£‡∏Å‡∏ß‡πà‡∏≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡∏Ç‡∏≠‡∏á learning rate\n",
    "model = nn.Linear(10, 1)\n",
    "original_weight = model.weight.data.clone()\n",
    "\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á gradient\n",
    "x = torch.randn(1, 10)\n",
    "y = torch.tensor([[1.0]])\n",
    "loss = (model(x) - y) ** 2\n",
    "loss.backward()\n",
    "\n",
    "print(f\"Gradient magnitude: {model.weight.grad.abs().mean():.4f}\")\n",
    "print(f\"\\nEffect of different learning rates:\")\n",
    "\n",
    "for lr in [0.001, 0.01, 0.1]:\n",
    "    model.weight.data = original_weight.clone()\n",
    "    model.weight.data -= lr * model.weight.grad\n",
    "    change = (model.weight.data - original_weight).abs().mean()\n",
    "    print(f\"  lr={lr}: weight changed by {change:.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 4.9 üîë Training Loop - Pattern ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á\n",
    "\n",
    "\n",
    "\n",
    " **‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ (‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢):**\n",
    "\n",
    "\n",
    "\n",
    " ‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠ pattern ‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£ train model ‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á:\n",
    "\n",
    "\n",
    "\n",
    " ```python\n",
    "\n",
    " for epoch in range(n_epochs):\n",
    "\n",
    "     model.train()              # 1. ‡∏ï‡∏±‡πâ‡∏á training mode\n",
    "\n",
    "     outputs = model(x)         # 2. Forward pass\n",
    "\n",
    "     loss = criterion(outputs, y)  # 3. ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì loss\n",
    "\n",
    "\n",
    "\n",
    "     optimizer.zero_grad()      # 4. Clear gradients\n",
    "\n",
    "     loss.backward()            # 5. Compute gradients\n",
    "\n",
    "     optimizer.step()           # 6. Update parameters\n",
    "\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á Training Step\n",
    "model = SimpleNet(10, 32, 5).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def training_step(model, x, y, criterion, optimizer):\n",
    "    \"\"\"\n",
    "    Training step ‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô\n",
    "    \n",
    "    Args:\n",
    "        model: neural network\n",
    "        x: input data\n",
    "        y: target labels\n",
    "        criterion: loss function\n",
    "        optimizer: optimizer\n",
    "    \n",
    "    Returns:\n",
    "        loss value\n",
    "    \"\"\"\n",
    "    model.train()  # 1. Training mode\n",
    "    \n",
    "    # 2. Forward pass\n",
    "    outputs = model(x)\n",
    "    \n",
    "    # 3. ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì loss\n",
    "    loss = criterion(outputs, y)\n",
    "    \n",
    "    # 4-6. Backward pass\n",
    "    optimizer.zero_grad()  # Clear gradients\n",
    "    loss.backward()        # Compute gradients\n",
    "    optimizer.step()       # Update parameters\n",
    "    \n",
    "    return loss.item()\n",
    "\n",
    "# ‡∏ó‡∏î‡∏™‡∏≠‡∏ö\n",
    "x = torch.randn(4, 10).to(device)\n",
    "y = torch.randint(0, 5, (4,)).to(device)\n",
    "loss = training_step(model, x, y, criterion, optimizer)\n",
    "print(f\"Training loss: {loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ---\n",
    "\n",
    " # üß™ Lab A: Linear Regression ‡∏à‡∏≤‡∏Å‡∏®‡∏π‡∏ô‡∏¢‡πå\n",
    "\n",
    " ---\n",
    "\n",
    "\n",
    "\n",
    " ‡∏°‡∏≤‡∏•‡∏≠‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á Linear Regression ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ tensor operations ‡πÅ‡∏•‡∏∞ autograd ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Step 1: ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
    "\n",
    "\n",
    "\n",
    " ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå: `y = 3x + 2 + noise`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
    "n_samples = 100\n",
    "X = torch.randn(n_samples, 1)\n",
    "y_true = 3 * X + 2 + 0.3 * torch.randn(n_samples, 1)\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y_true.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Step 2: Visualize ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X.numpy(), y_true.numpy(), alpha=0.6, label='Data')\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.title(\"Linear Regression Data\\n(True relationship: y = 3x + 2)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Step 3: ‡∏Å‡∏≥‡∏´‡∏ô‡∏î Parameters\n",
    "\n",
    "\n",
    "\n",
    " ‡πÄ‡∏£‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏´‡∏≤‡∏Ñ‡πà‡∏≤ w ‡πÅ‡∏•‡∏∞ b ‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡πÉ‡∏´‡πâ `y = wx + b` ‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡πà‡∏≤‡∏™‡∏∏‡πà‡∏°\n",
    "w = torch.randn(1, requires_grad=True)  # weight\n",
    "b = torch.zeros(1, requires_grad=True)  # bias\n",
    "\n",
    "print(f\"‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô:\")\n",
    "print(f\"  w = {w.item():.4f} (target: 3.0)\")\n",
    "print(f\"  b = {b.item():.4f} (target: 2.0)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Step 4: Training Loop\n",
    "\n",
    "\n",
    "\n",
    " **‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞ epoch:**\n",
    "\n",
    " 1. Forward pass: ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì prediction\n",
    "\n",
    " 2. ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì loss (MSE)\n",
    "\n",
    " 3. Backward pass: ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì gradients\n",
    "\n",
    " 4. Update parameters\n",
    "\n",
    " 5. Clear gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "n_epochs = 100\n",
    "losses = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # 1. Forward pass\n",
    "    y_pred = X * w + b\n",
    "    \n",
    "    # 2. ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì MSE loss\n",
    "    loss = ((y_pred - y_true) ** 2).mean()\n",
    "    losses.append(loss.item())\n",
    "    \n",
    "    # 3. Backward pass\n",
    "    loss.backward()\n",
    "    \n",
    "    # 4. Update parameters\n",
    "    with torch.no_grad():\n",
    "        w -= learning_rate * w.grad\n",
    "        b -= learning_rate * b.grad\n",
    "    \n",
    "    # 5. Clear gradients\n",
    "    w.grad.zero_()\n",
    "    b.grad.zero_()\n",
    "    \n",
    "    # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏ó‡∏∏‡∏Å‡πÜ 20 epochs\n",
    "    if (epoch + 1) % 20 == 0:\n",
    "        print(f\"Epoch {epoch+1:3d}: Loss = {loss.item():.4f}, \"\n",
    "              f\"w = {w.item():.4f}, b = {b.item():.4f}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Final Result:\")\n",
    "print(f\"   w = {w.item():.4f} (target: 3.0)\")\n",
    "print(f\"   b = {b.item():.4f} (target: 2.0)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Step 5: Visualize ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Loss curve\n",
    "axes[0].plot(losses)\n",
    "axes[0].set_xlabel(\"Epoch\")\n",
    "axes[0].set_ylabel(\"Loss\")\n",
    "axes[0].set_title(\"Loss Reduction During Training\")\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Prediction plot\n",
    "with torch.no_grad():\n",
    "    y_pred = X * w + b\n",
    "\n",
    "axes[1].scatter(X.numpy(), y_true.numpy(), alpha=0.6, label=\"Actual Data\")\n",
    "axes[1].plot(X.numpy(), y_pred.numpy(), 'r-', linewidth=2, \n",
    "             label=f\"Prediction: y = {w.item():.2f}x + {b.item():.2f}\")\n",
    "axes[1].set_xlabel(\"X\")\n",
    "axes[1].set_ylabel(\"y\")\n",
    "axes[1].set_title(\"Linear Regression Result\")\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## ‚úèÔ∏è ‡πÅ‡∏ö‡∏ö‡∏ù‡∏∂‡∏Å‡∏´‡∏±‡∏î Lab A: Polynomial Regression\n",
    "\n",
    "\n",
    "\n",
    " **‡πÇ‡∏à‡∏ó‡∏¢‡πå:** ‡∏Ç‡∏¢‡∏≤‡∏¢ linear regression ‡πÄ‡∏õ‡πá‡∏ô polynomial\n",
    "\n",
    "\n",
    "\n",
    " ‡∏´‡∏≤‡∏Ñ‡πà‡∏≤ a, b, c ‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡πÉ‡∏´‡πâ `y = ax¬≤ + bx + c` ‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• polynomial\n",
    "set_seed(42)\n",
    "X_poly = torch.linspace(-2, 2, 100).unsqueeze(1)\n",
    "y_poly_true = 0.5 * X_poly**2 - 1.5 * X_poly + 0.5 + 0.2 * torch.randn_like(X_poly)\n",
    "\n",
    "# ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà (YOUR CODE HERE)\n",
    "# 1. ‡∏Å‡∏≥‡∏´‡∏ô‡∏î parameters a, b, c\n",
    "# 2. ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô training loop\n",
    "# 3. Plot ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ---\n",
    "\n",
    " # üß™ Lab B: MLP Classifier ‡∏ö‡∏ô Toy Dataset\n",
    "\n",
    " ---\n",
    "\n",
    "\n",
    "\n",
    " ‡∏°‡∏≤‡∏™‡∏£‡πâ‡∏≤‡∏á Neural Network Classifier ‡∏ó‡∏µ‡πà‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Step 1: ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
    "\n",
    "\n",
    "\n",
    " ‡πÉ‡∏ä‡πâ dataset \"moons\" ‡∏à‡∏≤‡∏Å scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á dataset ‡∏£‡∏π‡∏õ‡∏û‡∏£‡∏∞‡∏à‡∏±‡∏ô‡∏ó‡∏£‡πå‡πÄ‡∏™‡∏µ‡πâ‡∏¢‡∏ß 2 ‡∏≠‡∏±‡∏ô\n",
    "X_np, y_np = make_moons(n_samples=500, noise=0.1)\n",
    "\n",
    "# ‡πÅ‡∏ö‡πà‡∏á train/test (80%/20%)\n",
    "X_train_np, X_test_np, y_train_np, y_test_np = train_test_split(\n",
    "    X_np, y_np, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô PyTorch tensors\n",
    "X_train = torch.from_numpy(X_train_np).float()\n",
    "X_test = torch.from_numpy(X_test_np).float()\n",
    "y_train = torch.from_numpy(y_train_np).long()  # CrossEntropy ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ long\n",
    "y_test = torch.from_numpy(y_test_np).long()\n",
    "\n",
    "print(f\"Training set: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}, {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Step 2: Visualize ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Training data\n",
    "axes[0].scatter(X_train_np[y_train_np == 0, 0], X_train_np[y_train_np == 0, 1], \n",
    "                c='blue', label='Class 0', alpha=0.7)\n",
    "axes[0].scatter(X_train_np[y_train_np == 1, 0], X_train_np[y_train_np == 1, 1], \n",
    "                c='red', label='Class 1', alpha=0.7)\n",
    "axes[0].set_title(\"Training Data\")\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Test data\n",
    "axes[1].scatter(X_test_np[y_test_np == 0, 0], X_test_np[y_test_np == 0, 1], \n",
    "                c='blue', label='Class 0', alpha=0.7)\n",
    "axes[1].scatter(X_test_np[y_test_np == 1, 0], X_test_np[y_test_np == 1, 1], \n",
    "                c='red', label='Class 1', alpha=0.7)\n",
    "axes[1].set_title(\"Test Data\")\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.suptitle(\"Moons Dataset\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Step 3: ‡∏™‡∏£‡πâ‡∏≤‡∏á MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-Layer Perceptron ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Binary Classification\n",
    "    \n",
    "    ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á:\n",
    "    Input(2) ‚Üí Linear ‚Üí ReLU ‚Üí Linear ‚Üí ReLU ‚Üí Linear ‚Üí Output(2)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim=2, hidden_dim=32, output_dim=2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á model\n",
    "model = MLPClassifier(input_dim=2, hidden_dim=32, output_dim=2)\n",
    "print(model)\n",
    "print(f\"\\nTotal parameters: {sum(p.numel() for p in model.parameters()):,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Step 4: ‡∏Å‡∏≥‡∏´‡∏ô‡∏î Loss ‡πÅ‡∏•‡∏∞ Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Step 5: Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 200\n",
    "train_losses = []\n",
    "test_accs = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # === Training ===\n",
    "    model.train()\n",
    "    \n",
    "    # Forward\n",
    "    logits = model(X_train)\n",
    "    loss = criterion(logits, y_train)\n",
    "    \n",
    "    # Backward\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    train_losses.append(loss.item())\n",
    "    \n",
    "    # === Evaluation ===\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_logits = model(X_test)\n",
    "        test_preds = test_logits.argmax(dim=1)\n",
    "        test_acc = (test_preds == y_test).float().mean()\n",
    "        test_accs.append(test_acc.item())\n",
    "    \n",
    "    # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏ó‡∏∏‡∏Å‡πÜ 50 epochs\n",
    "    if (epoch + 1) % 50 == 0:\n",
    "        print(f\"Epoch {epoch+1:3d}: Loss = {loss.item():.4f}, \"\n",
    "              f\"Test Accuracy = {test_acc.item():.4f}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Final Test Accuracy: {test_accs[-1]:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Step 6: Visualize Training Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Loss curve\n",
    "axes[0].plot(train_losses)\n",
    "axes[0].set_xlabel(\"Epoch\")\n",
    "axes[0].set_ylabel(\"Loss\")\n",
    "axes[0].set_title(\"Training Loss\")\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Accuracy curve\n",
    "axes[1].plot(test_accs)\n",
    "axes[1].set_xlabel(\"Epoch\")\n",
    "axes[1].set_ylabel(\"Accuracy\")\n",
    "axes[1].set_title(\"Test Accuracy\")\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Step 7: Visualize Decision Boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary(model, X, y, title=\"Decision Boundary\"):\n",
    "    \"\"\"\n",
    "    ‡πÅ‡∏™‡∏î‡∏á decision boundary ‡∏Ç‡∏≠‡∏á classifier\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # ‡∏™‡∏£‡πâ‡∏≤‡∏á mesh grid\n",
    "    x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
    "    y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),\n",
    "                         np.linspace(y_min, y_max, 100))\n",
    "    \n",
    "    # Predict ‡∏ö‡∏ô mesh\n",
    "    grid = torch.from_numpy(np.c_[xx.ravel(), yy.ravel()]).float()\n",
    "    with torch.no_grad():\n",
    "        probs = torch.softmax(model(grid), dim=1)[:, 1].numpy()\n",
    "    probs = probs.reshape(xx.shape)\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.contourf(xx, yy, probs, levels=50, cmap='RdBu', alpha=0.8)\n",
    "    plt.colorbar(label='P(Class 1)')\n",
    "    plt.scatter(X[y == 0, 0], X[y == 0, 1], c='blue', edgecolors='white', \n",
    "                s=50, label='Class 0')\n",
    "    plt.scatter(X[y == 1, 0], X[y == 1, 1], c='red', edgecolors='white', \n",
    "                s=50, label='Class 1')\n",
    "    plt.xlabel(\"Feature 1\")\n",
    "    plt.ylabel(\"Feature 2\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_decision_boundary(model, X_test_np, y_test_np, \n",
    "                       title=f\"Decision Boundary (Test Acc: {test_accs[-1]:.2%})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Step 8: ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÅ‡∏•‡∏∞‡πÇ‡∏´‡∏•‡∏î Model\n",
    "\n",
    "\n",
    "\n",
    " **‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ (‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢):**\n",
    "\n",
    "\n",
    "\n",
    " ‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å model ‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏Ñ‡∏∑‡∏≠‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å `state_dict` (parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å model\n",
    "model_path = \"./mlp_classifier.pt\"\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(f\"‚úÖ Model saved to: {model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡πÇ‡∏´‡∏•‡∏î model\n",
    "loaded_model = MLPClassifier(input_dim=2, hidden_dim=32, output_dim=2)\n",
    "loaded_model.load_state_dict(torch.load(model_path, weights_only=True))\n",
    "loaded_model.eval()\n",
    "\n",
    "# ‡∏ó‡∏î‡∏™‡∏≠‡∏ö\n",
    "with torch.no_grad():\n",
    "    test_logits = loaded_model(X_test)\n",
    "    test_preds = test_logits.argmax(dim=1)\n",
    "    test_acc = (test_preds == y_test).float().mean()\n",
    "    \n",
    "print(f\"‚úÖ Model loaded successfully - Test Accuracy: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ---\n",
    "\n",
    " # üìö ‡πÄ‡∏â‡∏•‡∏¢‡πÅ‡∏ö‡∏ö‡∏ù‡∏∂‡∏Å‡∏´‡∏±‡∏î\n",
    "\n",
    " ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## ‡πÄ‡∏â‡∏•‡∏¢: ‡πÅ‡∏ö‡∏ö‡∏ù‡∏∂‡∏Å‡∏´‡∏±‡∏î 1.1 - Device Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_to_best_device_solution(tensor):\n",
    "    \"\"\"‡∏¢‡πâ‡∏≤‡∏¢ tensor ‡πÑ‡∏õ‡∏¢‡∏±‡∏á device ‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î\"\"\"\n",
    "    print(f\"Device ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô: {tensor.device}\")\n",
    "    best_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    moved = tensor.to(best_device)\n",
    "    print(f\"‡∏¢‡πâ‡∏≤‡∏¢‡πÑ‡∏õ‡∏ó‡∏µ‡πà: {moved.device}\")\n",
    "    return moved\n",
    "\n",
    "# ‡∏ó‡∏î‡∏™‡∏≠‡∏ö\n",
    "print(\"‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô move_to_best_device:\")\n",
    "test_tensor = torch.ones(5)\n",
    "result = move_to_best_device_solution(test_tensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## ‡πÄ‡∏â‡∏•‡∏¢: ‡πÅ‡∏ö‡∏ö‡∏ù‡∏∂‡∏Å‡∏´‡∏±‡∏î 2.1 - Tensor Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = torch.arange(16).reshape(4, 4).float()\n",
    "print(f\"Matrix:\\n{matrix}\")\n",
    "\n",
    "# 1. Diagonal\n",
    "diagonal = matrix.diag()\n",
    "print(f\"\\n1. Diagonal: {diagonal}\")\n",
    "\n",
    "# 2. Upper-right 2x2\n",
    "upper_right = matrix[:2, 2:]\n",
    "print(f\"\\n2. Upper-right 2x2:\\n{upper_right}\")\n",
    "\n",
    "# 3. Above mean\n",
    "mean_val = matrix.mean()\n",
    "above_mean = matrix[matrix > mean_val]\n",
    "print(f\"\\n3. Mean = {mean_val:.2f}\")\n",
    "print(f\"   Values above mean: {above_mean}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## ‡πÄ‡∏â‡∏•‡∏¢: ‡πÅ‡∏ö‡∏ö‡∏ù‡∏∂‡∏Å‡∏´‡∏±‡∏î 2.2 - Softmax ‡πÅ‡∏•‡∏∞ Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_solution(x, dim=-1):\n",
    "    \"\"\"‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì softmax ‡∏û‡∏£‡πâ‡∏≠‡∏° numerical stability\"\"\"\n",
    "    x_max = x.max(dim=dim, keepdim=True).values\n",
    "    x_exp = torch.exp(x - x_max)  # ‡∏•‡∏ö max ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô overflow\n",
    "    return x_exp / x_exp.sum(dim=dim, keepdim=True)\n",
    "\n",
    "def batch_cosine_similarity_solution(a, b):\n",
    "    \"\"\"‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì cosine similarity\"\"\"\n",
    "    dot_product = (a * b).sum(dim=1)\n",
    "    norm_a = torch.norm(a, dim=1)\n",
    "    norm_b = torch.norm(b, dim=1)\n",
    "    return dot_product / (norm_a * norm_b)\n",
    "\n",
    "# ‡∏ó‡∏î‡∏™‡∏≠‡∏ö softmax\n",
    "x = torch.tensor([[1., 2., 3.], [1., 1., 1.]])\n",
    "result = softmax_solution(x)\n",
    "print(f\"Softmax result:\\n{result}\")\n",
    "print(f\"Row sums: {result.sum(dim=1)}\")  # ‡∏Ñ‡∏ß‡∏£‡πÄ‡∏õ‡πá‡∏ô 1\n",
    "\n",
    "# ‡∏ó‡∏î‡∏™‡∏≠‡∏ö cosine similarity\n",
    "a = torch.tensor([[1., 0., 0.], [1., 1., 0.]])\n",
    "b = torch.tensor([[1., 0., 0.], [0., 1., 0.]])\n",
    "sim = batch_cosine_similarity_solution(a, b)\n",
    "print(f\"\\nCosine similarities: {sim}\")  # [1.0, 0.707...]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## ‡πÄ‡∏â‡∏•‡∏¢: Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "X_poly = torch.linspace(-2, 2, 100).unsqueeze(1)\n",
    "y_poly_true = 0.5 * X_poly**2 - 1.5 * X_poly + 0.5 + 0.2 * torch.randn_like(X_poly)\n",
    "\n",
    "# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î parameters\n",
    "a = torch.randn(1, requires_grad=True)\n",
    "b_coef = torch.randn(1, requires_grad=True)\n",
    "c = torch.randn(1, requires_grad=True)\n",
    "\n",
    "# Training\n",
    "learning_rate = 0.1\n",
    "n_epochs = 500\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # Forward: y = ax¬≤ + bx + c\n",
    "    y_pred = a * X_poly**2 + b_coef * X_poly + c\n",
    "    loss = ((y_pred - y_poly_true) ** 2).mean()\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        a -= learning_rate * a.grad\n",
    "        b_coef -= learning_rate * b_coef.grad\n",
    "        c -= learning_rate * c.grad\n",
    "    \n",
    "    a.grad.zero_()\n",
    "    b_coef.grad.zero_()\n",
    "    c.grad.zero_()\n",
    "    \n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f\"Epoch {epoch+1}: Loss={loss.item():.4f}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Result: y = {a.item():.2f}x^2 + {b_coef.item():.2f}x + {c.item():.2f}\")\n",
    "print(f\"   Target: y = 0.50x^2 - 1.50x + 0.50\")\n",
    "\n",
    "# Plot\n",
    "with torch.no_grad():\n",
    "    y_pred = a * X_poly**2 + b_coef * X_poly + c\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_poly.numpy(), y_poly_true.numpy(), alpha=0.5, label='Data')\n",
    "plt.plot(X_poly.numpy(), y_pred.numpy(), 'r-', linewidth=2, \n",
    "         label=f'Fit: {a.item():.2f}x^2 + {b_coef.item():.2f}x + {c.item():.2f}')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Polynomial Regression Result')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ---\n",
    "\n",
    " # üéØ ‡∏™‡∏£‡∏∏‡∏õ Skills ‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ\n",
    "\n",
    " ---\n",
    "\n",
    "\n",
    "\n",
    " ## ‚úÖ ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô Training Loop ‡πÑ‡∏î‡πâ\n",
    "\n",
    " ```python\n",
    "\n",
    " for epoch in range(n_epochs):\n",
    "\n",
    "     model.train()\n",
    "\n",
    "     outputs = model(X)\n",
    "\n",
    "     loss = criterion(outputs, y)\n",
    "\n",
    "     optimizer.zero_grad()  # Clear gradients\n",
    "\n",
    "     loss.backward()        # Compute gradients\n",
    "\n",
    "     optimizer.step()       # Update weights\n",
    "\n",
    " ```\n",
    "\n",
    "\n",
    "\n",
    " ## ‚úÖ ‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏û‡∏ö‡∏ö‡πà‡∏≠‡∏¢\n",
    "\n",
    "\n",
    "\n",
    " | Error | ‡∏™‡∏≤‡πÄ‡∏´‡∏ï‡∏∏ | ‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ |\n",
    "\n",
    " |-------|--------|--------|\n",
    "\n",
    " | Size mismatch | ‡∏°‡∏¥‡∏ï‡∏¥‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á | ‡∏ï‡∏£‡∏ß‡∏à shape, ‡πÉ‡∏ä‡πâ reshape |\n",
    "\n",
    " | Device mismatch | CPU/GPU ‡∏õ‡∏ô‡∏Å‡∏±‡∏ô | ‡∏¢‡πâ‡∏≤‡∏¢‡πÑ‡∏õ device ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô |\n",
    "\n",
    " | Dtype mismatch | ‡∏ä‡∏ô‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á | ‡πÉ‡∏ä‡πâ .float(), .long() |\n",
    "\n",
    " | Gradients ‡πÄ‡∏õ‡πá‡∏ô None | ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å backward | ‡∏ï‡∏£‡∏ß‡∏à requires_grad |\n",
    "\n",
    " | Gradients ‡∏™‡∏∞‡∏™‡∏° | ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ clear | optimizer.zero_grad() |\n",
    "\n",
    "\n",
    "\n",
    " ## ‚úÖ Save/Load Models\n",
    "\n",
    " ```python\n",
    "\n",
    " # Save\n",
    "\n",
    " torch.save(model.state_dict(), \"model.pt\")\n",
    "\n",
    "\n",
    "\n",
    " # Load\n",
    "\n",
    " model.load_state_dict(torch.load(\"model.pt\", weights_only=True))\n",
    "\n",
    " model.eval()\n",
    "\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ---\n",
    "\n",
    " # üöÄ ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ñ‡∏±‡∏î‡πÑ‡∏õ\n",
    "\n",
    " ---\n",
    "\n",
    "\n",
    "\n",
    " **Day 2 Topics:**\n",
    "\n",
    " - Datasets ‡πÅ‡∏•‡∏∞ DataLoaders\n",
    "\n",
    " - Transforms ‡πÅ‡∏•‡∏∞ augmentation\n",
    "\n",
    " - Model architectures (CNNs, RNNs)\n",
    "\n",
    " - Training best practices\n",
    "\n",
    " - GPU optimization\n",
    "\n",
    "\n",
    "\n",
    " **‡πÅ‡∏´‡∏•‡πà‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°:**\n",
    "\n",
    " - [PyTorch Official Tutorials](https://pytorch.org/tutorials/)\n",
    "\n",
    " - [PyTorch Documentation](https://pytorch.org/docs/stable/index.html)\n",
    "\n",
    " - [Deep Learning with PyTorch Book](https://pytorch.org/deep-learning-with-pytorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
    "‚ïë                                                                   ‚ïë\n",
    "‚ïë  üéâ ‡∏¢‡∏¥‡∏ô‡∏î‡∏µ‡∏î‡πâ‡∏ß‡∏¢! ‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏à‡∏ö PyTorch Basics Lab ‡πÅ‡∏•‡πâ‡∏ß!                ‚ïë\n",
    "‚ïë                                                                   ‚ïë\n",
    "‚ïë  ‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ:                                              ‚ïë\n",
    "‚ïë  ‚Ä¢ Tensor ‡∏Ñ‡∏∑‡∏≠‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á PyTorch                                   ‚ïë\n",
    "‚ïë  ‚Ä¢ Autograd ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì gradient ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥                               ‚ïë\n",
    "‚ïë  ‚Ä¢ nn.Module ‡∏Ñ‡∏∑‡∏≠ base class ‡∏Ç‡∏≠‡∏á neural networks                   ‚ïë\n",
    "‚ïë  ‚Ä¢ Training loop: forward ‚Üí loss ‚Üí backward ‚Üí step                ‚ïë\n",
    "‚ïë                                                                   ‚ïë\n",
    "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
    "\"\"\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
